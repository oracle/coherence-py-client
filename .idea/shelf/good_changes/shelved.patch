Index: src/coherence/util_v1.py
===================================================================
diff --git a/src/coherence/util_v1.py b/src/coherence/util_v1.py
deleted file mode 100644
--- a/src/coherence/util_v1.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ /dev/null	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
@@ -1,436 +0,0 @@
-# Copyright (c) 2022, 2023 Oracle and/or its affiliates.
-# Licensed under the Universal Permissive License v 1.0 as shown at
-# https://oss.oracle.com/licenses/upl.
-
-from __future__ import annotations
-
-import logging
-import sys
-import threading
-from typing import Optional, TypeVar
-
-from google.protobuf.any_pb2 import Any as GrpcAny  # type: ignore
-from google.protobuf.wrappers_pb2 import BytesValue  # type: ignore
-
-from .aggregator import EntryAggregator
-from .cache_service_messages_v1_pb2 import (
-    EnsureCacheRequest,
-    ExecuteRequest,
-    IndexRequest,
-    KeysOrFilter,
-    NamedCacheRequest,
-    NamedCacheRequestType,
-    PutAllRequest,
-    PutRequest,
-    QueryRequest,
-    ReplaceMappingRequest,
-)
-from .common_messages_v1_pb2 import BinaryKeyAndValue, CollectionOfBytesValues
-from .comparator import Comparator
-from .extractor import ValueExtractor
-from .filter import Filter, Filters, MapEventFilter
-from .messages_pb2 import MapListenerRequest, PageRequest
-from .processor import EntryProcessor
-from .proxy_service_messages_v1_pb2 import ProxyRequest
-from .serialization import Serializer
-
-E = TypeVar("E")
-K = TypeVar("K")
-R = TypeVar("R")
-T = TypeVar("T")
-V = TypeVar("V")
-
-COH_LOG = logging.getLogger("coherence")
-
-
-class RequestIdGenerator:
-    _generator = None
-
-    def __init__(self) -> None:
-        self._lock = threading.Lock()
-        self._counter = 0
-
-    @classmethod
-    def generator(cls) -> RequestIdGenerator:
-        if RequestIdGenerator._generator is None:
-            RequestIdGenerator._generator = RequestIdGenerator()
-        return RequestIdGenerator._generator
-
-    @classmethod
-    def next(cls) -> int:
-        generator = cls.generator()
-        with generator._lock:
-            if generator._counter == sys.maxsize:
-                generator._counter = 0
-            else:
-                generator._counter += 1
-            return generator._counter
-
-
-class RequestFactoryV1:
-
-    def __init__(self, cache_name: str, cache_id: int, scope: str, serializer: Serializer) -> None:
-        self._cache_name: str = cache_name
-        self._cache_id: int = cache_id
-        self._scope: str = scope
-        self._serializer: Serializer = serializer
-        # self.__uidPrefix: str = "-" + cache_name + "-" + str(time.time_ns())
-        # self.__next_request_id: int = 0
-        # self.__next_filter_id: int = 0
-
-    @property
-    def cache_id(self) -> int:
-        return self._cache_id
-
-    @cache_id.setter
-    def cache_id(self, value: int) -> None:
-        self._cache_id = value
-
-    def get_serializer(self) -> Serializer:
-        return self._serializer
-
-    def _create_named_cache_request(self, request: any, request_type: NamedCacheRequestType) -> NamedCacheRequest:
-        any_cache_request = GrpcAny()
-        any_cache_request.Pack(request)
-
-        return NamedCacheRequest(
-            type=request_type,
-            cacheId=self.cache_id,
-            message=any_cache_request,
-        )
-
-    @staticmethod
-    def create_proxy_request(named_cache_request: NamedCacheRequest) -> ProxyRequest:
-        any_named_cache_request = GrpcAny()
-        any_named_cache_request.Pack(named_cache_request)
-        req_id = RequestIdGenerator.next()
-        proxy_request = ProxyRequest(
-            id=req_id,
-            message=any_named_cache_request,
-        )
-        return proxy_request
-
-    @staticmethod
-    def ensure_request(cache_name: str) -> NamedCacheRequest:
-        cache_request = EnsureCacheRequest(cache=cache_name)
-
-        any_cache_request = GrpcAny()
-        any_cache_request.Pack(cache_request)
-
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.EnsureCache,
-            message=any_cache_request,
-        )
-        return named_cache_request
-
-    def put_request(self, key: K, value: V, ttl: int = 0) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            PutRequest(
-                key=self._serializer.serialize(key),  # Serialized key
-                value=self._serializer.serialize(value),  # Serialized value
-                ttl=ttl,
-            ),
-            NamedCacheRequestType.Put,
-        )
-
-    def get_request(self, key: K) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Get
-        )
-
-    def get_all_request(self, keys: set[K]) -> NamedCacheRequest:
-        if keys is None:
-            raise ValueError("Must specify a set of keys")
-
-        return self._create_named_cache_request(
-            CollectionOfBytesValues(
-                values=list(self._serializer.serialize(k) for k in keys),
-            ),
-            NamedCacheRequestType.GetAll,
-        )
-
-    def put_if_absent_request(self, key: K, value: V, ttl: int = 0) -> NamedCacheRequest:
-
-        return self._create_named_cache_request(
-            PutRequest(
-                key=self._serializer.serialize(key),  # Serialized key
-                value=self._serializer.serialize(value),  # Serialized value
-                ttl=ttl,
-            ),
-            NamedCacheRequestType.PutIfAbsent,
-        )
-
-    def put_all_request(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            PutAllRequest(
-                entries=list(
-                    BinaryKeyAndValue(key=self._serializer.serialize(k), value=self._serializer.serialize(v))
-                    for k, v in kv_map.items()
-                ),
-                ttl=ttl,
-            ),
-            NamedCacheRequestType.PutAll,
-        )
-
-    def clear_request(self) -> NamedCacheRequest:
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.Clear,
-            cacheId=self.cache_id,
-        )
-        return named_cache_request
-
-    def destroy_request(self) -> NamedCacheRequest:
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.Destroy,
-            cacheId=self.cache_id,
-        )
-        return named_cache_request
-
-    def truncate_request(self) -> NamedCacheRequest:
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.Truncate,
-            cacheId=self.cache_id,
-        )
-        return named_cache_request
-
-    def remove_request(self, key: K) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Remove
-        )
-
-    def remove_mapping_request(self, key: K, value: V) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),
-            NamedCacheRequestType.RemoveMapping,
-        )
-
-    def replace_request(self, key: K, value: V) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),
-            NamedCacheRequestType.Replace,
-        )
-
-    def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            ReplaceMappingRequest(
-                key=self._serializer.serialize(key),
-                previousValue=self._serializer.serialize(old_value),
-                newValue=self._serializer.serialize(new_value),
-            ),
-            NamedCacheRequestType.ReplaceMapping,
-        )
-
-    def contains_key_request(self, key: K) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.ContainsKey
-        )
-
-    def contains_value_request(self, value: V) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            BytesValue(value=self._serializer.serialize(value)), NamedCacheRequestType.ContainsValue
-        )
-
-    def is_empty_request(self) -> NamedCacheRequest:
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.IsEmpty,
-            cacheId=self.cache_id,
-        )
-        return named_cache_request
-
-    def size_request(self) -> NamedCacheRequest:
-        named_cache_request = NamedCacheRequest(
-            type=NamedCacheRequestType.Size,
-            cacheId=self.cache_id,
-        )
-        return named_cache_request
-
-    def invoke_request(self, key: K, processor: EntryProcessor[R]) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            ExecuteRequest(
-                agent=self._serializer.serialize(processor),
-                keys=KeysOrFilter(
-                    key=self._serializer.serialize(key),
-                ),
-            ),
-            NamedCacheRequestType.Invoke,
-        )
-
-    def invoke_all_request(
-        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, query_filter: Optional[Filter] = None
-    ) -> NamedCacheRequest:
-        if keys is not None and query_filter is not None:
-            raise ValueError("keys and filter are mutually exclusive")
-
-        if keys is not None:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(processor),
-                keys=KeysOrFilter(
-                    keys=CollectionOfBytesValues(
-                        values=list(self._serializer.serialize(key) for key in keys),
-                    ),
-                ),
-            )
-        elif query_filter is not None:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(processor),
-                keys=KeysOrFilter(
-                    filter=self._serializer.serialize(query_filter),
-                ),
-            )
-        else:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(processor),
-            )
-
-        return self._create_named_cache_request(cache_request, NamedCacheRequestType.Invoke)
-
-    def aggregate_request(
-        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, query_filter: Optional[Filter] = None
-    ) -> NamedCacheRequest:
-        if keys is not None and query_filter is not None:
-            raise ValueError("keys and filter are mutually exclusive")
-
-        if keys is not None:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(aggregator),
-                keys=KeysOrFilter(
-                    keys=CollectionOfBytesValues(
-                        values=list(self._serializer.serialize(key) for key in keys),
-                    ),
-                ),
-            )
-        elif query_filter is not None:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(aggregator),
-                keys=KeysOrFilter(
-                    filter=self._serializer.serialize(query_filter),
-                ),
-            )
-        else:
-            cache_request = ExecuteRequest(
-                agent=self._serializer.serialize(aggregator),
-            )
-
-        return self._create_named_cache_request(cache_request, NamedCacheRequestType.Aggregate)
-
-    def values_request(
-        self, query_filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
-    ) -> NamedCacheRequest:
-        if query_filter is None and comparator is not None:
-            raise ValueError("Filter cannot be None")
-
-        if query_filter is not None:
-            query_request = QueryRequest(filter=self._serializer.serialize(query_filter))
-        elif comparator is not None:
-            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))
-        else:
-            query_request = QueryRequest()
-
-        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryValues)
-
-    def keys_request(self, query_filter: Optional[Filter] = None) -> NamedCacheRequest:
-
-        if query_filter is not None:
-            query_request = QueryRequest(filter=self._serializer.serialize(query_filter))
-        else:
-            query_request = QueryRequest()
-
-        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryKeys)
-
-    def entries_request(
-        self, query_filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
-    ) -> NamedCacheRequest:
-        if query_filter is None and comparator is not None:
-            raise ValueError("Filter cannot be None")
-
-        if query_filter is not None:
-            query_request = QueryRequest(filter=self._serializer.serialize(query_filter))
-        elif comparator is not None:
-            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))
-        else:
-            query_request = QueryRequest()
-
-        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryEntries)
-
-    def page_request(self, cookie: bytes) -> PageRequest:
-        """
-        Creates a gRPC PageRequest.
-
-        :param cookie: the cookie used for paging
-        :return: a new PageRequest
-        """
-
-        r: PageRequest = PageRequest(
-            scope=self._scope, cache=self._cache_name, format=self._serializer.format, cookie=cookie
-        )
-
-        return r
-
-    def map_listener_request(
-        self, subscribe: bool, lite: bool = False, *, key: Optional[K] = None, query_filter: Optional[Filter] = None
-    ) -> MapListenerRequest:
-        """Creates a gRPC generated MapListenerRequest"""
-
-        if key is None and query_filter is None:
-            raise AssertionError("Must specify a key or a filter")
-
-        request: MapListenerRequest = MapListenerRequest(
-            cache=self._cache_name, scope=self._scope, format=self._serializer.format
-        )
-
-        request.lite = lite
-        request.subscribe = subscribe
-        request.uid = self.__generate_next_request_id("key" if key is not None else "filter")
-        request.trigger = bytes()
-        request.priming = False
-
-        if key is not None:  # registering a key listener
-            request.type = MapListenerRequest.RequestType.KEY
-            request.key = self._serializer.serialize(key)
-        else:  # registering a Filter listener
-            request.type = MapListenerRequest.RequestType.FILTER
-            self.__next_filter_id += 1
-            request.filterId = self.__next_filter_id
-            filter_local: Filter = query_filter if query_filter is not None else Filters.always()
-            if not isinstance(filter_local, MapEventFilter):
-                filter_local = MapEventFilter.from_filter(filter_local)
-
-            request.filter = self._serializer.serialize(filter_local)
-
-        return request
-
-    def map_event_subscribe(self) -> MapListenerRequest:
-        request: MapListenerRequest = MapListenerRequest(
-            cache=self._cache_name, scope=self._scope, format=self._serializer.format
-        )
-        request.uid = self.__generate_next_request_id("init")
-        request.subscribe = True
-        request.type = MapListenerRequest.RequestType.INIT
-
-        return request
-
-    def __generate_next_request_id(self, prefix: str) -> str:
-        """Generates a prefix map-specific prefix when starting a MapEvent gRPC stream."""
-        self.__next_request_id += 1
-        return prefix + self.__uidPrefix + str(self.__next_request_id)
-
-    def add_index_request(
-        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None
-    ) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            IndexRequest(
-                add=True,
-                extractor=self._serializer.serialize(extractor),
-                sorted=ordered,
-            ),
-            NamedCacheRequestType.Index,
-        )
-
-    def remove_index_request(self, extractor: ValueExtractor[T, E]) -> NamedCacheRequest:
-        return self._create_named_cache_request(
-            IndexRequest(
-                add=False,
-                extractor=self._serializer.serialize(extractor),
-            ),
-            NamedCacheRequestType.Index,
-        )
Index: src/coherence/processor.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nfrom abc import ABC\nfrom decimal import Decimal\nfrom typing import Any, Generic, List, Optional, TypeVar, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom .extractor import (\n    CompositeUpdater,\n    ExtractorExpression,\n    Extractors,\n    ManipulatorExpression,\n    UniversalExtractor,\n    UniversalUpdater,\n    UpdaterExpression,\n    ValueExtractor,\n    ValueManipulator,\n    ValueUpdater,\n)\nfrom .filter import Filter\nfrom .serialization import mappings, proxy\n\nE = TypeVar(\"E\")\nK = TypeVar(\"K\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\nV = TypeVar(\"V\")\n\nNumeric: TypeAlias = Union[int, float, Decimal]\n\n\nclass EntryProcessor(ABC, Generic[R]):\n    \"\"\"\n    An invocable agent that operates against the entries within a NamedMap\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Constructs a new `EntryProcessor`\n        \"\"\"\n        super().__init__()\n\n    def and_then(self, processor: EntryProcessor[Any]) -> EntryProcessor[Any]:\n        \"\"\"\n        Returns a :class:`coherence.processor.CompositeProcessor` comprised of this and the provided processor.\n\n        :param processor: the next processor\n        :return: a :class:`coherence.processor.CompositeProcessor` comprised of this and the provided processor\n        \"\"\"\n        return CompositeProcessor(self, processor)\n\n    def when(self, filter: Filter) -> EntryProcessor[R]:\n        \"\"\"\n        Returns a :class:`coherence.processor.ConditionalProcessor` comprised of this processor and the provided filter.\n\n        The specified entry processor gets invoked if and only if the filter\n        applied to the entry evaluates to `true`; otherwise the\n        result of the invocation will return `None`.\n\n        :param filter: the filter :return: Returns a :class:`coherence.processor.ConditionalProcessor` comprised of\n         this processor and the provided filter.\n        \"\"\"\n        return ConditionalProcessor(filter, self)\n\n\n@proxy(\"processor.ExtractorProcessor\")\nclass ExtractorProcessor(EntryProcessor[R]):\n    \"\"\"\n    `ExtractorProcessor` is an :class:`coherence.processor.EntryProcessor` implementation that extracts a value from\n    an object cached within a NamedMap.\n\n    :Example:\n        A common usage pattern is:\n\n        >>> cache.invoke(aPerson,ExtractorProcessor(\"age\"))\n\n    For clustered caches using the ExtractorProcessor could significantly reduce the amount of network traffic.\n    \"\"\"\n\n    def __init__(self, value_extractor: ExtractorExpression[V, R]):\n        \"\"\"\n        Construct an `ExtractorProcessor` using the given extractor or method name.\n\n        :param value_extractor: the :class:`coherence.extractor.ValueExtractor` or string expression\n                                to use by this filter or the name of the method to\n                                invoke via java reflection\n        \"\"\"\n        super().__init__()\n        if value_extractor is None:\n            self.extractor: ValueExtractor[V, R] = Extractors.identity()\n        else:\n            if isinstance(value_extractor, ValueExtractor):\n                self.extractor = value_extractor\n            elif isinstance(value_extractor, str):\n                self.extractor = Extractors.extract(value_extractor)\n            else:\n                raise ValueError(\"value_extractor cannot be any other type\")\n\n\n@proxy(\"processor.CompositeProcessor\")\nclass CompositeProcessor(EntryProcessor[R]):\n    \"\"\"\n    CompositeProcessor represents a collection of entry processors that are invoked sequentially against the same\n    MapEntry.\n    \"\"\"\n\n    def __init__(self, *processors: Any):\n        \"\"\"\n        Construct a `CompositeProcessor` for the specified array of individual entry processors.\n\n        The result of the `CompositeProcessor` execution is an array of results returned by the individual\n        EntryProcessor invocations.\n\n        :param processors: the entry processor array\n        \"\"\"\n        super().__init__()\n        self.processors: list[EntryProcessor[Any]] = list()\n        for p in processors:\n            self.processors.append(p)\n\n    def and_then(self, processor: EntryProcessor[Any]) -> CompositeProcessor[R]:\n        self.processors.append(processor)\n        return self\n\n\n@proxy(\"processor.ConditionalProcessor\")\nclass ConditionalProcessor(EntryProcessor[V]):\n    \"\"\"\n    ConditionalProcessor represents a processor that is invoked conditionally based on the result of an entry\n    evaluation.  A `ConditionalProcessor` is returned from the `when()` function, which takes a filter as its argument.\n    \"\"\"\n\n    def __init__(self, filter: Filter, processor: EntryProcessor[V]):\n        \"\"\"\n        Construct a ConditionalProcessor for the specified filter and the processor.\n\n        The specified entry processor gets invoked if and only if the filter applied to the cache entry evaluates to\n        `true`; otherwise the result of the invocation will return `null`.\n\n        :param filter: the filter\n        :param processor: the entry processor\n        \"\"\"\n        super().__init__()\n        self.filter = filter\n        self.processor = processor\n\n\n@proxy(\"util.NullEntryProcessor\")\nclass NullProcessor(EntryProcessor[bool]):\n    \"\"\"\n    Put entry processor.\n\n    An implementation of an EntryProcessor that does nothing and returns `true` as a result of execution.\n    \"\"\"\n\n    __instance: Any = None\n\n    def __init__(self) -> None:\n        \"\"\"\n        Construct a Null EntryProcessor.\n        \"\"\"\n        super().__init__()\n\n\nclass PropertyProcessor(EntryProcessor[R]):\n    \"\"\"\n    `PropertyProcessor` is a base class for EntryProcessor implementations that depend on a ValueManipulator.\n    \"\"\"\n\n    def __init__(self, manipulator: ManipulatorExpression[T, E], use_is: bool = False):\n        \"\"\"\n        Construct a PropertyProcessor for the specified property name.\n\n        This constructor assumes that the corresponding property getter will have a name of (\"get\" + sName) and the\n        corresponding property setter's name will be (\"set\" + sName).\n\n        :param manipulator: the manipulator or property name\n        :param use_is: prefix with `is`\n        \"\"\"\n        super().__init__()\n        if type(manipulator) is str:\n            self.manipulator: ManipulatorExpression[T, E] = PropertyManipulator(manipulator, use_is)\n        else:\n            self.manipulator = manipulator\n\n\n@proxy(\"processor.PropertyManipulator\")\nclass PropertyManipulator(ValueManipulator[V, R]):\n    \"\"\"\n    `PropertyManipulator` is a reflection based ValueManipulator implementation based on the JavaBean property name\n    conventions.\n    \"\"\"\n\n    def __init__(self, property_name: str, use_is: bool = False):\n        \"\"\"\n        Construct a PropertyManipulator for the specified property name.\n\n        This constructor assumes that the corresponding property getter will have a name of either (\"get\" + sName) or\n        (\"is\" + sName) and the corresponding property setter's name will be (\"set\" + sName).\n\n        :param property_name: a property name\n        :param use_is: if true, the getter method will be prefixed with \"is\" rather than \"get\"\n        \"\"\"\n        super().__init__()\n        self.property_name = property_name\n        self.useIsPrefix = use_is\n\n    def get_extractor(self) -> ValueExtractor[V, R]:\n        raise NotImplementedError(\"Method not implemented\")\n\n    def get_updator(self) -> ValueUpdater[V, R]:\n        raise NotImplementedError(\"Method not implemented\")\n\n\n@proxy(\"processor.NumberMultiplier\")\nclass NumberMultiplier(PropertyProcessor[Numeric]):\n    \"\"\"\n    NumberMultiplier entry processor.\n    \"\"\"\n\n    def __init__(\n        self, name_or_manipulator: ManipulatorExpression[T, E], multiplier: Numeric, post_multiplication: bool = False\n    ):\n        \"\"\"\n        Construct an NumberMultiplier processor that will multiply a property value by a specified factor,\n        returning either the old or the new value as specified.\n\n        :param name_or_manipulator: the ValueManipulator or the property name\n        :param multiplier: the Number representing the magnitude and sign of the multiplier\n        :param post_multiplication: pass true to return the value as it was before it was multiplied, or pass false\n         to return the value as it is after it is multiplied\n        \"\"\"\n        if isinstance(name_or_manipulator, str):\n            manipulator: ValueManipulator[Any, Numeric] = self.create_custom_manipulator(name_or_manipulator)\n            super().__init__(manipulator)\n        else:\n            super().__init__(name_or_manipulator)\n        self.multiplier = multiplier\n        self.postMultiplication = post_multiplication\n\n    @staticmethod\n    def create_custom_manipulator(name_or_manipulator: str) -> ValueManipulator[V, Numeric]:\n        cu: CompositeUpdater[V, Numeric] = CompositeUpdater(\n            UniversalExtractor(name_or_manipulator), UniversalUpdater(name_or_manipulator)\n        )\n        return cu\n\n\n@proxy(\"processor.NumberIncrementor\")\nclass NumberIncrementor(PropertyProcessor[Numeric]):\n    \"\"\"\n    The :class:`coherence.processor.NumberIncrementor` :class:`coherence.processor.EntryProcessor` is used to increment\n    a property value of a numeric type.\n    \"\"\"\n\n    def __init__(\n        self, name_or_manipulator: ManipulatorExpression[T, E], increment: Numeric, post_increment: bool = False\n    ):\n        \"\"\"\n        Construct an :class:`coherence.processor.NumberIncrementor` processor that will increment a property\n        value by a specified amount, returning either the old or the new value as specified.\n\n        :param name_or_manipulator: the :class:`coherence.extractor.ValueManipulator` or string expression\n        :param increment: the numeric value representing the magnitude and sign of the increment\n        :param post_increment: pass `True` to return the value as it was before it was incremented, or pass `False`\n         to return the value as it is after it is incremented\n        \"\"\"\n        if isinstance(name_or_manipulator, str):\n            manipulator: ValueManipulator[Any, Numeric] = self.create_custom_manipulator(name_or_manipulator)\n            super().__init__(manipulator)\n        else:\n            super().__init__(name_or_manipulator)\n        self.increment = increment\n        self.postInc = post_increment\n\n    @staticmethod\n    def create_custom_manipulator(name_or_manipulator: str) -> ValueManipulator[Any, Numeric]:\n        cu: CompositeUpdater[Any, Numeric] = CompositeUpdater(\n            UniversalExtractor(name_or_manipulator), UniversalUpdater(name_or_manipulator)\n        )\n        return cu\n\n\n@proxy(\"processor.ConditionalPut\")\n@mappings({\"return_\": \"return\"})\nclass ConditionalPut(EntryProcessor[V]):\n    \"\"\"\n    :class:`coherence.processor.ConditionalPut` is an :class:`coherence.processor.EntryProcessor` that performs\n    an update operation for an entry that satisfies the specified condition.\n\n    While the :class:`coherence.processor.ConditionalPut` processing could be implemented via direct key-based\n    :class:`coherence.client.NamedMap` operations, it is more efficient and enforces concurrency control without\n    explicit locking.\n\n    Obviously, using more specific, fine-tuned filters (rather than ones based on the\n    :class:`coherence.extractor.IdentityExtractor`) may provide additional flexibility and efficiency allowing\n    the put operation to be performed conditionally on values of specific attributes (or even calculations)\n    instead of the entire object.\n    \"\"\"\n\n    def __init__(self, filter: Filter, value: V, return_value: bool = True):\n        \"\"\"\n        Construct a :class:`coherence.processor.ConditionalPut` that updates an entry with a new value if and only\n        if the filter applied to the entry evaluates to `True`.\n\n        :param filter: the :class:`coherence.filter.Filter` to evaluate an entry\n        :param value: a value to update an entry with\n        :param return_value: specifies whether the processor should return the current value in case it has\n         not been updated\n        \"\"\"\n        super().__init__()\n        self.filter = filter\n        self.value = value\n        self.return_ = return_value\n\n\n@proxy(\"processor.ConditionalPutAll\")\nclass ConditionalPutAll(EntryProcessor[V]):\n    \"\"\"\n    `ConditionalPutAll` is an `EntryProcessor` that performs an update operation for multiple entries that satisfy the\n    specified condition.\n\n    This allows for concurrent insertion/update of values within the cache.\n\n    :Example:\n\n        For example a concurrent `replaceAll(map)` could be implemented as:\n\n            >>> filter = PresentFilter.INSTANCE\n            >>> cache.invokeAll(map.keys(), ConditionalPutAll(filter, map))\n\n        or `putAllIfAbsent` could be done by inverting the filter:\n\n            >>> filter = NotFilter(PresentFilter())\n\n\n    Obviously, using more specific, fine-tuned filters may provide additional flexibility and efficiency allowing the\n    multi-put operations to be performed conditionally on values of specific attributes (or even calculations)\n    instead of a simple existence check.\n    \"\"\"\n\n    def __init__(self, filter: Filter, the_map: dict[K, V]):\n        \"\"\"\n        Construct a `ConditionalPutAll` processor that updates an entry with a new value if and only if the filter\n        applied to the entry evaluates to `True`. The new value is extracted from the specified map based on the\n        entry's key.\n\n        :param filter: the filter to evaluate all supplied entries\n        :param the_map: a dict of values to update entries with\n        \"\"\"\n        super().__init__()\n        self.filter = filter\n        self.entries = the_map\n\n\n@proxy(\"processor.ConditionalRemove\")\n@mappings({\"return_value\": \"return\"})\nclass ConditionalRemove(EntryProcessor[V]):\n    \"\"\"\n    `ConditionalRemove` is an `EntryProcessor` that performs n remove operation if the specified condition is satisfied.\n\n    While the `ConditionalRemove` processing could be implemented via direct key-based `NamedMap` operations, it is more\n    efficient and enforces concurrency control without explicit locking.\n    \"\"\"\n\n    def __init__(self, filter: Filter, return_value: bool = False):\n        \"\"\"\n        Construct a :class:`coherence.processor.ConditionalRemove` processor that removes an\n        :class:`coherence.client.NamedMap` entry if and only if the filter applied to the entry evaluates to `True`.\n\n        This processor may optionally return the current value as a result of\n        the invocation if it has not been removed (the :class:`coherence.filter.Filter` evaluated to\n        `False`).\n\n        :param filter: the filter to evaluate an entry\n        :param return_value: specifies whether the processor should return the current value if it has not\n         been removed\n        \"\"\"\n        super().__init__()\n        self.filter = filter\n        self.return_value = return_value\n\n\n@proxy(\"processor.MethodInvocationProcessor\")\nclass MethodInvocationProcessor(EntryProcessor[R]):\n    \"\"\"\n    An :class:`coherence.processor.EntryProcessor` that invokes the specified method on a value of a cache entry\n    and optionally updates the entry with a modified value.\n    \"\"\"\n\n    def __init__(self, method_name: str, mutator: bool, *args: Any):\n        \"\"\"\n        Construct :class:`coherence.processor.MethodInvoctionProcessor` instance.\n\n        :param method_name: the name of the method to invoke\n        :param mutator: the flag specifying whether the method mutates the state of a target object, which implies\n         that the entry value should be updated after method invocation\n        :param args: the method arguments\n        \"\"\"\n        super().__init__()\n        self.methodName = method_name\n        self.mutator = mutator\n        self.args: List[Any] = list(*args)\n\n\n@proxy(\"processor.TouchProcessor\")\nclass TouchProcessor(EntryProcessor[None]):\n    \"\"\"\n    Touches an entry (if present) in order to trigger interceptor re-evaluation and possibly increment expiry time.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Construct a `TouchProcessor`\n        \"\"\"\n        super().__init__()\n\n\n@proxy(\"processor.ScriptProcessor\")\nclass ScriptProcessor(EntryProcessor[Any]):\n    \"\"\"\n    ScriptProcessor wraps a script written in one of the languages supported by Graal VM.\n    \"\"\"\n\n    def __init__(self, name: str, language: str, *args: Any):\n        \"\"\"\n        Create a :class:`coherence.processor.ScriptProcessor` that wraps a script written in the specified language\n        and identified by the specified name. The specified args will be passed during execution of the script.\n\n        :param name: the name of the :class:`coherence.processor.EntryProcessor` that needs to be executed\n        :param language: the language the script is written. Currently, only `js` (for JavaScript) is supported\n        :param args: the arguments to be passed to the :class:`coherence.processor.EntryProcessor`\n        \"\"\"\n        super().__init__()\n        self.name = name\n        self.language = language\n        self.args: List[Any] = list(*args)\n\n\n@proxy(\"processor.PreloadRequest\")\nclass PreloadRequest(EntryProcessor[None]):\n    \"\"\"\n    `PreloadRequest` is a simple :class:`coherence.processor.EntryProcessor` that performs\n    a get call. No results are reported back to the caller.\n\n    The :class:`coherence.processor.PreloadRequest` process provides a means to \"preload\" an entry or a collection\n    of entries into the cache using the cache loader without incurring the cost of sending the value(s) over the\n    network. If the corresponding entry (or entries) already exists in the cache, or if the cache does not have a\n    loader, then invoking this :class:`coherence.processor.EntryProcessor` has no effect.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Construct a PreloadRequest EntryProcessor.\n        \"\"\"\n        super().__init__()\n\n\n@proxy(\"processor.UpdaterProcessor\")\nclass UpdaterProcessor(EntryProcessor[bool]):\n    \"\"\"\n    `UpdaterProcessor` is an :class:`coherence.processor.EntryProcessor` implementations that updates an attribute\n    of an object cached in an InvocableMap.\n\n    While it's possible to update a value via standard Map API, using the updater allows for clustered caches using\n    the UpdaterProcessor allows avoiding explicit concurrency control and could significantly reduce the amount of\n    network traffic.\n    \"\"\"\n\n    def __init__(self, updater_or_property_name: UpdaterExpression[V, bool], value: V):\n        \"\"\"\n        Construct an `UpdaterProcessor` based on the specified ValueUpdater.\n\n        :param updater_or_property_name: a ValueUpdater object or the method name; passing null will simpy replace\n         the entry's value with the specified one instead of updating it\n        :param value: the value to update the target entry with\n        \"\"\"\n        super().__init__()\n        if type(updater_or_property_name) == str:  # noqa: E721\n            self.updater: ValueUpdater[V, bool]\n            if updater_or_property_name.find(\".\") == -1:\n                self.updater = UniversalUpdater(updater_or_property_name)\n            else:\n                self.updater = CompositeUpdater(updater_or_property_name)\n        else:\n            self.updater = cast(ValueUpdater[V, bool], updater_or_property_name)\n        self.value = value\n\n\n@proxy(\"processor.VersionedPut\")\n@mappings({\"return_current\": \"return\"})\nclass VersionedPut(EntryProcessor[V]):\n    \"\"\"\n    `VersionedPut` is an :class:`coherence.processor.EntryProcessor` that assumes that entry values are versioned (see\n    Coherence Versionable interface for details) and performs an update/insert operation if and only if the version\n    of the specified value matches the version of the corresponding value. `VersionedPutAll` will increment the\n    version indicator before each value is updated.\n    \"\"\"\n\n    def __init__(self, value: V, allow_insert: bool = False, return_current: bool = False):\n        \"\"\"\n        Construct a `VersionedPut` that updates an entry with a new value if and only if the version of the new value\n        matches to the version of the current entry's value. This processor optionally returns the current value as a\n        result of the invocation if it has not been updated (the versions did not match).\n\n        :param value: a value to update an entry with\n        :param allow_insert: specifies whether an insert should be allowed (no currently existing value)\n        :param return_current: specifies whether the processor should return the current value in case it has\n         not been updated\n        \"\"\"\n        super().__init__()\n        self.value = value\n        self.allowInsert = allow_insert\n        self.return_current = return_current\n\n\n@proxy(\"processor.VersionedPutAll\")\n@mappings({\"return_current\": \"return\"})\nclass VersionedPutAll(EntryProcessor[V]):\n    \"\"\"\n    `VersionedPutAll` is an :class:`coherence.processor.EntryProcessor` that assumes that entry values are versioned (\n    see Coherence Versionable interface for details) and performs an update/insert operation only for entries whose\n    versions match to versions of the corresponding current values. In case of the match, the `VersionedPutAll` will\n    increment the version indicator before each value is updated.\n    \"\"\"\n\n    def __init__(self, values: dict[K, V], allow_insert: bool = False, return_current: bool = False):\n        \"\"\"\n        Construct a VersionedPutAll processor that updates an entry with a new value if and only if the version of\n        the new value matches to the version of the current entry's value (which must exist). This processor\n        optionally returns a map of entries that have not been updated (the versions did not match).\n\n        :param values: a `dict` of values to update entries with\n        :param allow_insert: specifies whether an insert should be allowed (no currently existing value)\n        :param return_current: specifies whether the processor should return the current value in case it has\n         not been updated\n        \"\"\"\n        super().__init__()\n        self.entries = values\n        self.allowInsert = allow_insert\n        self.return_current = return_current\n\n\nclass Processors:\n    \"\"\"\n    The `Processors` class provides a set of static methods for creating standard Coherence\n    :class:`coherence.processor.EntryProcessor`'s.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Raises `NotImplementedError` if called.\n        \"\"\"\n        raise NotImplementedError()\n\n    @staticmethod\n    def conditional_put(filter: Filter, value: V, return_value: bool = False) -> EntryProcessor[V]:\n        \"\"\"\n        Construct a :class:`coherence.processor.ConditionalPut` that updates an entry with a new value if and only\n        if the :class:`coherence.filter.Filter` applied to the entry evaluates to `True`.\n\n         :param filter: the :class:`coherence.filter.Filter` to evaluate an entry\n         :param value: a value to update an entry with\n         :param return_value: specifies whether the processor should return the current value in case it\n                has not been updated\n         :return: a processor that updates an entry with a new value if and only if the filter applied\n                  to the entry evaluates to `True`.\n        \"\"\"\n        return ConditionalPut(filter, value, return_value)\n\n    @staticmethod\n    def conditional_put_all(filter: Filter, values: dict[K, V]) -> EntryProcessor[V]:\n        \"\"\"\n        Construct a :class:`coherence.processor.ConditionalRemove` processor that updates an entry with a new value if\n        and only if the :class:`coherence.filter.Filter` applied to the entry evaluates to `True`. The new value is\n        extracted from the specified map based on the entry's key.\n\n        :param filter: the :class:`coherence.filter.Filter` to evaluate all supplied entries\n        :param values: a `dict` of values to update entries with\n        :return: a processor that updates one or more entries with the provided values if and only if the\n                 filter applied to the entry evaluates to `True`\n        \"\"\"\n        return ConditionalPutAll(filter, values)\n\n    @staticmethod\n    def conditional_remove(filter: Filter, return_value: bool = False) -> EntryProcessor[V]:\n        \"\"\"\n        Constructs a :class:`coherence.processor.ConditionalRemove` processor that removes an\n        :class:`coherence.client.NamedMap` entry if and only if the :class:`coherence.filter.Filter`\n        applied to the entry evaluates to `True`.\n\n        This processor may optionally return the current value as a result of\n        the invocation if it has not been removed (the :class:`coherence.filter.Filter` evaluated to\n        `False`).\n\n        :param filter: the :class:`coherence.filter.Filter` to evaluate an entry\n        :param return_value: specifies whether the processor should return the current value if it has not\n         been removed\n        \"\"\"\n        return ConditionalRemove(filter, return_value)\n\n    @staticmethod\n    def extract(extractor: Optional[ExtractorExpression[T, E]] = None) -> EntryProcessor[E]:\n        \"\"\"\n        Construct an :class:`coherence.processor.ExtractorProcessor` using the given\n        :class:`coherence.extractor.ValueExtractor` or string expression to extract a value from an object cached\n        within a :class:`coherence.client.NamedMap`.\n\n        For clustered caches using the :class:`coherence.processor.ExtractorProcessor` could significantly reduce\n        the amount of network traffic.\n\n        :param extractor: the :class:`coherence.extractor.ValueExtractor` or string expression to use by this\n                          processor or the name of the method to invoke via java reflection.  If `None`, an\n                          :class:`coherence.extractor.IdentityExtractor` will be used.\n        \"\"\"\n        ext: ExtractorExpression[T, E] = extractor if extractor is not None else Extractors.identity()\n        return ExtractorProcessor(ext)\n\n    @staticmethod\n    def increment(\n        name_or_manipulator: ManipulatorExpression[T, E], increment: Numeric, post_increment: bool = False\n    ) -> EntryProcessor[Numeric]:\n        \"\"\"\n        Construct an :class:`coherence.processor.NumberIncrementor` processor that will increment a property\n        value by a specified amount, returning either the old or the new value as specified.\n\n        :param name_or_manipulator: the :class:`coherence.extractor.ValueManipulator` or string expression\n        :param increment: the numeric value representing the magnitude and sign of the increment\n        :param post_increment: pass `True` to return the value as it was before it was incremented, or pass `False`\n         to return the value as it is after it is incremented\n        :return:\n        \"\"\"\n        return NumberIncrementor(name_or_manipulator, increment, post_increment)\n\n    @staticmethod\n    def invoke_accessor(method_name: str, *args: Any) -> EntryProcessor[R]:\n        \"\"\"\n        Constructs a :class:`coherence.processor.MethodInvocationProcessor` that invokes the specified method on\n         a value of a cache entry.\n\n        :param method_name: the name of the method to invoke\n        :param args: the method arguments\n        :return: a :class:`coherence.processor.MethodInvocationProcessor` that invokes the specified method on\n                 a value of a cache entry and optionally updates the entry with a modified value\n        \"\"\"\n        return MethodInvocationProcessor(method_name, False, args)\n\n    @staticmethod\n    def invoke_mutator(method_name: str, *args: Any) -> EntryProcessor[R]:\n        \"\"\"\n        Constructs a :class:`coherence.processor.MethodInvocationProcessor` that invokes the specified method on\n        a value of a cache entry updating the entry with a modified value.\n\n        :param method_name: the name of the method to invoke\n        :param args: the method arguments\n        :return: a :class:`coherence.processor.MethodInvocationProcessor` that invokes the specified method on\n                 a value of a cache entry and optionally updates the entry with a modified value\n        \"\"\"\n        return MethodInvocationProcessor(method_name, True, args)\n\n    @staticmethod\n    def multiply(\n        name_or_manipulator: ManipulatorExpression[T, E], multiplier: Numeric, post_multiplication: bool = False\n    ) -> EntryProcessor[Numeric]:\n        \"\"\"\n        Construct an NumberMultiplier processor that will multiply a property value by a specified factor,\n        returning either the old or the new value as specified.\n\n        :param name_or_manipulator: the ValueManipulator or the property name\n        :param multiplier: the Number representing the magnitude and sign of the multiplier\n        :param post_multiplication: pass `True` to return the value as it was before it was multiplied, or pass `False`\n         to return the value as it is after it is multiplied\n        \"\"\"\n        return NumberMultiplier(name_or_manipulator, multiplier, post_multiplication)\n\n    @staticmethod\n    def nop() -> EntryProcessor[bool]:\n        \"\"\"\n        Construct an :class:`coherence.processor.EntryProcessor` that does nothing and returns `True`\n        as a result of execution\n        :return: an :class:`coherence.processor.EntryProcessor` that does nothing and returns `True`\n        as a result of execution\n        \"\"\"\n        return NullProcessor()\n\n    @staticmethod\n    def preload() -> EntryProcessor[None]:\n        \"\"\"\n        :class:`coherence.processor.PreloadRequest` is a simple :class:`coherence.processor.EntryProcessor` that\n        performs a get call. No results are reported back to the caller.\n\n        The :class:`coherence.processor.PreloadRequest` process provides a means to \"preload\" an entry or a\n        collection of entries into the cache using the cache loader without incurring the cost of sending the\n        value(s) over the network. If the corresponding entry (or entries) already exists in the cache,\n        or if the cache does not have a loader, then invoking this :class:`coherence.processor.PreloadRequest`\n        has no effect.\n        :return:\n        \"\"\"\n        return PreloadRequest()\n\n    @staticmethod\n    def script(name: str, language: str, *args: Any) -> EntryProcessor[Any]:\n        \"\"\"\n        Create a :class:`coherence.processor.ScriptProcessor` that wraps a script written in the specified language\n        and identified by the specified name. The specified args will be passed during execution of the script.\n\n        :param name: the name of the :class:`coherence.processor.EntryProcessor` that needs to be executed\n        :param language: the language the script is written. Currently, only `js` (for JavaScript) is supported\n        :param args: the arguments to be passed to the :class:`coherence.processor.EntryProcessor`\n        \"\"\"\n        return ScriptProcessor(name, language, args)\n\n    @staticmethod\n    def touch() -> EntryProcessor[None]:\n        \"\"\"\n        Creates an :class:`coherence.processor.EntryProcessor` that touches an entry (if present) in order to\n        trigger interceptor re-evaluation and possibly increment expiry time.\n        :return:\n        \"\"\"\n        return TouchProcessor()\n\n    @staticmethod\n    def update(updater_or_property_name: UpdaterExpression[V, bool], value: V) -> EntryProcessor[bool]:\n        \"\"\"\n        Construct an :class:`coherence.processor.UpdaterProcessor` based on the specified `ValueUpdater`.\n\n        While it's possible to update a value via standard Map API, using the updater allows for clustered caches using\n        the `UpdaterProcessor` allows avoiding explicit concurrency control and could significantly reduce the amount of\n        network traffic.\n\n        :param updater_or_property_name: a ValueUpdater object or the method name; passing null will simpy replace\n         the entry's value with the specified one instead of updating it\n        :param value: the value to update the target entry with\n        \"\"\"\n        return UpdaterProcessor(updater_or_property_name, value)\n\n    @staticmethod\n    def versioned_put(value: V, allow_insert: bool = False, return_current: bool = False) -> EntryProcessor[V]:\n        \"\"\"\n        Construct a :class:`coherence.processor.VersionedPut` that updates an entry with a new value if and only\n        if the version of the new value matches to the version of the current entry's value. This processor optionally\n        returns the current value as a result of the invocation if it has not been updated (the versions did not match).\n\n        :param value: a value to update an entry with\n        :param allow_insert: specifies whether an insert should be allowed (no currently existing value)\n        :param return_current: specifies whether the processor should return the current value in case it has\n         not been updated\n        \"\"\"\n        return VersionedPut(value, allow_insert, return_current)\n\n    @staticmethod\n    def versioned_put_all(\n        values: dict[K, V], allow_insert: bool = False, return_current: bool = False\n    ) -> EntryProcessor[V]:\n        \"\"\"\n        Construct a :class:`coherence.processor.VersionedPut` processor that updates an entry with a new value if\n        and only if the version of the new value matches to the version of the current entry's value\n        (which must exist). This processor optionally returns a map of entries that have not been updated\n        (the versions did not match).\n\n        :param values: a `dict` of values to update entries with\n        :param allow_insert: specifies whether an insert should be allowed (no currently existing value)\n        :param return_current: specifies whether the processor should return the current value in case it has\n         not been updated\n        \"\"\"\n        return VersionedPutAll(values, allow_insert, return_current)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/processor.py b/src/coherence/processor.py
--- a/src/coherence/processor.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/src/coherence/processor.py	(date 1726012780645)
@@ -62,8 +62,8 @@
         applied to the entry evaluates to `true`; otherwise the
         result of the invocation will return `None`.
 
-        :param filter: the filter :return: Returns a :class:`coherence.processor.ConditionalProcessor` comprised of
-         this processor and the provided filter.
+        :param filter: the filter :return: Returns a :class:`coherence.processor.ConditionalProcessor` comprised
+         of this processor and the provided filter.
         """
         return ConditionalProcessor(filter, self)
 
Index: src/coherence/event.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom abc import ABCMeta, abstractmethod\nfrom asyncio import Event, Task\nfrom enum import Enum, unique\nfrom typing import Callable, Generic, Optional, Set, TypeVar, cast\n\n# noinspection PyPackageRequirements\nimport grpc\nfrom pymitter import EventEmitter\n\nimport coherence.client\n\nfrom .filter import Filter, Filters, MapEventFilter\nfrom .messages_pb2 import MapEventResponse, MapListenerRequest, MapListenerResponse\nfrom .serialization import Serializer\nfrom .services_pb2_grpc import NamedCacheServiceStub\nfrom .util import RequestFactory\n\nK = TypeVar(\"K\")\n\"\"\"the type of the map entry keys.\"\"\"\n\nV = TypeVar(\"V\")\n\"\"\"the type of the map entry values.\"\"\"\n\n\n@unique\nclass MapEventType(Enum):\n    \"\"\"Enum of possible events that could raise a MapEvent.\"\"\"\n\n    ENTRY_INSERTED = \"insert\"\n    \"\"\"This event indicates that an entry has been added to the cache.\"\"\"\n\n    ENTRY_UPDATED = \"update\"\n    \"\"\"This event indicates that an entry has been updated in the cache.\"\"\"\n\n    ENTRY_DELETED = \"delete\"\n    \"\"\"This event indicates that an entry has been removed from the cache.\"\"\"\n\n\n@unique\nclass MapLifecycleEvent(Enum):\n    \"\"\"Enum of possible events that may be raised at different\n    points of the cache lifecycle.\"\"\"\n\n    DESTROYED = \"map_destroyed\"\n    \"\"\"Raised when a storage for a given cache is destroyed\n     (usually as a result of a call to NamedMap.destroy()).\"\"\"\n\n    TRUNCATED = \"map_truncated\"\n    \"\"\"Raised when a storage for a given cache is truncated\n     as a result of a call to NamedMap.truncate().\"\"\"\n\n    RELEASED = \"map_released\"\n    \"\"\"Raised when the local resources for a cache has been\n    released as a result of a call to NamedMap.release().\n    Entries within the cache remain untouched\"\"\"\n\n\n@unique\nclass SessionLifecycleEvent(Enum):\n    \"\"\"Enum of possible events that may be raised at different\n    points of the session lifecycle.\"\"\"\n\n    CONNECTED = \"session_connected\"\n    \"\"\"Raised when the session has connected.\"\"\"\n\n    DISCONNECTED = \"session_disconnected\"\n    \"\"\"Raised when the session has disconnected.\"\"\"\n\n    RECONNECTED = \"session_reconnected\"\n    \"\"\"Raised when the session has re-connected.\"\"\"\n\n    CLOSED = \"session_closed\"\n    \"\"\"Raised when the session has been closed.\"\"\"\n\n\nclass MapEvent(Generic[K, V]):\n    \"\"\"An event which indicates that the content of a map has changed:\n\n    * an entry has been added\n    * an entry has been removed\n    * an entry has been changed\n    \"\"\"\n\n    def __init__(\n        self, source: coherence.client.NamedMap[K, V], response: MapEventResponse, serializer: Serializer\n    ) -> None:\n        \"\"\"\n        Constructs a new MapEvent.\n        :param source:      the event source\n        :param response:    the MapListenerResponse sent from the server\n        :param serializer:  the Serializer that should be used to deserialize event keys and values\n        \"\"\"\n        self._key: Optional[K] = None\n        self._new_value: Optional[V] = None\n        self._old_value: Optional[V] = None\n        self._id: MapEventType = self._from_event_id(response.id)\n        self._name: str = source.name\n        self._source: coherence.client.NamedMap[K, V] = source\n        self._serializer: Serializer = serializer\n        self._key_bytes: bytes = response.key\n        self._new_value_bytes: bytes = response.newValue\n        self._old_value_bytes: bytes = response.oldValue\n\n    @property\n    def source(self) -> coherence.client.NamedMap[K, V]:\n        \"\"\"\n        The source of the event.\n        :return: the event source\n        \"\"\"\n        return self._source\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The name of the cache from which the event originated.\n        :return:  the cache name from which the event originated\n        \"\"\"\n        return self._name\n\n    @property\n    def description(self) -> str:\n        \"\"\"\n        Returns the event's description.\n        :return: the event's description\n        \"\"\"\n        if self.type == MapEventType.ENTRY_INSERTED:\n            return \"insert\"\n        elif self.type == MapEventType.ENTRY_UPDATED:\n            return \"update\"\n        elif self.type == MapEventType.ENTRY_DELETED:\n            return \"delete\"\n        else:\n            return \"unknown\"\n\n    @property\n    def type(self) -> MapEventType:\n        \"\"\"\n        The MapEventType.  This may be one of:\n        * MapEventType.ENTRY_INSERTED\n        * MapEventType.ENTRY_UPDATED\n        * MapEventType.ENTRY_DELETED\n        :return: the event type\n        \"\"\"\n        return self._id\n\n    @property\n    def key(self) -> K:\n        \"\"\"\n        Return the key for the entry generating the event.\n        :return: the key for the entry generating the event\n        \"\"\"\n        if self._key is None:\n            self._key = self._serializer.deserialize(self._key_bytes)\n\n        return self._key\n\n    @property\n    def new(self) -> Optional[V]:\n        \"\"\"\n        Return the new value for the entry generating the event.\n        :return: the new value, if any, for the entry generating the event\n        \"\"\"\n        if self._new_value is None and self._new_value_bytes is not None:\n            self._new_value = self._serializer.deserialize(self._new_value_bytes)\n\n        return self._new_value\n\n    @property\n    def old(self) -> Optional[V]:\n        \"\"\"\n        Return the old value for the entry generating the event.\n        :return:the old value, if any, for the entry generating the event\n        \"\"\"\n        if self._old_value is None and self._old_value_bytes is not None:\n            self._old_value = self._serializer.deserialize(self._old_value_bytes)\n\n        return self._old_value\n\n    def __str__(self) -> str:\n        \"\"\"\n        Returns a string representation of this event.\n        :return: a string representation of this event\n        \"\"\"\n        return (\n            \"MapEvent{\"\n            + str(self.type.name)\n            + \", cache=\"\n            + self.name\n            + \", key=\"\n            + str(self.key)\n            + \", old=\"\n            + str(self.old)\n            + \", new=\"\n            + str(self.new)\n            + \"}\"\n        )\n\n    @staticmethod\n    def _from_event_id(_id: int) -> MapEventType:\n        \"\"\"Return the MapEventType based on the on-wire value for the event.\"\"\"\n        if _id == 1:\n            return MapEventType.ENTRY_INSERTED\n        elif _id == 2:\n            return MapEventType.ENTRY_UPDATED\n        elif _id == 3:\n            return MapEventType.ENTRY_DELETED\n        else:\n            raise RuntimeError(\"Unhandled MapEventType [\" + str(_id) + \"]\")\n\n\nMapListenerCallback = Callable[[MapEvent[K, V]], None]\n\"\"\"A type alias for MapEventListener callback functions.\"\"\"\n\n\nclass MapListener(Generic[K, V]):\n    \"\"\"A listener interface for receiving MapEvents.\"\"\"\n\n    _emitter: EventEmitter\n    \"\"\"The internal emitter used to emit events.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Constructs a new MapListener.\"\"\"\n        self._emitter = EventEmitter()\n\n    def _on(self, event: MapEventType, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Define a callback for the specified event type.\n\n        :param event:     the event type of interest\n        :param callback:  the callback that will be invoked when the specified event has occurred\n        \"\"\"\n        self._emitter.on(str(event.value), callback)\n        return self\n\n    def on_inserted(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when an insertion event has occurred.\n\n        :param callback:  the callback that will be invoked when an insertion event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_INSERTED, callback)\n\n    def on_updated(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when an update event has occurred.\n\n        :param callback:  the callback that will be invoked when an update event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_UPDATED, callback)\n\n    def on_deleted(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when a deletion event has occurred.\n\n        :param callback:  the callback that will be invoked when a deletion event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_DELETED, callback)\n\n    def on_any(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when any entry event has occurred.\n\n        :param callback:  the callback that will be invoked when a deletion event has occurred\n        \"\"\"\n        return self.on_deleted(callback).on_updated(callback).on_inserted(callback)\n\n\nclass _ListenerGroup(Generic[K, V], metaclass=ABCMeta):\n    \"\"\"Manages a collection of MapEventListeners that will be notified when an event is raised.\n    This also manages the on-wire activities for registering/deregistering a listener with the\n    gRPC proxy.\"\"\"\n\n    _key_or_filter: K | Filter\n    \"\"\"The key or Filter for which this group of listeners will receive events.\"\"\"\n\n    _registered_lite: bool\n    \"\"\"The flag indicating if any listeners have been registered as lite.\"\"\"\n\n    _listeners: dict[MapListener[K, V], bool]\n    \"\"\"A map of listeners and associated lite flag.\"\"\"\n\n    _lite_false_count: int\n    \"\"\"The number of callbacks that aren't lite.\"\"\"\n\n    _manager: _MapEventsManager[K, V]\n    \"\"\"The associated MapEventsManager for this group.\"\"\"\n\n    _request: MapListenerRequest\n    \"\"\"The subscription request.  A reference is maintained for unsubscribe purposes.\"\"\"\n\n    _subscription_waiter: Event\n    \"\"\"Used by a caller to be notified when the listener subscription as been completed.\"\"\"\n\n    _unsubscription_waiter: Event\n    \"\"\"Used by a caller to be notified when the listener unsubscribe as been completed.\"\"\"\n\n    def _init_(self, manager: _MapEventsManager[K, V], key_or_filter: K | Filter) -> None:\n        \"\"\"\n        Constructs a new _ListenerGroup.\n        :param manager:        the _MapEventManager\n        :param key_or_filter:  the key or filter for this group of listeners\n        :raises ValueError:    if either `manager` or `key_or_filter` is `None`\n        \"\"\"\n        if manager is None:\n            raise ValueError(\"Argument `manager` must not be None\")\n        if key_or_filter is None:\n            raise ValueError(\"Argument `key_or_filter` must not be None\")\n\n        self._manager = manager\n        self._key_or_filter = key_or_filter\n        self._listeners = {}\n        self._lite_false_count = 0\n        self._registered_lite = False\n        self._subscribed_waiter = Event()\n        self._unsubscribed_waiter = Event()\n\n    async def add_listener(self, listener: MapListener[K, V], lite: bool) -> None:\n        \"\"\"\n        Add a callback to this group. This causes a subscription message to be sent through the stream\n        if (a) either this is the first callback, or (b) the lite param is false but all\n        the previous callback have lite == True.\n        :param listener:  the MapListener to add/subscribe\n        :param lite:      `True` if the event should only include the key, or `False`\n                           if the event should include old and new values as well as the key\n        \"\"\"\n        listeners: dict[MapListener[K, V], bool] = self._listeners\n        prev_lite_status: Optional[bool] = listeners.get(listener, None)\n        if prev_lite_status is not None and prev_lite_status == lite:\n            return\n\n        listeners[listener] = lite\n\n        if not lite:\n            self._lite_false_count += 1\n\n        size: int = len(listeners)\n        requires_registration: bool = size == 1 or self._registered_lite and not lite\n\n        if requires_registration:\n            self._registered_lite = lite\n            if size > 1:\n                await self._unsubscribe()\n\n            await self._subscribe(lite)\n\n    async def remove_listener(self, listener: MapListener[K, V]) -> None:\n        \"\"\"\n        Remove the specified listener from this group.\n        :param listener:  the listener to remove\n        \"\"\"\n        listeners: dict[MapListener[K, V], bool] = self._listeners\n        prev_lite_status: Optional[bool] = self._listeners.get(listener, None)\n        if prev_lite_status is not None and prev_lite_status or len(listeners) == 0:\n            return\n\n        del listeners[listener]\n\n        if len(listeners) == 0:\n            await self._unsubscribe()\n            return\n\n        if not prev_lite_status:\n            self._lite_false_count -= 1\n\n            if self._lite_false_count == 0:\n                await self._unsubscribe()\n                await self._subscribe(True)\n\n    # noinspection PyProtectedMember\n    async def _write(self, request: MapListenerRequest) -> None:\n        \"\"\"Write the request to the event stream.\"\"\"\n        event_stream: grpc.aio.StreamStreamCall = await self._manager._ensure_stream()\n        await event_stream.write(request)\n\n    # noinspection PyProtectedMember\n    async def _subscribe(self, lite: bool) -> None:\n        \"\"\"\n        Send a gRPC MapListener subscription request for a key or filter.\n        :param lite:  `True` if the event should only include the key, or `False`\n                      if the event should include old and new values as well as the key\n        \"\"\"\n        request: MapListenerRequest\n        if isinstance(self._key_or_filter, Filter):\n            request = self._manager._request_factory.map_listener_request(True, lite, filter=self._key_or_filter)\n        else:\n            request = self._manager._request_factory.map_listener_request(True, lite, key=self._key_or_filter)\n\n        self._request = request\n\n        # set this registration as pending\n        self._manager._pending_registrations[request.uid] = self\n\n        await self._write(request)\n\n        await self._subscribed_waiter.wait()\n        self._subscribed_waiter.clear()\n\n    # noinspection PyProtectedMember\n    def _subscribe_complete(self) -> None:\n        \"\"\"Called when the response to the subscription request has been received.\"\"\"\n\n        # no longer pending\n        del self._manager._pending_registrations[self._request.uid]\n        self._post_subscribe(self._request)\n\n        # notify caller that subscription is active\n        self._subscribed_waiter.set()\n\n    # noinspection PyProtectedMember\n    async def _unsubscribe(self) -> None:\n        \"\"\"\n        Send a gRPC MapListener request to unsubscribe a listener for a key or filter.\n        \"\"\"\n\n        request: MapListenerRequest\n        if isinstance(self._key_or_filter, MapEventFilter):\n            request = self._manager._request_factory.map_listener_request(False, filter=self._key_or_filter)\n        else:\n            request = self._manager._request_factory.map_listener_request(False, key=self._key_or_filter)\n\n        request.filterId = self._request.filterId\n        await self._write(request)\n        self._post_unsubscribe(request)\n\n    # noinspection PyProtectedMember\n    def _notify_listeners(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Notify all listeners within this group of the provided event.\n        :param event:\n        \"\"\"\n        event_label: str = self._get_emitter_label(event)\n        listener: MapListener[K, V]\n        for listener in self._listeners.keys():\n            listener._emitter.emit(event_label, event)\n\n    # noinspection PyProtectedMember\n    @staticmethod\n    def _get_emitter_label(event: MapEvent[K, V]) -> str:\n        \"\"\"\n        The string label required by the internal event emitter.\n        :param event:  the MapEvent whose label will be generated\n        :return: the emitter-friendly event label\n        \"\"\"\n        if event.type == MapEventType.ENTRY_DELETED:\n            return MapEventType.ENTRY_DELETED.value\n        elif event.type == MapEventType.ENTRY_INSERTED:\n            return MapEventType.ENTRY_INSERTED.value\n        elif event.type == MapEventType.ENTRY_UPDATED:\n            return MapEventType.ENTRY_UPDATED.value\n        else:\n            raise AssertionError(f\"Unknown EventType [{event}]\")\n\n    @abstractmethod\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        \"\"\"\n        Custom actions that implementations may need to make after a subscription has been completed.\n        :param request:  the request that was used to subscribe\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        \"\"\"\n        Custom actions that implementations may need to make after an unsubscription has been completed.\n        :param request:  the request that was used to unsubscribe\n        \"\"\"\n        pass\n\n\nclass _KeyListenerGroup(_ListenerGroup[K, V]):\n    \"\"\"A ListenerGroup for key-based MapListeners\"\"\"\n\n    def __init__(self, manager: _MapEventsManager[K, V], key: K) -> None:\n        \"\"\"\n        Creates a new _KeyListenerGroup\n        :param manager:  the _MapEventManager\n        :param key:      the group key\n        \"\"\"\n        super()._init_(manager, key)\n\n    # noinspection PyProtectedMember\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        manager: _MapEventsManager[K, V] = self._manager\n        key: K = manager._serializer.deserialize(request.key)\n        self._manager._key_group_subscribed(key, self)\n\n    # noinspection PyProtectedMember\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        manager: _MapEventsManager[K, V] = self._manager\n        key: K = manager._serializer.deserialize(request.key)\n        manager._key_group_unsubscribed(key)\n\n\nclass _FilterListenerGroup(_ListenerGroup[K, V]):\n    \"\"\"A ListenerGroup for Filter-based MapListeners\"\"\"\n\n    def __init__(self, manager: _MapEventsManager[K, V], filter: Filter) -> None:\n        \"\"\"\n        Creates a new _KeyListenerGroup\n        :param manager:  the _MapEventManager\n        :param filter:   the group Filter\n        \"\"\"\n        super()._init_(manager, filter)\n\n    # noinspection PyProtectedMember\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        self._manager._filter_group_subscribed(request.filterId, cast(Filter, self._key_or_filter), self)\n\n    # noinspection PyProtectedMember\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        self._manager._filter_group_unsubscribed(request.filterId, cast(Filter, self._key_or_filter))\n\n\nclass _MapEventsManager(Generic[K, V]):\n    \"\"\"MapEventsManager handles registration, de-registration of callbacks, and\n    notification of {@link MapEvent}s to callbacks. Since multiple callbacks can\n    be registered for a single key / filter, this class relies on another internal\n    class called ListenerGroup which maintains the collection of callbacks.\n\n    There are two maps that are maintained:\n\n    1. A Map of string keys mapped to a ListenerGroup, which is used to identify\n       thd group of callbacks for a single key.\n    2. A Map of filter => ListenerGroup that is used to identify the group of callbacks\n       for a MapEventFilter.\n\n    When a filter is subscribed, the server responds with a unique filterID.This filterID\n    is what is specified is a MapEvent. So, this class maintains a third Map of\n    filterID to ListenerGroup for efficiently identifying the ListenerGroup for a filterID.\n    \"\"\"\n\n    _DEFAULT_FILTER: MapEventFilter[K, V] = MapEventFilter.from_filter(Filters.always())\n    \"\"\"The default filter to use if none is specified.\"\"\"\n\n    _named_map: coherence.client.NamedMap[K, V]\n    \"\"\"the NamedMap that is to be the source of the events.\"\"\"\n\n    _client: NamedCacheServiceStub\n    \"\"\"the gRPC cache client.\"\"\"\n\n    _serializer: Serializer\n    \"\"\"the Serializer to applied to in and outbound payloads.\"\"\"\n\n    _emitter: EventEmitter\n    \"\"\"the EventEmitter that will be used to emit MapEvents.\"\"\"\n\n    _map_name: str\n    \"\"\"The logical name of the provided NamedMap.\"\"\"\n\n    _key_map: dict[K, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a key and its group of MapListeners.\"\"\"\n\n    _filter_map: dict[Filter, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a Filter and its group of MapListeners.\"\"\"\n\n    _filter_id_listener_group_map: dict[int, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a logical filter ID and its ListenerGroup.\"\"\"\n\n    _request_factory: RequestFactory\n    \"\"\"The RequestFactory used to obtain the necessary gRPC requests.\"\"\"\n\n    _event_stream: Optional[grpc.aio.StreamStreamCall]\n    \"\"\"gRPC bidirectional stream for subscribing/unsubscribing MapListeners and receiving MapEvents from\n       the proxy.\"\"\"\n\n    _open: bool\n    \"\"\"\"Flag indicating the event stream is open and ready for listener registrations and\n    incoming events.\"\"\"\n\n    _pending_registrations: dict[str, _ListenerGroup[K, V]]\n    \"\"\"The mapping of pending listener registrations keyed by request uid.\"\"\"\n\n    _background_tasks: Set[Task[None]]\n\n    # noinspection PyProtectedMember\n    def __init__(\n        self,\n        named_map: coherence.client.NamedMap[K, V],\n        session: coherence.Session,\n        client: NamedCacheServiceStub,\n        serializer: Serializer,\n        emitter: EventEmitter,\n    ) -> None:\n        \"\"\"\n        Constructs a new _MapEventManager.\n        :param named_map:   the 'source' of the events\n        :param session:     the Session associated with this NamedMap\n        :param client:      the gRPC client\n        :param serializer:  the Serializer that will be used for ser/deser operations\n        :param emitter:     the internal event emitter used to notify registered MapListeners\n        \"\"\"\n        self._named_map = named_map\n        self._client = client\n        self._serializer = serializer\n        self._emitter = emitter\n        self._map_name = named_map.name\n        self._session = session\n\n        self._key_map = {}\n        self._filter_map = {}\n        self._filter_id_listener_group_map = {}\n        self._pending_registrations = {}\n\n        self._request_factory = RequestFactory(self._map_name, session.scope, serializer)\n\n        self._event_stream = None\n        self._open = False\n        self._background_tasks = set()\n        self._stream_waiter = Event()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, self._close)\n\n        # intentionally ignoring the typing here to avoid complicating the\n        # callback API exposed on the session\n        # noinspection PyTypeChecker\n        session.on(SessionLifecycleEvent.RECONNECTED, self._reconnect)\n\n    def _close(self) -> None:\n        \"\"\"Close the gRPC event stream and any background tasks.\"\"\"\n\n        event_stream: grpc.aio.StreamStreamCall = self._event_stream\n        if event_stream is not None:\n            event_stream.cancel()\n            self._event_stream = None\n\n        self._open = False\n        for task in self._background_tasks:\n            task.cancel()\n        self._background_tasks.clear()\n\n    # noinspection PyProtectedMember\n    async def _reconnect(self) -> None:\n        group: _ListenerGroup[K, V]\n        for group in self._key_map.values():\n            await group._subscribe(group._registered_lite)\n\n        for group in self._filter_map.values():\n            await group._subscribe(group._registered_lite)\n\n    async def _ensure_stream(self) -> grpc.aio.StreamStreamCall:\n        \"\"\"\n        Initialize the event stream for MapListener events.\n        \"\"\"\n        if self._event_stream is None:\n            event_stream: grpc.aio.StreamStreamCall = self._client.events()\n            await event_stream.write(self._request_factory.map_event_subscribe())\n            self._event_stream = event_stream\n            read_task: Task[None] = asyncio.create_task(self._handle_response())\n            self._background_tasks.add(read_task)\n            # we use asyncio.timeout here instead of using the gRPC timeout\n            # as any deadline set on the stream will result in a loss of events\n            try:\n                await asyncio.wait_for(self._stream_waiter.wait(), self._session.options.request_timeout_seconds)\n            except TimeoutError:\n                s = (\n                    \"Deadline [{0} seconds] exceeded waiting for event stream\"\n                    \" to become ready. Server address - {1})\".format(\n                        str(self._session.options.request_timeout_seconds), self._session.options.address\n                    )\n                )\n                raise TimeoutError(s)\n\n        return self._event_stream\n\n    async def _register_key_listener(self, listener: MapListener[K, V], key: K, lite: bool = False) -> None:\n        \"\"\"\n        Registers the specified listener to listen for events matching the provided key.\n        :param listener:  the MapListener to register\n        :param key:       the key to listener to\n        :param lite:      `True` if the event should only include the key, or `False`\n                          if the event should include old and new values as well as the key\n        \"\"\"\n        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)\n\n        if group is None:\n            group = _KeyListenerGroup(self, key)\n            self._key_map[key] = group\n\n        await group.add_listener(listener, lite)\n\n    async def _remove_key_listener(self, listener: MapListener[K, V], key: K) -> None:\n        \"\"\"\n        Removes the registration of the listener for the provided key.\n        :param listener:  the MapListener to remove\n        :param key:       they key the listener was associated with\n        \"\"\"\n        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)\n\n        if group is not None:\n            await group.remove_listener(listener)\n\n    async def _register_filter_listener(\n        self, listener: MapListener[K, V], filter: Optional[Filter], lite: bool = False\n    ) -> None:\n        \"\"\"\n        Registers the specified listener to listen for events matching the provided filter.\n        :param listener:  the MapListener to register\n        :param filter:    the Filter associated with the listener\n        :param lite:      `True` if the event should only include the key, or `False`\n                           if the event should include old and new values as well as the key\n        \"\"\"\n        filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER\n        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)\n\n        if group is None:\n            group = _FilterListenerGroup(self, filter_local)\n            self._filter_map[filter_local] = group\n        await group.add_listener(listener, lite)\n\n    async def _remove_filter_listener(self, listener: MapListener[K, V], filter: Optional[Filter]) -> None:\n        \"\"\"\n        Removes the registration of the listener for the provided filter.\n        :param listener:  the MapListener to remove\n        :param filter:    the Filter that was used with the listener registration\n        \"\"\"\n        filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER\n        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)\n\n        if group is not None:\n            await group.remove_listener(listener)\n\n    def _key_group_subscribed(self, key: K, group: _ListenerGroup[K, V]) -> None:\n        \"\"\"\n        Called internally by _KeyListenerGroup when a key listener is subscribed.\n        :param key:    the registration key\n        :param group:  the registered group\n        \"\"\"\n        self._key_map[key] = group\n\n    def _key_group_unsubscribed(self, key: K) -> None:\n        \"\"\"\n        Called internally by _KeyListenerGroup when a listener is unsubscribed.\n        :param key:  the key used at registration\n        \"\"\"\n        del self._key_map[key]\n\n    def _filter_group_subscribed(self, filter_id: int, filter: Filter, group: _ListenerGroup[K, V]) -> None:\n        \"\"\"\n        Called internally by _FilterListenerGroup when a filter listener is subscribed.\n        :param filter_id:  the ID of the filter\n        :param filter:     the Filter associated with the listener registration\n        :param group:      the registered group\n        \"\"\"\n        self._filter_id_listener_group_map[filter_id] = group\n        self._filter_map[filter] = group\n\n    def _filter_group_unsubscribed(self, filter_id: int, filter: Filter) -> None:\n        \"\"\"\n        Called internally by _FilterListenerGroup when a filter listener is unsubscribed.\n        :param filter_id:  the ID of the filter\n        :param filter:     the Filter used at registration\n        \"\"\"\n        del self._filter_id_listener_group_map[filter_id]\n        del self._filter_map[filter]\n\n    # noinspection PyProtectedMember\n    async def _handle_response(self) -> None:\n        \"\"\"\n        Handles reading data from the event stream and invoking the appropriate logic\n        for various MapListenerResponse messages that may be sent by the backend.\n        \"\"\"\n        if not self._open:  # will be triggered on first response\n            event_stream: grpc.aio.StreamStreamCall = await self._ensure_stream()\n            await event_stream.read()\n            self._open = True\n            self._stream_waiter.set()  # notify any callers waiting for stream init\n            self._stream_waiter.clear()\n            try:\n                while self._open:\n                    await asyncio.sleep(0.1)\n                    response: MapListenerResponse = await event_stream.read()\n                    if response.HasField(\"subscribed\"):\n                        subscribed = response.subscribed\n                        group: Optional[_ListenerGroup[K, V]] = self._pending_registrations.get(subscribed.uid, None)\n                        if group is not None:\n                            group._subscribe_complete()\n                    elif response.HasField(\"destroyed\"):\n                        destroyed_cache: str = response.destroyed.cache\n                        if destroyed_cache == self._map_name:\n                            self._emitter.emit(MapLifecycleEvent.DESTROYED.value, self._map_name)\n                    elif response.HasField(\"truncated\"):\n                        truncated_cache: str = response.truncated.cache\n                        if truncated_cache == self._map_name:\n                            self._emitter.emit(MapLifecycleEvent.TRUNCATED.value, self._map_name)\n                    elif response.HasField(\"event\"):\n                        response_event = response.event\n                        event: MapEvent[K, V] = MapEvent(self._named_map, response_event, self._serializer)\n                        for _id in response_event.filterIds:\n                            filter_group: Optional[_ListenerGroup[K, V]] = self._filter_id_listener_group_map.get(\n                                _id, None\n                            )\n                            if filter_group is not None:\n                                filter_group._notify_listeners(event)\n\n                        key_group = self._key_map.get(event.key, None)\n                        if key_group is not None:\n                            key_group._notify_listeners(event)\n            except asyncio.CancelledError:\n                return\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/event.py b/src/coherence/event.py
--- a/src/coherence/event.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/src/coherence/event.py	(date 1726012780643)
@@ -5,11 +5,12 @@
 from __future__ import annotations
 
 import asyncio
-from abc import ABCMeta, abstractmethod
+from abc import ABC, ABCMeta, abstractmethod
 from asyncio import Event, Task
 from enum import Enum, unique
-from typing import Callable, Generic, Optional, Set, TypeVar, cast
+from typing import Any, Callable, Generic, Optional, Set, TypeVar, cast
 
+import cache_service_messages_v1_pb2
 # noinspection PyPackageRequirements
 import grpc
 from pymitter import EventEmitter
@@ -20,7 +21,7 @@
 from .messages_pb2 import MapEventResponse, MapListenerRequest, MapListenerResponse
 from .serialization import Serializer
 from .services_pb2_grpc import NamedCacheServiceStub
-from .util import RequestFactory
+from .util import RequestFactory, RequestFactoryV1
 
 K = TypeVar("K")
 """the type of the map entry keys."""
@@ -28,6 +29,9 @@
 V = TypeVar("V")
 """the type of the map entry values."""
 
+RT = TypeVar("RT")
+"""the gRPC request type."""
+
 
 @unique
 class MapEventType(Enum):
@@ -272,11 +276,7 @@
         return self.on_deleted(callback).on_updated(callback).on_inserted(callback)
 
 
-class _ListenerGroup(Generic[K, V], metaclass=ABCMeta):
-    """Manages a collection of MapEventListeners that will be notified when an event is raised.
-    This also manages the on-wire activities for registering/deregistering a listener with the
-    gRPC proxy."""
-
+class _ListenerGroup(Generic[K, V, RT], metaclass=ABCMeta):
     _key_or_filter: K | Filter
     """The key or Filter for which this group of listeners will receive events."""
 
@@ -289,31 +289,13 @@
     _lite_false_count: int
     """The number of callbacks that aren't lite."""
 
-    _manager: _MapEventsManager[K, V]
-    """The associated MapEventsManager for this group."""
-
-    _request: MapListenerRequest
-    """The subscription request.  A reference is maintained for unsubscribe purposes."""
-
     _subscription_waiter: Event
     """Used by a caller to be notified when the listener subscription as been completed."""
 
     _unsubscription_waiter: Event
     """Used by a caller to be notified when the listener unsubscribe as been completed."""
 
-    def _init_(self, manager: _MapEventsManager[K, V], key_or_filter: K | Filter) -> None:
-        """
-        Constructs a new _ListenerGroup.
-        :param manager:        the _MapEventManager
-        :param key_or_filter:  the key or filter for this group of listeners
-        :raises ValueError:    if either `manager` or `key_or_filter` is `None`
-        """
-        if manager is None:
-            raise ValueError("Argument `manager` must not be None")
-        if key_or_filter is None:
-            raise ValueError("Argument `key_or_filter` must not be None")
-
-        self._manager = manager
+    def __init__(self, key_or_filter: K | Filter):
         self._key_or_filter = key_or_filter
         self._listeners = {}
         self._lite_false_count = 0
@@ -321,6 +303,34 @@
         self._subscribed_waiter = Event()
         self._unsubscribed_waiter = Event()
 
+    @abstractmethod
+    async def _subscribe(self, lite: bool) -> None:
+        pass;
+
+    @abstractmethod
+    async def _unsubscribe(self) -> None:
+        pass
+
+    @abstractmethod
+    def _post_subscribe(self, request: RT) -> None:
+        """
+        Custom actions that implementations may need to make after a subscription has been completed.
+        :param request:  the request that was used to subscribe
+        """
+        pass
+
+    @abstractmethod
+    def _post_unsubscribe(self, request: RT) -> None:
+        """
+        Custom actions that implementations may need to make after an unsubscription has been completed.
+        :param request:  the request that was used to unsubscribe
+        """
+        pass
+
+    @abstractmethod
+    def _subscribe_complete(self) -> None:
+        pass
+
     async def add_listener(self, listener: MapListener[K, V], lite: bool) -> None:
         """
         Add a callback to this group. This causes a subscription message to be sent through the stream
@@ -373,6 +383,62 @@
                 await self._unsubscribe()
                 await self._subscribe(True)
 
+    # noinspection PyProtectedMember
+    def _notify_listeners(self, event: MapEvent[K, V]) -> None:
+        """
+        Notify all listeners within this group of the provided event.
+        :param event:
+        """
+        event_label: str = self._get_emitter_label(event)
+        listener: MapListener[K, V]
+        for listener in self._listeners.keys():
+            listener._emitter.emit(event_label, event)
+
+    # noinspection PyProtectedMember
+    @staticmethod
+    def _get_emitter_label(event: MapEvent[K, V]) -> str:
+        """
+        The string label required by the internal event emitter.
+        :param event:  the MapEvent whose label will be generated
+        :return: the emitter-friendly event label
+        """
+        if event.type == MapEventType.ENTRY_DELETED:
+            return MapEventType.ENTRY_DELETED.value
+        elif event.type == MapEventType.ENTRY_INSERTED:
+            return MapEventType.ENTRY_INSERTED.value
+        elif event.type == MapEventType.ENTRY_UPDATED:
+            return MapEventType.ENTRY_UPDATED.value
+        else:
+            raise AssertionError(f"Unknown EventType [{event}]")
+
+
+class _ListenerGroupV0(_ListenerGroup[K, V, MapListenerRequest], metaclass=ABCMeta):
+    """Manages a collection of MapEventListeners that will be notified when an event is raised.
+    This also manages the on-wire activities for registering/de-registering a listener with the
+    gRPC proxy."""
+
+    _manager: _MapEventsManagerV0[K, V]
+    """The associated MapEventsManager for this group."""
+
+    _request: MapListenerRequest
+    """The subscription request.  A reference is maintained for unsubscribe purposes."""
+
+    def __init__(self, manager: _MapEventsManagerV0[K, V], key_or_filter: K | Filter) -> None:
+        """
+        Constructs a new _ListenerGroup.
+        :param manager:        the _MapEventManager
+        :param key_or_filter:  the key or filter for this group of listeners
+        :raises ValueError:    if either `manager` or `key_or_filter` is `None`
+        """
+        if manager is None:
+            raise ValueError("Argument `manager` must not be None")
+        if key_or_filter is None:
+            raise ValueError("Argument `key_or_filter` must not be None")
+
+        super().__init__(key_or_filter=key_or_filter)
+
+        self._manager = manager
+
     # noinspection PyProtectedMember
     async def _write(self, request: MapListenerRequest) -> None:
         """Write the request to the event stream."""
@@ -402,17 +468,6 @@
         await self._subscribed_waiter.wait()
         self._subscribed_waiter.clear()
 
-    # noinspection PyProtectedMember
-    def _subscribe_complete(self) -> None:
-        """Called when the response to the subscription request has been received."""
-
-        # no longer pending
-        del self._manager._pending_registrations[self._request.uid]
-        self._post_subscribe(self._request)
-
-        # notify caller that subscription is active
-        self._subscribed_waiter.set()
-
     # noinspection PyProtectedMember
     async def _unsubscribe(self) -> None:
         """
@@ -430,60 +485,31 @@
         self._post_unsubscribe(request)
 
     # noinspection PyProtectedMember
-    def _notify_listeners(self, event: MapEvent[K, V]) -> None:
-        """
-        Notify all listeners within this group of the provided event.
-        :param event:
-        """
-        event_label: str = self._get_emitter_label(event)
-        listener: MapListener[K, V]
-        for listener in self._listeners.keys():
-            listener._emitter.emit(event_label, event)
-
-    # noinspection PyProtectedMember
-    @staticmethod
-    def _get_emitter_label(event: MapEvent[K, V]) -> str:
-        """
-        The string label required by the internal event emitter.
-        :param event:  the MapEvent whose label will be generated
-        :return: the emitter-friendly event label
-        """
-        if event.type == MapEventType.ENTRY_DELETED:
-            return MapEventType.ENTRY_DELETED.value
-        elif event.type == MapEventType.ENTRY_INSERTED:
-            return MapEventType.ENTRY_INSERTED.value
-        elif event.type == MapEventType.ENTRY_UPDATED:
-            return MapEventType.ENTRY_UPDATED.value
-        else:
-            raise AssertionError(f"Unknown EventType [{event}]")
+    def _subscribe_complete(self) -> None:
+        del self._manager._pending_registrations[self._request.uid]
+        self._post_subscribe(self._request)
 
-    @abstractmethod
-    def _post_subscribe(self, request: MapListenerRequest) -> None:
-        """
-        Custom actions that implementations may need to make after a subscription has been completed.
-        :param request:  the request that was used to subscribe
-        """
-        pass
+        # notify caller that subscription is active
+        self._subscribed_waiter.set()
 
-    @abstractmethod
-    def _post_unsubscribe(self, request: MapListenerRequest) -> None:
-        """
-        Custom actions that implementations may need to make after an unsubscription has been completed.
-        :param request:  the request that was used to unsubscribe
-        """
-        pass
 
-
-class _KeyListenerGroup(_ListenerGroup[K, V]):
+class _KeyListenerGroupV0(_ListenerGroupV0[K, V]):
     """A ListenerGroup for key-based MapListeners"""
 
-    def __init__(self, manager: _MapEventsManager[K, V], key: K) -> None:
+    def __init__(
+        self,
+        manager: _MapEventsManagerV0[
+            K,
+            V,
+        ],
+        key: K,
+    ) -> None:
         """
         Creates a new _KeyListenerGroup
         :param manager:  the _MapEventManager
         :param key:      the group key
         """
-        super()._init_(manager, key)
+        super().__init__(manager, key)
 
     # noinspection PyProtectedMember
     def _post_subscribe(self, request: MapListenerRequest) -> None:
@@ -498,16 +524,16 @@
         manager._key_group_unsubscribed(key)
 
 
-class _FilterListenerGroup(_ListenerGroup[K, V]):
+class _FilterListenerGroupV0(_ListenerGroupV0[K, V]):
     """A ListenerGroup for Filter-based MapListeners"""
 
-    def __init__(self, manager: _MapEventsManager[K, V], filter: Filter) -> None:
+    def __init__(self, manager: _MapEventsManagerV0[K, V], filter: Filter) -> None:
         """
-        Creates a new _KeyListenerGroup
-        :param manager:  the _MapEventManager
-        :param filter:   the group Filter
+        Creates a new _FilterListenerGroupV0
+        :param manager:       the _MapEventManager
+        :param filter:  the group Filter
         """
-        super()._init_(manager, filter)
+        super().__init__(manager, filter)
 
     # noinspection PyProtectedMember
     def _post_subscribe(self, request: MapListenerRequest) -> None:
@@ -518,7 +544,7 @@
         self._manager._filter_group_unsubscribed(request.filterId, cast(Filter, self._key_or_filter))
 
 
-class _MapEventsManager(Generic[K, V]):
+class _MapEventsManager(Generic[K, V], ABC):
     """MapEventsManager handles registration, de-registration of callbacks, and
     notification of {@link MapEvent}s to callbacks. Since multiple callbacks can
     be registered for a single key / filter, this class relies on another internal
@@ -554,18 +580,15 @@
     _map_name: str
     """The logical name of the provided NamedMap."""
 
-    _key_map: dict[K, _ListenerGroup[K, V]]
+    _key_map: dict[K, _ListenerGroup[K, V, Any]]
     """Contains mappings between a key and its group of MapListeners."""
 
-    _filter_map: dict[Filter, _ListenerGroup[K, V]]
+    _filter_map: dict[Filter, _ListenerGroup[K, V, Any]]
     """Contains mappings between a Filter and its group of MapListeners."""
 
-    _filter_id_listener_group_map: dict[int, _ListenerGroup[K, V]]
+    _filter_id_listener_group_map: dict[int, _ListenerGroup[K, V, Any]]
     """Contains mappings between a logical filter ID and its ListenerGroup."""
 
-    _request_factory: RequestFactory
-    """The RequestFactory used to obtain the necessary gRPC requests."""
-
     _event_stream: Optional[grpc.aio.StreamStreamCall]
     """gRPC bidirectional stream for subscribing/unsubscribing MapListeners and receiving MapEvents from
        the proxy."""
@@ -574,30 +597,26 @@
     """"Flag indicating the event stream is open and ready for listener registrations and
     incoming events."""
 
-    _pending_registrations: dict[str, _ListenerGroup[K, V]]
+    _pending_registrations: dict[str, _ListenerGroup[K, V, Any]]
     """The mapping of pending listener registrations keyed by request uid."""
 
     _background_tasks: Set[Task[None]]
 
-    # noinspection PyProtectedMember
     def __init__(
         self,
         named_map: coherence.client.NamedMap[K, V],
         session: coherence.Session,
-        client: NamedCacheServiceStub,
         serializer: Serializer,
         emitter: EventEmitter,
-    ) -> None:
+    ):
         """
         Constructs a new _MapEventManager.
         :param named_map:   the 'source' of the events
         :param session:     the Session associated with this NamedMap
-        :param client:      the gRPC client
         :param serializer:  the Serializer that will be used for ser/deser operations
         :param emitter:     the internal event emitter used to notify registered MapListeners
         """
         self._named_map = named_map
-        self._client = client
         self._serializer = serializer
         self._emitter = emitter
         self._map_name = named_map.name
@@ -608,8 +627,6 @@
         self._filter_id_listener_group_map = {}
         self._pending_registrations = {}
 
-        self._request_factory = RequestFactory(self._map_name, session.scope, serializer)
-
         self._event_stream = None
         self._open = False
         self._background_tasks = set()
@@ -622,52 +639,21 @@
         # noinspection PyTypeChecker
         session.on(SessionLifecycleEvent.RECONNECTED, self._reconnect)
 
+    @abstractmethod
     def _close(self) -> None:
-        """Close the gRPC event stream and any background tasks."""
-
-        event_stream: grpc.aio.StreamStreamCall = self._event_stream
-        if event_stream is not None:
-            event_stream.cancel()
-            self._event_stream = None
+        pass
 
-        self._open = False
-        for task in self._background_tasks:
-            task.cancel()
-        self._background_tasks.clear()
-
-    # noinspection PyProtectedMember
+    @abstractmethod
     async def _reconnect(self) -> None:
-        group: _ListenerGroup[K, V]
-        for group in self._key_map.values():
-            await group._subscribe(group._registered_lite)
+        pass
 
-        for group in self._filter_map.values():
-            await group._subscribe(group._registered_lite)
+    @abstractmethod
+    def _new_key_group(self, key: K) -> _ListenerGroup[K, V, Any]:
+        pass
 
-    async def _ensure_stream(self) -> grpc.aio.StreamStreamCall:
-        """
-        Initialize the event stream for MapListener events.
-        """
-        if self._event_stream is None:
-            event_stream: grpc.aio.StreamStreamCall = self._client.events()
-            await event_stream.write(self._request_factory.map_event_subscribe())
-            self._event_stream = event_stream
-            read_task: Task[None] = asyncio.create_task(self._handle_response())
-            self._background_tasks.add(read_task)
-            # we use asyncio.timeout here instead of using the gRPC timeout
-            # as any deadline set on the stream will result in a loss of events
-            try:
-                await asyncio.wait_for(self._stream_waiter.wait(), self._session.options.request_timeout_seconds)
-            except TimeoutError:
-                s = (
-                    "Deadline [{0} seconds] exceeded waiting for event stream"
-                    " to become ready. Server address - {1})".format(
-                        str(self._session.options.request_timeout_seconds), self._session.options.address
-                    )
-                )
-                raise TimeoutError(s)
-
-        return self._event_stream
+    @abstractmethod
+    def _new_filter_group(self, filter: Filter) -> _ListenerGroup[K, V, Any]:
+        pass
 
     async def _register_key_listener(self, listener: MapListener[K, V], key: K, lite: bool = False) -> None:
         """
@@ -677,10 +663,10 @@
         :param lite:      `True` if the event should only include the key, or `False`
                           if the event should include old and new values as well as the key
         """
-        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)
+        group: Optional[_ListenerGroup[K, V, Any]] = self._key_map.get(key, None)
 
         if group is None:
-            group = _KeyListenerGroup(self, key)
+            group = self._new_key_group(key)
             self._key_map[key] = group
 
         await group.add_listener(listener, lite)
@@ -691,7 +677,7 @@
         :param listener:  the MapListener to remove
         :param key:       they key the listener was associated with
         """
-        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)
+        group: Optional[_ListenerGroup[K, V, Any]] = self._key_map.get(key, None)
 
         if group is not None:
             await group.remove_listener(listener)
@@ -701,16 +687,16 @@
     ) -> None:
         """
         Registers the specified listener to listen for events matching the provided filter.
-        :param listener:  the MapListener to register
-        :param filter:    the Filter associated with the listener
-        :param lite:      `True` if the event should only include the key, or `False`
-                           if the event should include old and new values as well as the key
+        :param listener:      the MapListener to register
+        :param filter:  the Filter associated with the listener
+        :param lite:          `True` if the event should only include the key, or `False`
+                              if the event should include old and new values as well as the key
         """
         filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER
-        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)
+        group: Optional[_ListenerGroup[K, V, Any]] = self._filter_map.get(filter_local, None)
 
         if group is None:
-            group = _FilterListenerGroup(self, filter_local)
+            group = self._new_filter_group(filter_local)
             self._filter_map[filter_local] = group
         await group.add_listener(listener, lite)
 
@@ -721,12 +707,12 @@
         :param filter:    the Filter that was used with the listener registration
         """
         filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER
-        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)
+        group: Optional[_ListenerGroup[K, V, Any]] = self._filter_map.get(filter_local, None)
 
         if group is not None:
             await group.remove_listener(listener)
 
-    def _key_group_subscribed(self, key: K, group: _ListenerGroup[K, V]) -> None:
+    def _key_group_subscribed(self, key: K, group: _ListenerGroup[K, V, Any]) -> None:
         """
         Called internally by _KeyListenerGroup when a key listener is subscribed.
         :param key:    the registration key
@@ -741,12 +727,12 @@
         """
         del self._key_map[key]
 
-    def _filter_group_subscribed(self, filter_id: int, filter: Filter, group: _ListenerGroup[K, V]) -> None:
+    def _filter_group_subscribed(self, filter_id: int, filter: Filter, group: _ListenerGroup[K, V, Any]) -> None:
         """
         Called internally by _FilterListenerGroup when a filter listener is subscribed.
-        :param filter_id:  the ID of the filter
-        :param filter:     the Filter associated with the listener registration
-        :param group:      the registered group
+        :param filter_id:     the ID of the filter
+        :param filter:  the Filter associated with the listener registration
+        :param group:         the registered group
         """
         self._filter_id_listener_group_map[filter_id] = group
         self._filter_map[filter] = group
@@ -754,12 +740,90 @@
     def _filter_group_unsubscribed(self, filter_id: int, filter: Filter) -> None:
         """
         Called internally by _FilterListenerGroup when a filter listener is unsubscribed.
-        :param filter_id:  the ID of the filter
-        :param filter:     the Filter used at registration
+        :param filter_id:     the ID of the filter
+        :param filter:  the Filter used at registration
         """
         del self._filter_id_listener_group_map[filter_id]
         del self._filter_map[filter]
 
+
+class _MapEventsManagerV0(_MapEventsManager[K, V]):
+    """MapEventsManager implementation for V0 of the gRPC proxy."""
+
+    # noinspection PyProtectedMember
+    def __init__(
+        self,
+        named_map: coherence.client.NamedMap[K, V],
+        session: coherence.Session,
+        client: NamedCacheServiceStub,
+        serializer: Serializer,
+        emitter: EventEmitter,
+    ) -> None:
+        """
+        Constructs a new _MapEventManager.
+        :param named_map:   the 'source' of the events
+        :param session:     the Session associated with this NamedMap
+        :param client:      the gRPC client
+        :param serializer:  the Serializer that will be used for ser/deser operations
+        :param emitter:     the internal event emitter used to notify registered MapListeners
+        """
+        super().__init__(named_map, session, serializer, emitter)
+        self._client = client
+        self._request_factory = RequestFactory(self._map_name, session.scope, serializer)
+
+    def _new_key_group(self, key: K) -> _ListenerGroup[K, V, Any]:
+        return _KeyListenerGroupV0(self, key)
+
+    def _new_filter_group(self, filter: Filter) -> _ListenerGroup[K, V, Any]:
+        return _FilterListenerGroupV0(self, filter)
+
+    def _close(self) -> None:
+        """Close the gRPC event stream and any background tasks."""
+
+        event_stream: grpc.aio.StreamStreamCall = self._event_stream
+        if event_stream is not None:
+            event_stream.cancel()
+            self._event_stream = None
+
+        self._open = False
+        for task in self._background_tasks:
+            task.cancel()
+        self._background_tasks.clear()
+
+    # noinspection PyProtectedMember
+    async def _reconnect(self) -> None:
+        group: _ListenerGroup[K, V, Any]
+        for group in self._key_map.values():
+            await group._subscribe(group._registered_lite)
+
+        for group in self._filter_map.values():
+            await group._subscribe(group._registered_lite)
+
+    async def _ensure_stream(self) -> grpc.aio.StreamStreamCall:
+        """
+        Initialize the event stream for MapListener events.
+        """
+        if self._event_stream is None:
+            event_stream: grpc.aio.StreamStreamCall = self._client.events()
+            await event_stream.write(self._request_factory.map_event_subscribe())
+            self._event_stream = event_stream
+            read_task: Task[None] = asyncio.create_task(self._handle_response())
+            self._background_tasks.add(read_task)
+            # we use asyncio.timeout here instead of using the gRPC timeout
+            # as any deadline set on the stream will result in a loss of events
+            try:
+                await asyncio.wait_for(self._stream_waiter.wait(), self._session.options.request_timeout_seconds)
+            except TimeoutError:
+                s = (
+                    "Deadline [{0} seconds] exceeded waiting for event stream"
+                    " to become ready. Server address - {1})".format(
+                        str(self._session.options.request_timeout_seconds), self._session.options.address
+                    )
+                )
+                raise TimeoutError(s)
+
+        return self._event_stream
+
     # noinspection PyProtectedMember
     async def _handle_response(self) -> None:
         """
@@ -778,7 +842,9 @@
                     response: MapListenerResponse = await event_stream.read()
                     if response.HasField("subscribed"):
                         subscribed = response.subscribed
-                        group: Optional[_ListenerGroup[K, V]] = self._pending_registrations.get(subscribed.uid, None)
+                        group: Optional[_ListenerGroup[K, V, Any]] = self._pending_registrations.get(
+                            subscribed.uid, None
+                        )
                         if group is not None:
                             group._subscribe_complete()
                     elif response.HasField("destroyed"):
@@ -793,7 +859,7 @@
                         response_event = response.event
                         event: MapEvent[K, V] = MapEvent(self._named_map, response_event, self._serializer)
                         for _id in response_event.filterIds:
-                            filter_group: Optional[_ListenerGroup[K, V]] = self._filter_id_listener_group_map.get(
+                            filter_group: Optional[_ListenerGroup[K, V, Any]] = self._filter_id_listener_group_map.get(
                                 _id, None
                             )
                             if filter_group is not None:
@@ -804,3 +870,115 @@
                             key_group._notify_listeners(event)
             except asyncio.CancelledError:
                 return
+
+
+class _ListenerGroupV1(_ListenerGroup[K, V, cache_service_messages_v1_pb2.MapListenerRequest], ABC):
+
+    def __init__(self, manager: _MapEventsManagerV1[K, V], key_or_filter: K | Filter):
+        if manager is None:
+            raise ValueError("Argument `manager` must not be None")
+        if key_or_filter is None:
+            raise ValueError("Argument `key_or_filter` must not be None")
+
+        super().__init__(key_or_filter=key_or_filter)
+
+        self._manager = manager
+
+    async def _subscribe(self, lite: bool) -> None:
+        return await super()._subscribe(lite)  # TODO
+
+
+class _KeyListenerGroupV1(_ListenerGroupV1[K, V]):
+    _manager: _MapEventsManagerV1[K, V]
+    """The associated MapEventsManager for this group."""
+
+    _request: MapListenerRequest
+    """The subscription request.  A reference is maintained for unsubscribe purposes."""
+
+    def __init__(self, manager: _MapEventsManagerV1[K, V], key_or_filter: K | Filter) -> None:
+        """
+        Constructs a new _ListenerGroup.
+        :param manager:        the _MapEventManager
+        :param key_or_filter:  the key or filter for this group of listeners
+        :raises ValueError:    if either `manager` or `key_or_filter` is `None`
+        """
+        if manager is None:
+            raise ValueError("Argument `manager` must not be None")
+        if key_or_filter is None:
+            raise ValueError("Argument `key_or_filter` must not be None")
+
+        super().__init__(manager, key_or_filter)
+
+    # noinspection PyProtectedMember
+    def _post_subscribe(self, request: MapListenerRequest) -> None:
+        manager: _MapEventsManagerV1[K, V] = self._manager
+        key: K = manager._serializer.deserialize(request.key)
+        self._manager._key_group_subscribed(key, self)
+
+    # noinspection PyProtectedMember
+    def _post_unsubscribe(self, request: MapListenerRequest) -> None:
+        manager: _MapEventsManager[K, V] = self._manager
+        key: K = manager._serializer.deserialize(request.key)
+        manager._key_group_unsubscribed(key)
+
+    async def _unsubscribe(self) -> None:
+        pass
+
+    def _subscribe_complete(self) -> None:
+        pass
+
+
+class _FilterListenerGroupV1(_ListenerGroupV1[K, V]):
+    """A ListenerGroup for Filter-based MapListeners"""
+
+    def __init__(self, manager: _MapEventsManagerV1[K, V], filter: Filter) -> None:
+        """
+        Creates a new _KeyListenerGroup
+        :param manager:  the _MapEventManager
+        :param filter:   the group Filter
+        """
+        super().__init__(manager, filter)
+
+    # noinspection PyProtectedMember
+    def _post_subscribe(self, request: MapListenerRequest) -> None:
+        self._manager._filter_group_subscribed(request.filterId, cast(Filter, self._key_or_filter), self)
+
+    # noinspection PyProtectedMember
+    def _post_unsubscribe(self, request: MapListenerRequest) -> None:
+        self._manager._filter_group_unsubscribed(request.filterId, cast(Filter, self._key_or_filter))
+
+    async def _unsubscribe(self) -> None:
+        pass
+
+    def _subscribe_complete(self) -> None:
+        pass
+
+
+class _MapEventsManagerV1(_MapEventsManager[K, V]):
+    def __init__(
+        self,
+        named_map: coherence.client.NamedMap[K, V],
+        session: coherence.Session,
+        serializer: Serializer,
+        emitter: EventEmitter,
+    ) -> None:
+        super().__init__(named_map, session, serializer, emitter)
+        # noinspection PyUnresolvedReferences,PyProtectedMember
+        self._request_factory: RequestFactoryV1 = RequestFactoryV1(
+            self._map_name, named_map._cache_id, session.scope, serializer
+        )
+
+    async def _ensure_stream(self) -> grpc.aio.StreamStreamCall:
+        pass  # in v1, this is a no-op
+
+    def _new_key_group(self, key: K) -> _ListenerGroup[K, V, Any]:
+        return _KeyListenerGroupV1(self, key)
+
+    def _new_filter_group(self, filter: Filter) -> _ListenerGroup[K, V, Any]:
+        return _FilterListenerGroupV1(self, filter)
+
+    def _close(self) -> None:
+        pass
+
+    async def _reconnect(self) -> None:
+        pass
Index: src/coherence/client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport abc\nimport asyncio\nimport logging\nimport os\nimport time\nimport uuid\nfrom asyncio import Condition, Event, Task\nfrom threading import Lock\nfrom typing import (\n    Any,\n    AsyncIterator,\n    Awaitable,\n    Callable,\n    Final,\n    Generic,\n    List,\n    Literal,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    TypeVar,\n    cast,\n    no_type_check,\n)\n\n# noinspection PyPackageRequirements\nimport grpc\nfrom cache_service_messages_v1_pb2 import NamedCacheRequest, NamedCacheRequestType, NamedCacheResponse, ResponseType\n# import proxy_service_messages_v1_pb2\nfrom google.protobuf.json_format import MessageToJson  # type: ignore\nfrom google.protobuf.wrappers_pb2 import BoolValue, BytesValue, Int32Value  # type: ignore\nfrom proxy_service_messages_v1_pb2 import ProxyRequest\nfrom pymitter import EventEmitter\n\nfrom . import proxy_service_messages_v1_pb2, proxy_service_v1_pb2_grpc\nfrom .aggregator import AverageAggregator, EntryAggregator, PriorityAggregator, SumAggregator\nfrom .common_messages_v1_pb2 import BinaryKeyAndValue, OptionalValue\nfrom .comparator import Comparator\nfrom .event import MapLifecycleEvent, MapListener, SessionLifecycleEvent\nfrom .extractor import ValueExtractor\nfrom .filter import Filter\nfrom .messages_pb2 import PageRequest\nfrom .processor import EntryProcessor\nfrom .serialization import Serializer, SerializerRegistry\nfrom .services_pb2_grpc import NamedCacheServiceStub\nfrom .util import RequestFactory\nfrom .util_v1 import RequestFactoryV1\n\nE = TypeVar(\"E\")\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\n\nCOH_LOG = logging.getLogger(\"coherence\")\n\n\n@no_type_check\ndef _pre_call_cache(func):\n    def inner(self, *args, **kwargs):\n        if not self.active:\n            raise RuntimeError(\"Cache [] has been \" + \"released\" if self.released else \"destroyed\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if not self.active:\n            raise RuntimeError(\n                \"Cache [{}] has been {}.\".format(self.name, \"released\" if self.released else \"destroyed\")\n            )\n\n        # noinspection PyProtectedMember\n        await self._session._wait_for_ready()\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\n@no_type_check\ndef _pre_call_session(func):\n    def inner(self, *args, **kwargs):\n        if self._closed:\n            raise RuntimeError(\"Session has been closed.\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if self._closed:\n            raise RuntimeError(\"Session has been closed.\")\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\nclass MapEntry(Generic[K, V]):\n    \"\"\"\n    A map entry (key-value pair).\n    \"\"\"\n\n    def __init__(self, key: K, value: V):\n        self.key = key\n        self.value = value\n\n\nclass NamedMap(abc.ABC, Generic[K, V]):\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored persistently, on disk.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"documentation\"\"\"\n\n    @abc.abstractmethod\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        \"\"\"\n        Add a callback that will be invoked when the specified MapLifecycleEvent is raised.\n        :param event:     the MapLifecycleEvent to listen for\n        :param callback:  the callback that will be invoked when the event occurs\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def destroyed(self) -> bool:\n        pass\n\n    @property\n    @abc.abstractmethod\n    def released(self) -> bool:\n        pass\n\n    @property\n    def active(self) -> bool:\n        return not self.released and not self.destroyed\n\n    @abc.abstractmethod\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        \"\"\"\n        Add a MapListener that will receive events (inserts, updates, deletes) that occur\n        against the map, with the key, old-value and new-value included.\n\n        :param listener:      the MapListener to register\n        :param listener_for:  the optional key that identifies the entry for which to raise events or a Filter\n         that will be passed MapEvent objects to select from; a MapEvent will be delivered to the listener only if the\n         filter evaluates to `True` for that MapEvent. `None` is equivalent to a Filter that always returns `True`\n        :param lite:          optionally pass `True` to indicate that the MapEvent objects do not have to include the\n         old or new values in order to allow optimizations\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        \"\"\"\n        Remove a standard map listener that previously registered to receive events.\n        :param listener:      the MapListener to be removed\n        :param listener_for:  the key or filter, if any, passed to a previous addMapListener invocation\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get(self, key: K) -> Optional[V]:\n        \"\"\"\n        Returns the value to which this cache maps the specified key.\n\n        :param key: the key whose associated value is to be returned\n\n        :Example:\n\n         >>> import asyncio\n         >>> from typing import Any, AsyncGenerator, Optional, TypeVar\n         >>> from coherence import NamedCache, Session\n         >>> K = TypeVar(\"K\")\n         >>> V = TypeVar(\"V\")\n         >>> R = TypeVar(\"R\")\n         >>> session: Session = Session(None)\n         >>> cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n         >>> k: str = \"one\"\n         >>> v: str = \"only-one\"\n         >>> await cache.put(k, v)\n         >>> r = await cache.get(k)\n         >>> print(r)\n         only-one\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        \"\"\"\n        Returns the value to which the specified key is mapped, or the specified `defaultValue`\n        if this map contains no mapping for the key.\n\n        :param key: the key whose associated value is to be returned\n        :param default_value: defaultValue if this map contains no mapping for the key.\n        :return: value for the key in the map or the `defaultValue`\n        \"\"\"\n\n    @abc.abstractmethod\n    def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Get all the specified keys if they are in the map. For each key that is in the map,\n        that key and its corresponding value will be placed in the map that is returned by\n        this method. The absence of a key in the returned map indicates that it was not in the cache,\n        which may imply (for caches that can load behind the scenes) that the requested data\n        could not be loaded.\n\n        :param keys: an Iterable of keys that may be in this map\n        :return: an AsyncIterator of MapEntry instances for the specified keys passed in `keys`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V) -> V:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the\n        map previously contained a mapping for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None`\n         if there was no mapping for key. A `None` return can also indicate\n         that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V) -> V:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to `None`) associates\n        it with the given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None` if there was no mapping for key. A\n         `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_all(self, map: dict[K, V], ttl: Optional[int] = 0) -> None:\n        \"\"\"\n        Copies all mappings from the specified map to this map\n\n        :param map: the map to copy from\n        :param ttl: the time to live for the map entries\n        \"\"\"\n\n    @abc.abstractmethod\n    async def clear(self) -> None:\n        \"\"\"\n        Clears all the mappings in the 'NamedMap'.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def destroy(self) -> None:\n        \"\"\"\n        Release and destroy this cache.\n\n        Warning: This method is used to completely destroy the specified cache\n        across the cluster. All references in the entire cluster to this cache\n        will be invalidated, the cached data will be cleared, and all resources\n        will be released.\n        \"\"\"\n\n    @abc.abstractmethod\n    def release(self) -> None:\n        \"\"\"\n        Release local resources associated with instance.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def truncate(self) -> None:\n        \"\"\"\n        Truncates the cache.  Unlike :func:`coherence.client.NamedMap.clear()`, this function does not generate an\n        event for each removed entry.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove(self, key: K) -> V:\n        \"\"\"\n        Removes the mapping for a key from this map if it is present.\n\n        :param key: key whose mapping is to be removed from the map\n        :return: the previous value associated with key, or `None` if there was no mapping for key\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        \"\"\"\n        Removes the entry for the specified key only if it is currently mapped to the specified value.\n\n        :param key: key with which the specified value is associated\n        :param value: expected to be associated with the specified key\n        :return: resolving to true if the value was removed\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace(self, key: K, value: V) -> V:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key: key whose associated value is to be replaced\n        :param value: value expected to be associated with the specified key\n        :return: resolving to the previous value associated with the specified key, or `None` if there was no mapping\n         for the key. (A `None` return can also indicate that the map previously associated `None` with the key\n         if the implementation supports `None` values.)\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key:         key whose associated value is to be removed\n        :param old_value:   value expected to be associated with the specified key\n        :param new_value:   value to be associated with the specified key\n        :return: resolving to `true` if the value was replaced\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_key(self, key: K) -> bool:\n        \"\"\"\n        Returns `true` if the specified key is mapped a value within the cache.\n\n        :param key: the key whose presence in this cache is to be tested\n        :return: resolving to `true` if the key is mapped to a value, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_value(self, value: V) -> bool:\n        \"\"\"\n        Returns `true` if the specified value is mapped to some key.\n\n        :param value: the value expected to be associated with some key\n        :return: resolving to `true` if a mapping exists, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def is_empty(self) -> bool:\n        \"\"\"\n        Returns `true` if this map contains no key-value mappings.\n\n        :return: `true` if this map contains no key-value mappings.\n        \"\"\"\n\n    @abc.abstractmethod\n    async def size(self) -> int:\n        \"\"\"\n        Signifies the number of key-value mappings in this map.\n\n        :return: the number of key-value mappings in this map\n        \"\"\"\n\n    @abc.abstractmethod\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:\n        \"\"\"\n        Invoke the passed EntryProcessor against the Entry specified by the\n        passed key, returning the result of the invocation.\n\n        :param key: the key to process - it is not required to exist within the Map\n        :param processor: the EntryProcessor to use to process the specified key\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        \"\"\"\n        Invoke the passed EntryProcessor against the set of entries that are selected by the given Filter,\n        returning the result of the invocation for each.\n\n        Unless specified otherwise, implementations will perform this operation in two steps:\n            1. use the filter to retrieve a matching entry set\n            2. apply the agent to every filtered entry.\n\n        This algorithm assumes that the agent's processing does not affect the result of the specified filter\n        evaluation, since the filtering and processing could be performed in parallel on different threads. If this\n        assumption does not hold, the processor logic has to be idempotent, or at least re-evaluate the filter. This\n        could be easily accomplished by wrapping the processor with the ConditionalProcessor.\n\n        :param processor: the EntryProcessor to use to process the specified keys\n        :param keys: the keys to process these keys are not required to exist within the Map\n        :param filter: a Filter that results in the set of keys to be processed\n        :return: an AsyncIterator of MapEntry instances containing the results of invoking the EntryProcessor against\n         each of the specified keys\n        \"\"\"\n\n    @abc.abstractmethod\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> R:\n        \"\"\"\n        Perform an aggregating operation against the entries specified by the passed keys.\n\n        :param aggregator: the EntryAggregator that is used to aggregate across the specified entries of this Map\n        :param keys: the Iterable of keys that specify the entries within this Map to aggregate across\n        :param filter: the Filter that is used to select entries within this Map to aggregate across\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        \"\"\"\n        Return a Set of the values contained in this map that satisfy the criteria expressed by the filter.\n        If no filter or comparator is specified, it returns a Set view of the values contained in this map.The\n        collection is backed by the map, so changes to the map are reflected in the collection, and vice-versa. If\n        the map is modified while an iteration over the collection is in progress (except through the iterator's own\n        `remove` operation), the results of the iteration are undefined.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator:  the Comparator object which imposes an ordering on entries in the resulting set; or null\n         if the entries' natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances resolving to the values that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        \"\"\"\n        Return a set view of the keys contained in this map for entries that satisfy the criteria expressed by the\n        filter.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter is provided.\n        :return: an AsyncIterator of keys for entries that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Return a set view of the entries contained in this map that satisfy the criteria expressed by the filter.\n        Each element in the returned set is a :class:`coherence.client.MapEntry`.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator: the Comparator object which imposes an ordering on entries in the resulting set; or `None`\n         if the entries' values natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        \"\"\"\n        Add an index to this map.\n\n        :param extractor: The :class:`coherence.extractor.ValueExtractor` object that is used to extract\n                   an indexable Object from a value stored in the\n                   indexed Map. Must not be 'None'.\n        :param ordered: true if the contents of the indexed information\n                   should be ordered false otherwise.\n        :param comparator: The :class:`coherence.comparator.Comparator` object which imposes an ordering\n                   on entries in the indexed map or None if the\n                   entries' values natural ordering should be used.\n        \"\"\"\n\n    @abc.abstractmethod\n    def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        \"\"\"\n        Removes an index on this `NamedMap`.\n\n        :param extractor: The :class:`coherence.extractor.ValueExtractor` object that is used to extract\n                  an indexable Object from a value stored in the\n                  indexed Map. Must not be 'None'.\n\n        \"\"\"\n\n\nclass NamedCache(NamedMap[K, V]):\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored in an external system, for example, a database,\n    or data that has been assembled or calculated at some significant cost.  Such entries are referred to as being\n    `cached`.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V, ttl: int = 0) -> V:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the map previously contained a mapping\n        for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to null) associates it with the\n        given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n\nclass NamedCacheClient(NamedCache[K, V]):\n    def __init__(self, cache_name: str, session: Session, serializer: Serializer):\n        self._cache_name: str = cache_name\n        self._serializer: Serializer = serializer\n        self._client_stub: NamedCacheServiceStub = NamedCacheServiceStub(session.channel)\n        self._request_factory: RequestFactory = RequestFactory(cache_name, session.scope, serializer)\n        self._emitter: EventEmitter = EventEmitter()\n        self._internal_emitter: EventEmitter = EventEmitter()\n        self._destroyed: bool = False\n        self._released: bool = False\n        self._session: Session = session\n        from .event import _MapEventsManager\n\n        self._setup_event_handlers()\n\n        self._events_manager: _MapEventsManager[K, V] = _MapEventsManager(\n            self, session, self._client_stub, serializer, self._internal_emitter\n        )\n\n    @property\n    def name(self) -> str:\n        return self._cache_name\n\n    @property\n    def destroyed(self) -> bool:\n        return self._destroyed\n\n    @property\n    def released(self) -> bool:\n        return self._released\n\n    @_pre_call_cache\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        self._emitter.on(str(event.value), callback)\n\n    @_pre_call_cache\n    async def get(self, key: K) -> Optional[V]:\n        g = self._request_factory.get_request(key)\n        v = await self._client_stub.get(g)\n        if v.present:\n            return self._request_factory.get_serializer().deserialize(v.value)\n        else:\n            return None\n\n    @_pre_call_cache\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        v: Optional[V] = await self.get(key)\n        if v is not None:\n            return v\n        else:\n            return default_value\n\n    @_pre_call_cache\n    async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        r = self._request_factory.get_all_request(keys)\n        stream = self._client_stub.getAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def put(self, key: K, value: V, ttl: int = 0) -> V:\n        p = self._request_factory.put_request(key, value, ttl)\n        v = await self._client_stub.put(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:\n        p = self._request_factory.put_if_absent_request(key, value, ttl)\n        v = await self._client_stub.putIfAbsent(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_all(self, map: dict[K, V]) -> None:\n        p = self._request_factory.put_all_request(map)\n        await self._client_stub.putAll(p)\n\n    @_pre_call_cache\n    async def clear(self) -> None:\n        r = self._request_factory.clear_request()\n        await self._client_stub.clear(r)\n\n    async def destroy(self) -> None:\n        self.release()\n        self._internal_emitter.once(MapLifecycleEvent.DESTROYED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.DESTROYED.value, self.name)\n        r = self._request_factory.destroy_request()\n        await self._client_stub.destroy(r)\n\n    @_pre_call_cache\n    def release(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.RELEASED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.RELEASED.value, self.name)\n\n    @_pre_call_cache\n    async def truncate(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.TRUNCATED.value)\n        r = self._request_factory.truncate_request()\n        await self._client_stub.truncate(r)\n\n    @_pre_call_cache\n    async def remove(self, key: K) -> V:\n        r = self._request_factory.remove_request(key)\n        v = await self._client_stub.remove(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        r = self._request_factory.remove_mapping_request(key, value)\n        v = await self._client_stub.removeMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace(self, key: K, value: V) -> V:\n        r = self._request_factory.replace_request(key, value)\n        v = await self._client_stub.replace(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        r = self._request_factory.replace_mapping_request(key, old_value, new_value)\n        v = await self._client_stub.replaceMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_key(self, key: K) -> bool:\n        r = self._request_factory.contains_key_request(key)\n        v = await self._client_stub.containsKey(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_value(self, value: V) -> bool:\n        r = self._request_factory.contains_value_request(value)\n        v = await self._client_stub.containsValue(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def is_empty(self) -> bool:\n        r = self._request_factory.is_empty_request()\n        v = await self._client_stub.isEmpty(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def size(self) -> int:\n        r = self._request_factory.size_request()\n        v = await self._client_stub.size(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:\n        r = self._request_factory.invoke_request(key, processor)\n        v = await self._client_stub.invoke(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        r = self._request_factory.invoke_all_request(processor, keys, filter)\n        stream = self._client_stub.invokeAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> R:\n        r = self._request_factory.aggregate_request(aggregator, keys, filter)\n        results = await self._client_stub.aggregate(r)\n        value: Any = self._request_factory.get_serializer().deserialize(results.value)\n        # for compatibility with 22.06\n        if isinstance(aggregator, SumAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, AverageAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, PriorityAggregator):\n            pri_agg: PriorityAggregator[R] = aggregator\n            if (\n                isinstance(pri_agg.aggregator, AverageAggregator) or isinstance(pri_agg.aggregator, SumAggregator)\n            ) and isinstance(value, str):\n                return cast(R, float(value))\n        # end compatibility with 22.06\n\n        return cast(R, value)\n\n    @_pre_call_cache\n    def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _scalar_deserializer)\n        else:\n            r = self._request_factory.values_request(filter)\n            stream = self._client_stub.values(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        if by_page and filter is None:\n            return _PagedStream(self, _scalar_deserializer, True)\n        else:\n            r = self._request_factory.keys_request(filter)\n            stream = self._client_stub.keySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _entry_deserializer)\n        else:\n            r = self._request_factory.entries_request(filter, comparator)\n            stream = self._client_stub.entrySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    from .event import MapListener\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._register_filter_listener(listener, listener_for, lite)\n        else:\n            await self._events_manager._register_key_listener(listener, listener_for, lite)\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._remove_filter_listener(listener, listener_for)\n        else:\n            await self._events_manager._remove_key_listener(listener, listener_for)\n\n    @_pre_call_cache\n    async def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n        r = self._request_factory.add_index_request(extractor, ordered, comparator)\n        await self._client_stub.addIndex(r)\n\n    @_pre_call_cache\n    async def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n        r = self._request_factory.remove_index_request(extractor)\n        await self._client_stub.removeIndex(r)\n\n    def _setup_event_handlers(self) -> None:\n        \"\"\"\n        Setup handlers to notify cache-level handlers of events.\n        \"\"\"\n        emitter: EventEmitter = self._emitter\n        internal_emitter: EventEmitter = self._internal_emitter\n        this: NamedCacheClient[K, V] = self\n        cache_name = self._cache_name\n\n        # noinspection PyProtectedMember\n        def on_destroyed(name: str) -> None:\n            if name == cache_name and not this.destroyed:\n                this._events_manager._close()\n                this._destroyed = True\n                emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        # noinspection PyProtectedMember\n        def on_released(name: str) -> None:\n            if name == cache_name and not this.released:\n                this._events_manager._close()\n                this._released = True\n                emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        def on_truncated(name: str) -> None:\n            if name == cache_name:\n                emitter.emit(MapLifecycleEvent.TRUNCATED.value, name)\n\n        internal_emitter.on(MapLifecycleEvent.DESTROYED.value, on_destroyed)\n        internal_emitter.on(MapLifecycleEvent.RELEASED.value, on_released)\n        internal_emitter.on(MapLifecycleEvent.TRUNCATED.value, on_truncated)\n\n    def __str__(self) -> str:\n        return (\n            f\"NamedCache(name={self.name}, session={self._session.session_id}, serializer={self._serializer},\"\n            f\" released={self.released}, destroyed={self.destroyed})\"\n        )\n\n\nclass NamedCacheClientV1(NamedCache[K, V]):\n\n    def __init__(self, cache_name: str, session: Session, serializer: Serializer):\n        self._cache_name: str = cache_name\n        self._cache_id: int = 0\n        self._serializer: Serializer = serializer\n        self._client_stub: proxy_service_v1_pb2_grpc.ProxyServiceStub = session._v1_init_response_details.get(\"stub\")\n        self._client_stream: grpc.aio._call.StreamStreamCall = session._v1_init_response_details.get(\"stream\")\n        self._request_factory: RequestFactoryV1 = RequestFactoryV1(\n            cache_name, self._cache_id, session.scope, serializer\n        )\n        # self._emitter: EventEmitter = EventEmitter()\n        # self._internal_emitter: EventEmitter = EventEmitter()\n        self._destroyed: bool = False\n        self._released: bool = False\n        self._session: Session = session\n        self._stream_handler: StreamHandler = StreamHandler.get_stream_handler(self._session, self._client_stream)\n        # asyncio.create_task(self._stream_handler.handle_response())\n        # from .event import _MapEventsManager\n\n        # self._setup_event_handlers()\n\n        # self._events_manager: _MapEventsManager[K, V] = _MapEventsManager(\n        #     self, session, self._client_stub, serializer, self._internal_emitter\n        # )\n\n    async def _dispatch_and_wait(self, request: NamedCacheRequest) -> Any:\n        proxy_request: ProxyRequest = self._request_factory.create_proxy_request(request)\n        request_id: int = proxy_request.id\n        await self._stream_handler.write_request(proxy_request, request_id, request)\n        # TODO: use timeout from configuration\n        return await asyncio.wait_for(self._stream_handler.get_response(request_id), 10.0)\n\n    @property\n    def cache_id(self) -> int:\n        return self._cache_id\n\n    @cache_id.setter\n    def cache_id(self, cache_id: int) -> None:\n        self._cache_id = cache_id\n\n    async def ensure_cache(self) -> None:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.ensure_request(self._cache_name)\n        )\n\n        self.cache_id = response.cacheId\n        self._session.update_cache_id_map(self.cache_id, self)\n        self._request_factory.cache_id = response.cacheId\n\n    async def get(self, key: K) -> Optional[V]:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.get_request(key))\n\n        if response.HasField(\"message\"):\n            optional_value = OptionalValue()\n            response.message.Unpack(optional_value)\n            if optional_value.present:\n                return self._serializer.deserialize(optional_value.value)\n            else:\n                return None\n        else:\n            return None\n\n    async def put(self, key: K, value: V, ttl: int = 0) -> V:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.put_request(key, value, ttl))\n\n        if response is None:\n            return None\n        else:\n            if response.HasField(\"message\"):\n                value = BytesValue()\n                response.message.Unpack(value)\n                result: V = self._serializer.deserialize(value.value)\n                return result\n            else:\n                return None\n\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.put_if_absent_request(key, value, ttl)\n        )\n\n        if response is None:\n            return None\n        else:\n            if response.HasField(\"message\"):\n                value = BytesValue()\n                response.message.Unpack(value)\n                result: V = self._serializer.deserialize(value.value)\n                return result\n            else:\n                return None\n\n    @property\n    def name(self) -> str:\n        return self._cache_name\n\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        pass\n\n    @property\n    def destroyed(self) -> bool:\n        pass\n\n    @property\n    def released(self) -> bool:\n        pass\n\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        pass\n\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        pass\n\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        v: Optional[V] = await self.get(key)\n        if v is not None:\n            return v\n        else:\n            return default_value\n\n    async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        response: List[NamedCacheResponse] = await self._dispatch_and_wait(self._request_factory.get_all_request(keys))\n\n        lst = list()\n        for entry in response:\n            if entry.HasField(\"message\"):\n                binary_key_value = BinaryKeyAndValue()\n                entry.message.Unpack(binary_key_value)\n                m = MapEntry(binary_key_value.key, binary_key_value.value)\n                lst.append(m)\n        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)\n\n    async def put_all(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> None:\n        await self._dispatch_and_wait(self._request_factory.put_all_request(kv_map, ttl))\n\n    async def clear(self) -> None:\n        await self._dispatch_and_wait(self._request_factory.clear_request())\n\n    async def destroy(self) -> None:\n        await self._dispatch_and_wait(self._request_factory.destroy_request())\n\n    def release(self) -> None:\n        # TODO\n        pass\n\n    async def truncate(self) -> None:\n        await self._dispatch_and_wait(self._request_factory.truncate_request())\n\n    async def remove(self, key: K) -> V:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.remove_request(key))\n\n        if response.HasField(\"message\"):\n            value = BytesValue()\n            response.message.Unpack(value)\n            result = self._serializer.deserialize(value.value)\n            return result\n        else:\n            return None\n\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.remove_mapping_request(key, value)\n        )\n\n        if response.HasField(\"message\"):\n            value = BoolValue()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return False\n\n    async def replace(self, key: K, value: V) -> V:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.replace_request(key, value))\n\n        if response.HasField(\"message\"):\n            value = BytesValue()\n            response.message.Unpack(value)\n            result = self._serializer.deserialize(value.value)\n            return result\n        else:\n            return None\n\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.replace_mapping_request(key, old_value, new_value)\n        )\n\n        if response.HasField(\"message\"):\n            value = BoolValue()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return False\n\n    async def contains_key(self, key: K) -> bool:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.contains_key_request(key))\n\n        if response.HasField(\"message\"):\n            value = BoolValue()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return False\n\n    async def contains_value(self, value: V) -> bool:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.contains_value_request(value)\n        )\n\n        if response.HasField(\"message\"):\n            value = BoolValue()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return False\n\n    async def is_empty(self) -> bool:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.is_empty_request())\n\n        if response.HasField(\"message\"):\n            value = BoolValue()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return False\n\n    async def size(self) -> int:\n        response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.size_request())\n\n        if response.HasField(\"message\"):\n            value = Int32Value()\n            response.message.Unpack(value)\n            return value.value\n        else:\n            return 0\n\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:\n        response: List[NamedCacheResponse] = await self._dispatch_and_wait(\n            self._request_factory.invoke_request(key, processor)\n        )\n\n        if len(response) == 0:\n            return None\n        else:\n            entry = response[0]\n            if entry.HasField(\"message\"):\n                binary_key_value = BinaryKeyAndValue()\n                entry.message.Unpack(binary_key_value)\n                return self._serializer.deserialize(binary_key_value.value)\n\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        response: List[NamedCacheResponse] = await self._dispatch_and_wait(\n            self._request_factory.invoke_all_request(processor, keys, filter)\n        )\n\n        lst = list()\n        for entry in response:\n            if entry.HasField(\"message\"):\n                binary_key_value = BinaryKeyAndValue()\n                entry.message.Unpack(binary_key_value)\n                m = MapEntry(binary_key_value.key, binary_key_value.value)\n                lst.append(m)\n        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)\n\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> R:\n        response: NamedCacheResponse = await self._dispatch_and_wait(\n            self._request_factory.aggregate_request(aggregator, keys, filter)\n        )\n\n        # TODO is this right?\n        if response.HasField(\"message\"):\n            value = BytesValue()\n            response.message.Unpack(value)\n            result = self._serializer.deserialize(value.value)\n            return result\n        else:\n            return None\n\n    def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        pass\n\n    def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        pass\n\n    def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        pass\n\n    async def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n\n        await self._dispatch_and_wait(self._request_factory.add_index_request(extractor, ordered, comparator))\n\n    async def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n\n        await self._dispatch_and_wait(self._request_factory.remove_index_request(extractor))\n\n\nclass TlsOptions:\n    \"\"\"\n    Options specific to the configuration of TLS.\n    \"\"\"\n\n    ENV_CA_CERT = \"COHERENCE_TLS_CERTS_PATH\"\n    \"\"\"\n    Environment variable to configure the path to CA certificates\n    \"\"\"\n    ENV_CLIENT_CERT = \"COHERENCE_TLS_CLIENT_CERT\"\n    \"\"\"\n    Environment variable to configure the path to client certificates\n    \"\"\"\n    ENV_CLIENT_KEY = \"COHERENCE_TLS_CLIENT_KEY\"\n    \"\"\"\n    Environment variable to configure the path to client key\n    \"\"\"\n\n    def __init__(\n        self,\n        locked: bool = False,\n        enabled: bool = False,\n        ca_cert_path: str | None = None,\n        client_cert_path: str | None = None,\n        client_key_path: str | None = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.TlsOptions`\n\n        :param locked: If `true`, prevents further mutations to the options.\n        :param enabled: Enable/disable TLS support.\n        :param ca_cert_path: the path to the CA certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CERTS_PATH\n        :param client_cert_path: the path to the client certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_CERT\n        :param client_key_path: the path to the client certificate key. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_KEY\n        \"\"\"\n        self._locked = locked\n        self._enabled = enabled\n\n        self._ca_cert_path = ca_cert_path if ca_cert_path is not None else os.getenv(TlsOptions.ENV_CA_CERT)\n        self._client_cert_path = (\n            client_cert_path if client_cert_path is not None else os.getenv(TlsOptions.ENV_CLIENT_CERT)\n        )\n        self._client_key_path = client_key_path if client_key_path is not None else os.getenv(TlsOptions.ENV_CLIENT_KEY)\n\n    @property\n    def enabled(self) -> bool:\n        \"\"\"\n        Property to set/get the boolean state if TLS is enabled(true) or disabled(false)\n        \"\"\"\n        return self._enabled\n\n    @enabled.setter\n    def enabled(self, enabled: bool) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._enabled = enabled\n\n    @property\n    def ca_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the CA certificate\n        \"\"\"\n        return self._ca_cert_path\n\n    @ca_cert_path.setter\n    def ca_cert_path(self, ca_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._ca_cert_path = ca_cert_path\n\n    @property\n    def client_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate.\n        \"\"\"\n        return self._client_cert_path\n\n    @client_cert_path.setter\n    def client_cert_path(self, client_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_cert_path = client_cert_path\n\n    @property\n    def client_key_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate key.\n        \"\"\"\n        return self._client_key_path\n\n    @client_key_path.setter\n    def client_key_path(self, client_key_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_key_path = client_key_path\n\n    def locked(self) -> None:\n        \"\"\"\n        Once called, no further mutations can be made.\n        \"\"\"\n        self._locked = True\n\n    def is_locked(self) -> bool:\n        return self._locked\n\n    def __str__(self) -> str:\n        return (\n            f\"TlsOptions(enabled={self.enabled}, ca-cert-path={self.ca_cert_path}, \"\n            f\"client-cert-path={self.client_cert_path}, client-key-path={self.client_key_path})\"\n        )\n\n\nclass Options:\n    \"\"\"\n    Supported :func:`coherence.client.Session` options.\n    \"\"\"\n\n    ENV_SERVER_ADDRESS = \"COHERENCE_SERVER_ADDRESS\"\n    \"\"\"\n    Environment variable to specify the Coherence gRPC server address for the client to connect to. The\n    environment variable is used if address is not passed as an argument in the constructor. If the environment\n    variable is not set and address is not passed as an argument then `DEFAULT_ADDRESS` is used\n    \"\"\"\n    ENV_REQUEST_TIMEOUT = \"COHERENCE_CLIENT_REQUEST_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the request timeout for each remote call. The environment variable is used if\n    request timeout is not passed as an argument in the constructor. If the environment variable is not set and\n    request timeout is not passed as an argument then `DEFAULT_REQUEST_TIMEOUT` of 30 seconds is used\n    \"\"\"\n    ENV_READY_TIMEOUT = \"COHERENCE_READY_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the maximum amount of time an NamedMap or NamedCache operations may wait for the\n    underlying gRPC channel to be ready.  This is independent of the request timeout which sets a deadline on how\n    long the call may take after being dispatched.\n    \"\"\"\n    ENV_SESSION_DISCONNECT_TIMEOUT = \"COHERENCE_SESSION_DISCONNECT_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the maximum amount of time, in seconds, a Session may remain in a disconnected\n    state without successfully reconnecting.\n    \"\"\"\n\n    DEFAULT_ADDRESS: Final[str] = \"localhost:1408\"\n    \"\"\"The default target address to connect to Coherence gRPC server.\"\"\"\n    DEFAULT_SCOPE: Final[str] = \"\"\n    \"\"\"The default scope.\"\"\"\n    DEFAULT_REQUEST_TIMEOUT: Final[float] = 30.0\n    \"\"\"The default request timeout.\"\"\"\n    DEFAULT_READY_TIMEOUT: Final[float] = 0\n    \"\"\"\n    The default ready timeout is 0 which disables the feature by default.  Explicitly configure the ready timeout\n    session option or use the environment variable to specify a positive value indicating how many seconds an RPC will\n    wait for the underlying channel to be ready before failing.\n    \"\"\"\n    DEFAULT_SESSION_DISCONNECT_TIMEOUT: Final[float] = 30.0\n    \"\"\"\n    The default maximum time a session may be in a disconnected state without having successfully reconnected.\n    \"\"\"\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    def __init__(\n        self,\n        address: str = DEFAULT_ADDRESS,\n        scope: str = DEFAULT_SCOPE,\n        request_timeout_seconds: float = DEFAULT_REQUEST_TIMEOUT,\n        ready_timeout_seconds: float = DEFAULT_READY_TIMEOUT,\n        session_disconnect_seconds: float = DEFAULT_SESSION_DISCONNECT_TIMEOUT,\n        ser_format: str = DEFAULT_FORMAT,\n        channel_options: Optional[Sequence[Tuple[str, Any]]] = None,\n        tls_options: Optional[TlsOptions] = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.Options`\n\n        :param address: Address of the target Coherence cluster.  If not explicitly set, this defaults\n          to :func:`coherence.client.Options.DEFAULT_ADDRESS`. See\n          also :func:`coherence.client.Options.ENV_SERVER_ADDRESS`\n        :param scope: scope name used to link this :func:`coherence.client.Options` to the\n          corresponding `ConfigurableCacheFactory` on the server.\n        :param request_timeout_seconds: Defines the request timeout, in `seconds`, that will be applied to each\n          remote call. If not explicitly set, this defaults to :func:`coherence.client.Options.DEFAULT_REQUEST_TIMEOUT`.\n          See also :func:`coherence.client.Options.ENV_REQUEST_TIMEOUT`\n        :param ready_timeout_seconds: Defines the ready timeout, in `seconds`.  If this is a positive\n          float value, remote calls will not fail immediately if no connection is available.  If this is a value of zero\n          or less, then remote calls will fail-fast.  If not explicitly configured, the default of 0 is assumed.\n\n          See also :class:`coherence.client.Options.ENV_READY_TIMEOUT`\n        :param session_disconnect_seconds: Defines the maximum time, in `seconds`, that a session may remain in\n          a disconnected state without successfully reconnecting.\n        :param ser_format: The serialization format.  Currently, this is always `json`\n        :param channel_options: The `gRPC` `ChannelOptions`. See\n            https://grpc.github.io/grpc/python/glossary.html#term-channel_arguments and\n            https://github.com/grpc/grpc/blob/master/include/grpc/impl/grpc_types.h\n        :param tls_options: Optional TLS configuration.\n        \"\"\"\n        addr = os.getenv(Options.ENV_SERVER_ADDRESS)\n        if addr is not None:\n            self._address = addr\n        else:\n            self._address = address\n\n        self._request_timeout_seconds = Options._get_float_from_env(\n            Options.ENV_REQUEST_TIMEOUT, request_timeout_seconds\n        )\n        self._ready_timeout_seconds = Options._get_float_from_env(Options.ENV_READY_TIMEOUT, ready_timeout_seconds)\n        self._session_disconnect_timeout_seconds = Options._get_float_from_env(\n            Options.ENV_READY_TIMEOUT, session_disconnect_seconds\n        )\n\n        self._scope = scope\n        self._ser_format = ser_format\n\n        if channel_options is not None:\n            self._channel_options = channel_options\n\n        if tls_options is not None:\n            self._tls_options = tls_options\n\n    @property\n    def tls_options(self) -> Optional[TlsOptions]:\n        \"\"\"\n        Returns the TLS-specific configuration options.\n\n        :return: the TLS-specific configuration options.\n        \"\"\"\n        return getattr(self, \"_tls_options\", None)\n\n    @tls_options.setter\n    def tls_options(self, tls_options: TlsOptions) -> None:\n        \"\"\"\n        Sets the TLS-specific configuration options.\n\n        :param tls_options: the TLS-specific configuration options.\n        \"\"\"\n        self._tls_options = tls_options\n\n    @property\n    def address(self) -> str:\n        \"\"\"\n        Return the IPv4 host address and port in the format of ``[host]:[port]``.\n\n        :return: the IPv4 host address and port in the format of ``[host]:[port]``.\n        \"\"\"\n        return self._address\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n         server.\n        \"\"\"\n        return self._scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        The serialization format used by this session.  This library currently supports JSON serialization only,\n        thus this always returns 'json'.\n\n        :return: the serialization format used by this session.\n        \"\"\"\n        return self._ser_format\n\n    @property\n    def request_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the request timeout in `seconds`\n\n        :return: the request timeout in `seconds`\n        \"\"\"\n        return self._request_timeout_seconds\n\n    @property\n    def ready_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the ready timeout in `seconds`.\n\n        :return: the ready timeout in `seconds`\n        \"\"\"\n        return self._ready_timeout_seconds\n\n    @property\n    def session_disconnect_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the ready timeout in `seconds`.\n\n        :return: the ready timeout in `seconds`\n        \"\"\"\n        return self._session_disconnect_timeout_seconds\n\n    @property\n    def channel_options(self) -> Optional[Sequence[Tuple[str, Any]]]:\n        \"\"\"\n        Return the `gRPC` `ChannelOptions`.\n\n        :return: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        return getattr(self, \"_channel_options\", None)\n\n    @channel_options.setter\n    def channel_options(self, channel_options: Sequence[Tuple[str, Any]]) -> None:\n        \"\"\"\n        Set the `gRPC` `ChannelOptions`.\n\n        :param channel_options: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        self._channel_options = channel_options\n\n    @staticmethod\n    def _get_float_from_env(variable_name: str, default_value: float) -> float:\n        \"\"\"\n        Return a float value parsed from the provided environment variable name.\n\n        :param variable_name: the environment variable name\n        :param default_value: the value to use if the environment variable is not set\n\n        :return: the float value from the environment or the default if the value can't be parsed\n          or the environment variable is not set\n        \"\"\"\n        timeout = os.getenv(variable_name)\n        if timeout is not None:\n            time_out: float = default_value\n            try:\n                time_out = float(timeout)\n            except ValueError:\n                COH_LOG.warning(\n                    \"The timeout value of [%s] specified by environment variable [%s] cannot be converted to a float\",\n                    timeout,\n                    variable_name,\n                )\n\n            return time_out\n        else:\n            return default_value\n\n    def __str__(self) -> str:\n        return (\n            f\"Options(address={self.address}, scope={self.scope}, format={self.format},\"\n            f\" request-timeout-seconds={self.request_timeout_seconds}, \"\n            f\"ready-timeout-seconds={self.ready_timeout_seconds}, \"\n            f\"session-disconnect-timeout-seconds={self.session_disconnect_timeout_seconds}, \"\n            f\"tls-options={self.tls_options}, \"\n            f\"channel-options={self.channel_options})\"\n        )\n\n\ndef _get_channel_creds(tls_options: TlsOptions) -> grpc.ChannelCredentials:\n    client_cert: bytes | None = None\n    client_key: bytes | None = None\n    ca_cert: bytes | None = None\n\n    if tls_options.client_cert_path is not None:\n        with open(tls_options.client_cert_path, \"rb\") as f:\n            client_cert = f.read()\n    if tls_options.client_key_path is not None:\n        with open(tls_options.client_key_path, \"rb\") as f:\n            client_key = f.read()\n    if tls_options.ca_cert_path is not None:\n        with open(tls_options.ca_cert_path, \"rb\") as f:\n            ca_cert = f.read()\n\n    credentials = grpc.ssl_channel_credentials(ca_cert, client_key, client_cert)\n\n    return credentials\n\n\nclass Session:\n    \"\"\"\n    Session represents a logical connection to an endpoint. It also acts as a factory for creating caches.\n\n    This class emits the following events:\n\n        1. :class:`coherence.event.MapLifecycleEvent.DESTROYED`: when the underlying cache is destroyed\n        2. :class:`coherence.event.MapLifecycleEvent.TRUNCATED`: When the underlying cache is truncated\n        3. :class:`coherence.event.MapLifecycleEvent.RELEASED`: When the underlying cache is released\n        4. :class:`coherence.event.SessionLifecycleEvent.CONNECT`: when the Session detects the underlying `gRPC`\n            channel has connected.\n        5. :class:`coherence.event.SessionLifecycleEvent.DISCONNECT`: when the Session detects the underlying `gRPC`\n            channel has disconnected\n        6. :class:`coherence.event.SessionLifecycleEvent.RECONNECTED`: when the Session detects the underlying `gRPC`\n            channel has re-connected\n        7. :class:`coherence.event.SessionLifecycleEvent.CLOSED`: when the Session has been closed\n\n    \"\"\"\n\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    _initialized = False\n\n    def __init__(self, session_options: Optional[Options] = None):\n        \"\"\"\n        Construct a new `Session` based on the provided :func:`coherence.client.Options`\n\n        :param session_options: the provided :func:`coherence.client.Options`\n        \"\"\"\n        self._closed: bool = False\n        self._session_id: str = str(uuid.uuid4())\n        self._ready = False\n        self._ready_condition: Condition = Condition()\n        self._caches: dict[str, NamedCache[Any, Any]] = dict()\n        # to map cacheId to Cache instance. Not used in v0\n        self._id_to_caches: dict[int, NamedCache[Any, Any]] = dict()\n        self._lock: Lock = Lock()\n        if session_options is not None:\n            self._session_options = session_options\n        else:\n            self._session_options = Options()\n\n        self._ready_timeout_seconds: float = self._session_options.ready_timeout_seconds\n        self._ready_enabled: bool = self._ready_timeout_seconds > 0\n\n        interceptors = [\n            _InterceptorUnaryUnary(self),\n            _InterceptorUnaryStream(self),\n            _InterceptorStreamUnary(self),\n        ]\n\n        # only add the StreamStream interceptor if ready support is enabled as\n        # when added in the non-ready case, the call will not fail-fast\n        if self._ready_enabled:\n            interceptors.append(_InterceptorStreamStream(self))\n\n        self._tasks: Set[Task[None]] = set()\n\n        options: Sequence[tuple[str, Any]] = [\n            (\"grpc.min_reconnect_backoff_ms\", 1100),\n            (\"grpc.max_reconnect_backoff_ms\", 3000),\n            (\"grpc.lb_policy_name\", \"round_robin\"),\n        ]\n\n        self._is_server_grpc_v1 = False\n        self._v1_init_response_details = None\n\n        if self._session_options.tls_options is None:\n            self._channel: grpc.aio.Channel = grpc.aio.insecure_channel(\n                self._session_options.address,\n                options=(\n                    options if self._session_options.channel_options is None else self._session_options.channel_options\n                ),\n                interceptors=interceptors,\n            )\n        else:\n            creds: grpc.ChannelCredentials = _get_channel_creds(self._session_options.tls_options)\n            self._channel = grpc.aio.secure_channel(\n                self._session_options.address,\n                creds,\n                options=(\n                    options if self._session_options.channel_options is None else self._session_options.channel_options\n                ),\n                interceptors=interceptors,\n            )\n\n        watch_task: Task[None] = asyncio.create_task(watch_channel_state(self))\n        self._tasks.add(watch_task)\n        self._emitter: EventEmitter = EventEmitter()\n        self._channel.get_state(True)  # trigger connect\n\n    @staticmethod\n    async def create(session_options: Optional[Options] = None) -> Session:\n        session: Session = Session(session_options)\n        await session._set_ready(False)\n        return session\n\n    # noinspection PyTypeHints\n    @_pre_call_session\n    def on(\n        self,\n        event: Literal[MapLifecycleEvent.DESTROYED] | Literal[MapLifecycleEvent.RELEASED] | SessionLifecycleEvent,\n        callback: Callable[[str], None] | Callable[[], None],\n    ) -> None:\n        \"\"\"\n        Register a callback to be invoked when the following events are raised:\n\n        * MapLifecycleEvent.DESTROYED\n        * MapLifecycleEvent.RELEASED\n        * Any SessionLifecycleEvent\n\n        The callbacks defined for MapLifecycleEvent DESTROYED and RELEASED should accept a single string\n        argument representing the cache name that the event was raised for.\n\n        The SessionLifecycleEvent callbacks should not accept call arguments.\n        :param event:     the event to listener for\n        :param callback:  the callback to invoke when the event is raised\n        \"\"\"\n        self._emitter.on(str(event.value), callback)\n\n    @property\n    def channel(self) -> grpc.aio.Channel:\n        \"\"\"\n        Return the underlying `gRPC` Channel used by this session.\n\n        :return: the underlying `gRPC` Channel used by this session.\n        \"\"\"\n        return self._channel\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n          server.\n        \"\"\"\n        return self._session_options.scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        Returns the default serialization format used by the `Session`\n\n        :return: the default serialization format used by the `Session`\n        \"\"\"\n        return self._session_options.format\n\n    @property\n    def options(self) -> Options:\n        \"\"\"\n        Return the :func:`coherence.client.Options` (read-only) used to configure this session.\n\n        :return: the :func:`coherence.client.Options` (read-only) used to configure this session.\n        \"\"\"\n        return self._session_options\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"\n        Returns `True` if Session is closed else `False`.\n\n        :return: `True` if Session is closed else `False`\n        \"\"\"\n        return self._closed\n\n    @property\n    def session_id(self) -> str:\n        \"\"\"\n        Returns this Session's ID.\n\n        :return: this Session's ID\n        \"\"\"\n        return self._session_id\n\n    def __str__(self) -> str:\n        return (\n            f\"Session(id={self.session_id}, closed={self.closed}, state={self._channel.get_state(False)},\"\n            f\" caches/maps={len(self._caches)}, options={self.options})\"\n        )\n\n    def update_cache_id_map(self, cache_id: int, cache: NamedCache[K, V]) -> None:\n        self._id_to_caches.update({cache_id: cache})\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_cache(self, name: str, ser_format: str = DEFAULT_FORMAT) -> NamedCache[K, V]:\n        \"\"\"\n        Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n\n        :param name: the cache name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n        \"\"\"\n        serializer = SerializerRegistry.serializer(ser_format)\n        if not Session._initialized:\n            check_result = await self._check_server_grpc_version_is_v1()\n            Session._initialized = True\n            if check_result is None:  # Server is running grpc v0\n                self._is_server_grpc_v1 = False\n            else:  # Server is running grpc v1\n                self._is_server_grpc_v1 = True\n                self._v1_init_response_details = check_result\n\n        if not self._is_server_grpc_v1:\n            with self._lock:\n                c = self._caches.get(name)\n                if c is None:\n                    c = NamedCacheClient(name, self, serializer)\n                    # initialize the event stream now to ensure lifecycle listeners will work as expected\n                    await c._events_manager._ensure_stream()\n                    self._setup_event_handlers(c)\n                    self._caches.update({name: c})\n                return c\n        else:  # Server is running grpc v1\n            with self._lock:\n                c = self._caches.get(name)\n                if c is None:\n                    c = NamedCacheClientV1(name, self, serializer)\n                    await c.ensure_cache()\n                    # initialize the event stream now to ensure lifecycle listeners will work as expected\n                    # await c._events_manager._ensure_stream()\n                    # self._setup_event_handlers(c)\n                    self._caches.update({name: c})\n                return c\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_map(self, name: str, ser_format: str = DEFAULT_FORMAT) -> NamedMap[K, V]:\n        \"\"\"\n        Returns a :func:`coherence.client.NameMap` for the specified cache name.\n\n        :param name: the map name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedMap` for the specified cache name.\n        \"\"\"\n        serializer = SerializerRegistry.serializer(ser_format)\n        if not Session._initialized:\n            check_result = await self._check_server_grpc_version_is_v1()\n            Session._initialized = True\n            if check_result is None:  # Server is running grpc v0\n                self._is_server_grpc_v1 = False\n            else:  # Server is running grpc v1\n                self._is_server_grpc_v1 = True\n                self._v1_init_response_details = check_result\n\n        if not self._is_server_grpc_v1:\n            with self._lock:\n                c = self._caches.get(name)\n                if c is None:\n                    c = NamedCacheClient(name, self, serializer)\n                    # initialize the event stream now to ensure lifecycle listeners will work as expected\n                    await c._events_manager._ensure_stream()\n                    self._setup_event_handlers(c)\n                    self._caches.update({name: c})\n                return c\n        else:  # Server is running grpc v1\n            with self._lock:\n                c = self._caches.get(name)\n            if c is None:\n                c = NamedCacheClientV1(name, self, serializer)\n                await c.ensure_cache()\n                # initialize the event stream now to ensure lifecycle listeners will work as expected\n                # await c._events_manager._ensure_stream()\n                # self._setup_event_handlers(c)\n                self._caches.update({name: c})\n            return c\n\n    def is_ready(self) -> bool:\n        \"\"\"\n        Returns\n        :return:\n        \"\"\"\n        if self._closed:\n            return False\n\n        return True if not self._ready_enabled else self._ready\n\n    async def _set_ready(self, ready: bool) -> None:\n        self._ready = ready\n        if self._ready:\n            if not self._ready_condition.locked():\n                await self._ready_condition.acquire()\n            self._ready_condition.notify_all()\n            self._ready_condition.release()\n        else:\n            await self._ready_condition.acquire()\n\n    async def _wait_for_ready(self) -> None:\n        if self._ready_enabled and not self.is_ready():\n            timeout: float = self._ready_timeout_seconds\n            COH_LOG.debug(f\"Waiting for session {self.session_id} to become active; timeout=[{timeout} seconds]\")\n            try:\n                await asyncio.wait_for(self._ready_condition.wait(), timeout)\n            except TimeoutError:\n                s = \"Deadline [{0} seconds] exceeded \" \"waiting for session {1} to become active\".format(\n                    str(timeout), self.session_id\n                )\n                raise TimeoutError(s)\n\n    # noinspection PyUnresolvedReferences\n    async def close(self) -> None:\n        \"\"\"\n        Close the `Session`\n        \"\"\"\n        if not self._closed:\n            self._closed = True\n            self._emitter.emit(SessionLifecycleEvent.CLOSED.value)\n            for task in self._tasks:\n                task.cancel()\n            self._tasks.clear()\n\n            caches_copy: dict[str, NamedCache[Any, Any]] = self._caches.copy()\n            for cache in caches_copy.values():\n                cache.release()\n\n            self._caches.clear()\n\n            await self._channel.close()  # TODO: consider grace period?\n            self._channel = None\n\n    def _setup_event_handlers(self, client: NamedCacheClient[K, V]) -> None:\n        this: Session = self\n\n        def on_destroyed(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        def on_released(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        client.on(MapLifecycleEvent.DESTROYED, on_destroyed)\n        client.on(MapLifecycleEvent.RELEASED, on_released)\n\n    async def _check_server_grpc_version_is_v1(self) -> object:\n        stub = proxy_service_v1_pb2_grpc.ProxyServiceStub(self._channel)\n        stream = stub.subChannel()\n        results: dict[str, Any] = dict()\n        results[\"stub\"] = stub\n        results[\"stream\"] = stream\n\n        try:\n            response = await self._send_init_request(stream)\n            results[\"init_response\"] = response\n            return results\n        except grpc.aio._call.AioRpcError:\n            return None\n\n    async def _send_init_request(self, stream) -> object:\n        # InitRequest\n        init_request = proxy_service_messages_v1_pb2.ProxyRequest(\n            id=2,\n            init=self._create_init_request(),\n        )\n        await stream.write(init_request)\n        try:\n            response = await stream.read()\n            # COH_LOG.info(response)\n            # COH_LOG.info(\"InitRequest request completed.\")\n            return response\n        except grpc.aio._call.AioRpcError as e:\n            if e.details() == \"Method not found: coherence.proxy.v1.ProxyService/subChannel\":\n                COH_LOG.info(\"Server is not running v1 gRPC version\")\n            raise e\n\n    def _create_init_request(self) -> proxy_service_messages_v1_pb2.InitRequest:\n\n        init_request = proxy_service_messages_v1_pb2.InitRequest(\n            scope=\"\",\n            format=\"json\",\n            protocol=\"CacheService\",\n            protocolVersion=1,\n            supportedProtocolVersion=1,\n            heartbeat=0,\n        )\n\n        return init_request\n\n    # Commented out as it doesn't appear valid or used\n    # @property\n    # def request_id_map(self):\n    #     return self._request_id_map\n\n\n# noinspection PyArgumentList\nclass _BaseInterceptor:\n    \"\"\"Base client interceptor to enable waiting for channel connectivity and\n    set call timeouts.\n    Having this base class and four concrete implementations is due to\n    https://github.com/grpc/grpc/issues/31442\"\"\"\n\n    def __init__(self, session: Session):\n        self._session: Session = session\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def _do_intercept(self, continuation, client_call_details, request):\n        \"\"\"\n        Intercepts a gRPC call setting our specific options for the call.\n        :param continuation:         the gRPC call continuation\n        :param client_call_details:  the call details\n        :param request:              the gRPC request (if any)\n        :return:                     the result of the call\n        \"\"\"\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            self._session.options.request_timeout_seconds,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True if self._session._ready_enabled else None,\n        )\n        return await continuation(new_details, request)\n\n\nclass _InterceptorUnaryUnary(_BaseInterceptor, grpc.aio.UnaryUnaryClientInterceptor):\n    \"\"\"Interceptor for Unary/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorUnaryStream(_BaseInterceptor, grpc.aio.UnaryStreamClientInterceptor):\n    \"\"\"Interceptor for Unary/Stream calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_stream(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamUnary(_BaseInterceptor, grpc.aio.StreamUnaryClientInterceptor):\n    \"\"\"Interceptor for Stream/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamStream(_BaseInterceptor, grpc.aio.StreamStreamClientInterceptor):\n    \"\"\"Interceptor for Stream/Stream calls.\"\"\"\n\n    # noinspection PyArgumentList,PyUnresolvedReferences\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_stream(self, continuation, client_call_details, request):\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            client_call_details.timeout,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True,\n        )\n\n        return await continuation(new_details, request)\n\n\n# noinspection PyProtectedMember\nasync def watch_channel_state(session: Session) -> None:\n    emitter: EventEmitter = session._emitter\n    channel: grpc.aio.Channel = session.channel\n    first_connect: bool = True\n    connected: bool = False\n    last_state: grpc.ChannelConnectivity = grpc.ChannelConnectivity.IDLE\n    disconnect_time: float = 0\n\n    def current_milli_time() -> float:\n        return round(time.time() * 1000)\n\n    try:\n        while True:\n            state: grpc.ChannelConnectivity = channel.get_state(True)\n            if COH_LOG.isEnabledFor(logging.DEBUG):\n                COH_LOG.debug(f\"New Channel State: transitioning from [{last_state}] to [{state}].\")\n            if state == grpc.ChannelConnectivity.SHUTDOWN:\n                COH_LOG.info(f\"Session [{session.session_id}] terminated.\")\n                await session._set_ready(False)\n                await session.close()\n                return\n            elif state == grpc.ChannelConnectivity.READY:\n                if not first_connect and not connected:\n                    connected = True\n                    disconnect_time = 0\n                    COH_LOG.info(f\"Session [{session.session_id} re-connected to [{session.options.address}].\")\n                    await emitter.emit_async(SessionLifecycleEvent.RECONNECTED.value)\n                    await session._set_ready(True)\n                elif first_connect and not connected:\n                    connected = True\n                    COH_LOG.info(f\"Session [{session.session_id}] connected to [{session.options.address}].\")\n\n                    first_connect = False\n                    await emitter.emit_async(SessionLifecycleEvent.CONNECTED.value)\n                    await session._set_ready(True)\n            else:\n                if connected:\n                    connected = False\n                    disconnect_time = -1\n                    COH_LOG.warning(\n                        f\"Session [{session.session_id}] disconnected from [{session.options.address}];\"\n                        f\" will attempt reconnect.\"\n                    )\n\n                    await emitter.emit_async(SessionLifecycleEvent.DISCONNECTED.value)\n                    await session._set_ready(False)\n\n                if disconnect_time != 0:\n                    if disconnect_time == -1:\n                        disconnect_time = current_milli_time()\n                    else:\n                        waited: float = current_milli_time() - disconnect_time\n                        timeout = session.options.session_disconnect_timeout_seconds\n                        if COH_LOG.isEnabledFor(logging.DEBUG):\n                            COH_LOG.debug(\n                                f\"Waited [{waited / 1000} seconds] for session [{session.session_id}] to reconnect.\"\n                                f\" [~{(round(timeout - (waited / 1000)))} seconds] remaining to reconnect.\"\n                            )\n                        if waited >= timeout:\n                            COH_LOG.error(\n                                f\"session [{session.session_id}] unable to reconnect within [{timeout} seconds.\"\n                                f\"  Closing session.\"\n                            )\n                            await session.close()\n                            return\n\n            state = channel.get_state(True)\n            if COH_LOG.isEnabledFor(logging.DEBUG):\n                COH_LOG.debug(f\"Waiting for state change from [{state}]\")\n            await channel.wait_for_state_change(state)\n    except asyncio.CancelledError:\n        return\n\n\nclass _Stream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    A simple AsyncIterator that wraps a Callable that produces iteration\n    elements.\n    \"\"\"\n\n    def __init__(\n        self,\n        serializer: Serializer,\n        stream: grpc.Channel.unary_stream,\n        next_producer: Callable[[Serializer, grpc.Channel.unary_stream], Awaitable[T]],\n    ) -> None:\n        super().__init__()\n        # A function that may be called to produce a series of results\n        self._next_producer = next_producer\n\n        # the Serializer that should be used to deserialize results\n        self._serializer = serializer\n\n        # the gRPC stream providing results\n        self._stream = stream\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    def __anext__(self) -> Awaitable[T]:\n        return self._next_producer(self._serializer, self._stream)\n\n\n# noinspection PyProtectedMember\nclass _PagedStream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    An AsyncIterator that will stream results in pages.\n    \"\"\"\n\n    def __init__(\n        self, client: NamedCacheClient[K, V], result_handler: Callable[[Serializer, Any], Any], keys: bool = False\n    ) -> None:\n        super().__init__()\n        # flag indicating that all pages have been processed\n        self._exhausted: bool = False\n\n        # the gRPC client\n        self._client: NamedCacheClient[K, V] = client\n\n        # the handler responsible for deserializing the result\n        self._result_handler: Callable[[Serializer, Any], Any] = result_handler\n\n        # the serializer to be used when deserializing streamed results\n        self._serializer: Serializer = client._request_factory.get_serializer()\n\n        # cookie that tracks page streaming; used for each new page request\n        self._cookie: bytes = bytes()\n\n        # the gRPC stream providing the results\n        self._stream: grpc.Channel.unary_stream = None\n\n        # flag indicating a new page has been loaded\n        self._new_page: bool = True\n\n        # flag indicating that pages will be keys only\n        self._keys: bool = keys\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    async def __anext__(self) -> T:\n        # keep the loop running to ensure we don't exit\n        # prematurely which would result in a None value\n        # being returned incorrectly between pages\n        while True:\n            if self._stream is None and not self._exhausted:\n                await self.__load_next_page()\n\n            if self._stream is None and self._exhausted:\n                raise StopAsyncIteration\n\n            async for item in self._stream:\n                if self._new_page:  # a new page has been loaded; the cookie will be the first result\n                    self._new_page = False\n                    self._cookie = item.value if self._keys else item.cookie\n                    if self._cookie == b\"\":\n                        self._exhausted = True  # processing the last page\n                else:\n                    return self._result_handler(self._serializer, item)\n\n            self._stream = None\n            if self._exhausted:\n                raise StopAsyncIteration\n\n    # noinspection PyProtectedMember\n    async def __load_next_page(self) -> None:\n        \"\"\"\n        Requests the next page of results to be streamed.\n\n        :return: None\n        \"\"\"\n        request: PageRequest = self._client._request_factory.page_request(self._cookie)\n        self._stream = self._get_stream(request)\n        self._new_page = True\n\n    def _get_stream(self, request: PageRequest) -> grpc.Channel.unary_stream:\n        \"\"\"\n        Obtain the gRPC unary_stream for the provided PageRequest.\n\n        :param request: the PageRequest\n        :return: the gRPC unary_stream for the given request\n        \"\"\"\n        client_stub: NamedCacheServiceStub = self._client._client_stub\n        return client_stub.nextKeySetPage(request) if self._keys else client_stub.nextEntrySetPage(request)\n\n\ndef _scalar_deserializer(serializer: Serializer, item: Any) -> Any:\n    \"\"\"\n    Helper method to deserialize a key or value returned in a stream.\n\n    :param serializer: the serializer that should be used\n    :param item: the key or value to deserialize\n    :return: the deserialized key or value\n    \"\"\"\n    return serializer.deserialize(item.value)\n\n\ndef _entry_deserializer(serializer: Serializer, item: Any) -> MapEntry[Any, Any]:\n    \"\"\"\n    Helper method to deserialize entries returned in a stream.\n\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param item: the entry\n    :return: the deserialized entry\n    \"\"\"\n    return MapEntry(serializer.deserialize(item.key), serializer.deserialize(item.value))\n\n\nasync def _scalar_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> T:\n    \"\"\"\n    Helper method to iterate over a stream and produce scalar results.\n\n    :param serializer: the serializer that should be used to deserialize the scalar value\n    :param stream: the gRPC stream\n    :return: one or more deserialized scalar values\n    \"\"\"\n    async for item in stream:\n        return _scalar_deserializer(serializer, item)\n    raise StopAsyncIteration\n\n\nasync def _entry_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> MapEntry[K, V]:\n    \"\"\"\n    Helper method to iterate over a stream and produce MapEntry instances\n    .\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param stream: the gRPC stream\n    :return: one or more deserialized MapEntry instances\n    \"\"\"\n    async for item in stream:\n        return _entry_deserializer(serializer, item)\n    raise StopAsyncIteration\n\n\nasync def _entry_producer_from_list(serializer: Serializer, the_list: list[Any]) -> MapEntry[K, V]:\n    if len(the_list) == 0:\n        raise StopAsyncIteration\n    for item in the_list:\n        await asyncio.sleep(0)\n        the_list.pop(0)\n        return _entry_deserializer(serializer, item)\n\n\nclass _ListAsyncIterator(abc.ABC, AsyncIterator[T]):\n    def __init__(\n        self,\n        serializer: Serializer,\n        the_list: list[T],\n        next_producer: Callable[[Serializer, list[T]], Awaitable[T]],\n    ) -> None:\n        super().__init__()\n        # A function that may be called to produce a series of results\n        self._next_producer = next_producer\n\n        # the Serializer that should be used to deserialize results\n        self._serializer = serializer\n\n        # the gRPC stream providing results\n        self._the_list = the_list\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    def __anext__(self) -> Awaitable[T]:\n        return self._next_producer(self._serializer, self._the_list)\n\n\nclass StreamHandler:\n    theStreamHandler = None\n\n    def __init__(self, session: Session, stream: grpc.aio._call.StreamStreamCall):\n        self._session: Session = session\n        self._stream: grpc.aio._call.StreamStreamCall = stream\n        self._request_id_to_event_map: dict[int, Event] = dict()\n        self._request_id_request_map: dict[int, NamedCacheRequest] = dict()\n        self.result_available = Event()\n        self.result_available.clear()\n        self.response_result: NamedCacheResponse | None = None\n        self.response_result_collection: list[NamedCacheResponse] = list()\n        self._background_tasks = set()\n        task = asyncio.create_task(self.handle_response())\n        self._background_tasks.add(task)\n        task.add_done_callback(self._background_tasks.discard)\n\n    @property\n    def session(self) -> Session:\n        return self._session\n\n    @property\n    def stream(self) -> grpc.aio._call.StreamStreamCall:\n        return self._stream\n\n    @classmethod\n    def get_stream_handler(cls, session: Session, stream: grpc.aio._call.StreamStreamCall) -> StreamHandler:\n        if cls.theStreamHandler is None:\n            cls.theStreamHandler = StreamHandler(session, stream)\n            return cls.theStreamHandler\n        else:\n            return cls.theStreamHandler\n\n    async def handle_response(self) -> None:\n        COH_LOG.setLevel(logging.DEBUG)\n        while not self.session.closed:\n            await asyncio.sleep(0)\n            response = await self.stream.read()\n            response_id = response.id\n            COH_LOG.debug(f\"response_id: {response_id}\")\n            if response_id == 0:\n                self.handle_zero_id_response(response)\n            else:\n                if response.HasField(\"message\"):\n                    req_type = self._request_id_request_map[response_id].type\n                    if req_type == NamedCacheRequestType.EnsureCache:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        # COH_LOG.info(f\"cache_id: {named_cache_response.cacheId}\")\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.Put:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.PutIfAbsent:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.Get:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.GetAll:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result_collection.append(named_cache_response)\n                    elif req_type == NamedCacheRequestType.Remove:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.Replace:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.RemoveMapping:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.ReplaceMapping:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.ContainsKey:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.ContainsValue:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.IsEmpty:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.Size:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    elif req_type == NamedCacheRequestType.Invoke:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result_collection.append(named_cache_response)\n                    elif req_type == NamedCacheRequestType.Aggregate:\n                        named_cache_response = NamedCacheResponse()\n                        response.message.Unpack(named_cache_response)\n                        self.response_result = named_cache_response\n                    else:\n                        pass\n                elif response.HasField(\"init\"):\n                    self._request_id_to_event_map.pop(response_id)\n                    print(\"InitRequest request completed.\")\n                    self.result_available.set()\n                elif response.HasField(\"error\"):\n                    error_message = response.error\n                    print(f\"EnsureCache request failed with error: {error_message}\")\n                    return\n                elif response.HasField(\"complete\"):\n                    # self.session.request_id_map.pop(response_id)\n                    # COH_LOG.info(\"Complete response received successfully.\")\n                    self._request_id_to_event_map[response_id].set()\n\n    async def get_response(self, response_id: int) -> NamedCacheResponse:\n        await self._request_id_to_event_map[response_id].wait()\n        result = self.response_result\n        self.response_result = None\n        self._request_id_to_event_map[response_id].clear()\n        self._request_id_to_event_map.pop(response_id)\n        self._request_id_request_map.pop(response_id)\n        return result\n\n    async def get_response_collection(self, response_id: int) -> list[NamedCacheResponse]:\n        await self._request_id_to_event_map[response_id].wait()\n        result = self.response_result_collection\n        self.response_result_collection = list()\n        self._request_id_to_event_map[response_id].clear()\n        self._request_id_to_event_map.pop(response_id)\n        self._request_id_request_map.pop(response_id)\n        return result\n\n    async def write_request(\n        self,\n        proxy_request: proxy_service_messages_v1_pb2.ProxyRequest,\n        request_id: int,\n        request: NamedCacheRequest,\n    ) -> None:\n        self._request_id_to_event_map[request_id] = Event()\n        self._request_id_to_event_map[request_id].clear()\n        self._request_id_request_map[request_id] = request\n        await self._stream.write(proxy_request)\n\n    def handle_zero_id_response(self, response) -> None:\n        if response.HasField(\"message\"):\n            named_cache_response = NamedCacheResponse()\n            response.message.Unpack(named_cache_response)\n            type = named_cache_response.type\n            # cache_id = named_cache_response.cacheId\n            if type == ResponseType.Message:\n                pass\n            elif type == ResponseType.MapEvent:\n                # Handle MapEvent Response\n                COH_LOG.debug(\"MapEvent Response type received\")\n                response_json = MessageToJson(named_cache_response)\n                COH_LOG.debug(response_json)\n                pass\n            elif type == ResponseType.Destroyed:\n                # Handle Destroyed Response\n                COH_LOG.debug(\"Destroyed Response type received\")\n                response_json = MessageToJson(named_cache_response)\n                COH_LOG.debug(response_json)\n                pass\n            elif type == ResponseType.Truncated:\n                # Handle Truncated Response\n                COH_LOG.debug(\"Truncated Response type received\")\n                response_json = MessageToJson(named_cache_response)\n                COH_LOG.debug(response_json)\n            else:\n                pass\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/client.py b/src/coherence/client.py
--- a/src/coherence/client.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/src/coherence/client.py	(date 1726015383491)
@@ -39,19 +39,19 @@
 from proxy_service_messages_v1_pb2 import ProxyRequest
 from pymitter import EventEmitter
 
-from . import proxy_service_messages_v1_pb2, proxy_service_v1_pb2_grpc
+from . import proxy_service_messages_v1_pb2
 from .aggregator import AverageAggregator, EntryAggregator, PriorityAggregator, SumAggregator
 from .common_messages_v1_pb2 import BinaryKeyAndValue, OptionalValue
 from .comparator import Comparator
-from .event import MapLifecycleEvent, MapListener, SessionLifecycleEvent
+from .event import MapLifecycleEvent, MapListener, SessionLifecycleEvent, _MapEventsManagerV0, _MapEventsManagerV1
 from .extractor import ValueExtractor
 from .filter import Filter
 from .messages_pb2 import PageRequest
 from .processor import EntryProcessor
+from .proxy_service_v1_pb2_grpc import ProxyServiceStub
 from .serialization import Serializer, SerializerRegistry
 from .services_pb2_grpc import NamedCacheServiceStub
-from .util import RequestFactory
-from .util_v1 import RequestFactoryV1
+from .util import RequestFactory, RequestFactoryV1
 
 E = TypeVar("E")
 K = TypeVar("K")
@@ -228,7 +228,7 @@
         """
 
     @abc.abstractmethod
-    async def put(self, key: K, value: V) -> V:
+    async def put(self, key: K, value: V) -> Optional[V]:
         """
         Associates the specified value with the specified key in this map. If the
         map previously contained a mapping for this key, the old value is replaced.
@@ -242,7 +242,7 @@
         """
 
     @abc.abstractmethod
-    async def put_if_absent(self, key: K, value: V) -> V:
+    async def put_if_absent(self, key: K, value: V) -> Optional[V]:
         """
         If the specified key is not already associated with a value (or is mapped to `None`) associates
         it with the given value and returns `None`, else returns the current value.
@@ -298,7 +298,7 @@
         """
 
     @abc.abstractmethod
-    async def remove(self, key: K) -> V:
+    async def remove(self, key: K) -> Optional[V]:
         """
         Removes the mapping for a key from this map if it is present.
 
@@ -317,7 +317,7 @@
         """
 
     @abc.abstractmethod
-    async def replace(self, key: K, value: V) -> V:
+    async def replace(self, key: K, value: V) -> Optional[V]:
         """
         Replaces the entry for the specified key only if currently mapped to the specified value.
 
@@ -374,7 +374,7 @@
         """
 
     @abc.abstractmethod
-    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:
+    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:
         """
         Invoke the passed EntryProcessor against the Entry specified by the
         passed key, returning the result of the invocation.
@@ -411,7 +411,7 @@
     @abc.abstractmethod
     async def aggregate(
         self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
-    ) -> R:
+    ) -> Optional[R]:
         """
         Perform an aggregating operation against the entries specified by the passed keys.
 
@@ -428,7 +428,7 @@
         """
         Return a Set of the values contained in this map that satisfy the criteria expressed by the filter.
         If no filter or comparator is specified, it returns a Set view of the values contained in this map.The
-        collection is backed by the map, so changes to the map are reflected in the collection, and vice-versa. If
+        collection is backed by the map, so changes to the map are reflected in the collection, and vice versa. If
         the map is modified while an iteration over the collection is in progress (except through the iterator's own
         `remove` operation), the results of the iteration are undefined.
 
@@ -509,7 +509,7 @@
     """
 
     @abc.abstractmethod
-    async def put(self, key: K, value: V, ttl: int = 0) -> V:
+    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:  # type: ignore
         """
         Associates the specified value with the specified key in this map. If the map previously contained a mapping
         for this key, the old value is replaced.
@@ -524,7 +524,7 @@
         """
 
     @abc.abstractmethod
-    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:
+    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:  # type: ignore
         """
         If the specified key is not already associated with a value (or is mapped to null) associates it with the
         given value and returns `None`, else returns the current value.
@@ -550,11 +550,10 @@
         self._destroyed: bool = False
         self._released: bool = False
         self._session: Session = session
-        from .event import _MapEventsManager
 
         self._setup_event_handlers()
 
-        self._events_manager: _MapEventsManager[K, V] = _MapEventsManager(
+        self._events_manager: _MapEventsManagerV0[K, V] = _MapEventsManagerV0(
             self, session, self._client_stub, serializer, self._internal_emitter
         )
 
@@ -599,13 +598,13 @@
         return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)
 
     @_pre_call_cache
-    async def put(self, key: K, value: V, ttl: int = 0) -> V:
+    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:
         p = self._request_factory.put_request(key, value, ttl)
         v = await self._client_stub.put(p)
         return self._request_factory.get_serializer().deserialize(v.value)
 
     @_pre_call_cache
-    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:
+    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:
         p = self._request_factory.put_if_absent_request(key, value, ttl)
         v = await self._client_stub.putIfAbsent(p)
         return self._request_factory.get_serializer().deserialize(v.value)
@@ -639,7 +638,7 @@
         await self._client_stub.truncate(r)
 
     @_pre_call_cache
-    async def remove(self, key: K) -> V:
+    async def remove(self, key: K) -> Optional[V]:
         r = self._request_factory.remove_request(key)
         v = await self._client_stub.remove(r)
         return self._request_factory.get_serializer().deserialize(v.value)
@@ -651,7 +650,7 @@
         return self._request_factory.get_serializer().deserialize(v.value)
 
     @_pre_call_cache
-    async def replace(self, key: K, value: V) -> V:
+    async def replace(self, key: K, value: V) -> Optional[V]:
         r = self._request_factory.replace_request(key, value)
         v = await self._client_stub.replace(r)
         return self._request_factory.get_serializer().deserialize(v.value)
@@ -687,7 +686,7 @@
         return self._request_factory.get_serializer().deserialize(v.value)
 
     @_pre_call_cache
-    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:
+    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:
         r = self._request_factory.invoke_request(key, processor)
         v = await self._client_stub.invoke(r)
         return self._request_factory.get_serializer().deserialize(v.value)
@@ -704,7 +703,7 @@
     @_pre_call_cache
     async def aggregate(
         self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
-    ) -> R:
+    ) -> Optional[R]:
         r = self._request_factory.aggregate_request(aggregator, keys, filter)
         results = await self._client_stub.aggregate(r)
         value: Any = self._request_factory.get_serializer().deserialize(results.value)
@@ -843,13 +842,15 @@
         self._cache_name: str = cache_name
         self._cache_id: int = 0
         self._serializer: Serializer = serializer
-        self._client_stub: proxy_service_v1_pb2_grpc.ProxyServiceStub = session._v1_init_response_details.get("stub")
-        self._client_stream: grpc.aio._call.StreamStreamCall = session._v1_init_response_details.get("stream")
+        self._client_stub: ProxyServiceStub = cast(ProxyServiceStub, session._v1_init_response_details.get("stub"))
+        self._client_stream: grpc.aio._call.StreamStreamCall = cast(
+            grpc.aio._call.StreamStreamCall, session._v1_init_response_details.get("stream")
+        )
         self._request_factory: RequestFactoryV1 = RequestFactoryV1(
             cache_name, self._cache_id, session.scope, serializer
         )
-        # self._emitter: EventEmitter = EventEmitter()
-        # self._internal_emitter: EventEmitter = EventEmitter()
+        self._emitter: EventEmitter = EventEmitter()
+        self._internal_emitter: EventEmitter = EventEmitter()
         self._destroyed: bool = False
         self._released: bool = False
         self._session: Session = session
@@ -857,11 +858,11 @@
         # asyncio.create_task(self._stream_handler.handle_response())
         # from .event import _MapEventsManager
 
-        # self._setup_event_handlers()
+        self._setup_event_handlers()
 
-        # self._events_manager: _MapEventsManager[K, V] = _MapEventsManager(
-        #     self, session, self._client_stub, serializer, self._internal_emitter
-        # )
+        self._events_manager: _MapEventsManagerV1[K, V] = _MapEventsManagerV1(
+            self, session, serializer, self._internal_emitter
+        )
 
     async def _dispatch_and_wait(self, request: NamedCacheRequest) -> Any:
         proxy_request: ProxyRequest = self._request_factory.create_proxy_request(request)
@@ -870,6 +871,37 @@
         # TODO: use timeout from configuration
         return await asyncio.wait_for(self._stream_handler.get_response(request_id), 10.0)
 
+    def _setup_event_handlers(self) -> None:
+        """
+        Setup handlers to notify cache-level handlers of events.
+        """
+        emitter: EventEmitter = self._emitter
+        internal_emitter: EventEmitter = self._internal_emitter
+        this: NamedCacheClientV1[K, V] = self
+        cache_name = self._cache_name
+
+        # noinspection PyProtectedMember
+        def on_destroyed(name: str) -> None:
+            if name == cache_name and not this.destroyed:
+                this._events_manager._close()
+                this._destroyed = True
+                emitter.emit(MapLifecycleEvent.DESTROYED.value, name)
+
+        # noinspection PyProtectedMember
+        def on_released(name: str) -> None:
+            if name == cache_name and not this.released:
+                this._events_manager._close()
+                this._released = True
+                emitter.emit(MapLifecycleEvent.RELEASED.value, name)
+
+        def on_truncated(name: str) -> None:
+            if name == cache_name:
+                emitter.emit(MapLifecycleEvent.TRUNCATED.value, name)
+
+        internal_emitter.on(MapLifecycleEvent.DESTROYED.value, on_destroyed)
+        internal_emitter.on(MapLifecycleEvent.RELEASED.value, on_released)
+        internal_emitter.on(MapLifecycleEvent.TRUNCATED.value, on_truncated)
+
     @property
     def cache_id(self) -> int:
         return self._cache_id
@@ -878,6 +910,7 @@
     def cache_id(self, cache_id: int) -> None:
         self._cache_id = cache_id
 
+    @_pre_call_cache
     async def ensure_cache(self) -> None:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.ensure_request(self._cache_name)
@@ -887,6 +920,7 @@
         self._session.update_cache_id_map(self.cache_id, self)
         self._request_factory.cache_id = response.cacheId
 
+    @_pre_call_cache
     async def get(self, key: K) -> Optional[V]:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.get_request(key))
 
@@ -900,21 +934,23 @@
         else:
             return None
 
-    async def put(self, key: K, value: V, ttl: int = 0) -> V:
+    @_pre_call_cache
+    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.put_request(key, value, ttl))
 
         if response is None:
             return None
         else:
             if response.HasField("message"):
-                value = BytesValue()
-                response.message.Unpack(value)
-                result: V = self._serializer.deserialize(value.value)
+                bytes_value = BytesValue()
+                response.message.Unpack(bytes_value)
+                result: V = self._serializer.deserialize(bytes_value.value)
                 return result
             else:
                 return None
 
-    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> V:
+    @_pre_call_cache
+    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.put_if_absent_request(key, value, ttl)
         )
@@ -923,9 +959,9 @@
             return None
         else:
             if response.HasField("message"):
-                value = BytesValue()
-                response.message.Unpack(value)
-                result: V = self._serializer.deserialize(value.value)
+                bytes_value = BytesValue()
+                response.message.Unpack(bytes_value)
+                result: V = self._serializer.deserialize(bytes_value.value)
                 return result
             else:
                 return None
@@ -939,20 +975,23 @@
 
     @property
     def destroyed(self) -> bool:
-        pass
+        return False  # TODO
 
     @property
     def released(self) -> bool:
-        pass
+        return False  # TODO
 
+    @_pre_call_cache
     async def add_map_listener(
         self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False
     ) -> None:
         pass
 
+    @_pre_call_cache
     async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:
         pass
 
+    @_pre_call_cache
     async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:
         v: Optional[V] = await self.get(key)
         if v is not None:
@@ -960,6 +999,7 @@
         else:
             return default_value
 
+    @_pre_call_cache
     async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:
         response: List[NamedCacheResponse] = await self._dispatch_and_wait(self._request_factory.get_all_request(keys))
 
@@ -970,58 +1010,66 @@
                 entry.message.Unpack(binary_key_value)
                 m = MapEntry(binary_key_value.key, binary_key_value.value)
                 lst.append(m)
-        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)
+        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)  # type: ignore
 
+    @_pre_call_cache
     async def put_all(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> None:
         await self._dispatch_and_wait(self._request_factory.put_all_request(kv_map, ttl))
 
+    @_pre_call_cache
     async def clear(self) -> None:
         await self._dispatch_and_wait(self._request_factory.clear_request())
 
     async def destroy(self) -> None:
         await self._dispatch_and_wait(self._request_factory.destroy_request())
 
+    @_pre_call_cache
     def release(self) -> None:
         # TODO
         pass
 
+    @_pre_call_cache
     async def truncate(self) -> None:
         await self._dispatch_and_wait(self._request_factory.truncate_request())
 
-    async def remove(self, key: K) -> V:
+    @_pre_call_cache
+    async def remove(self, key: K) -> Optional[V]:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.remove_request(key))
 
         if response.HasField("message"):
             value = BytesValue()
             response.message.Unpack(value)
-            result = self._serializer.deserialize(value.value)
+            result: V = self._serializer.deserialize(value.value)
             return result
         else:
             return None
 
+    @_pre_call_cache
     async def remove_mapping(self, key: K, value: V) -> bool:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.remove_mapping_request(key, value)
         )
 
         if response.HasField("message"):
-            value = BoolValue()
-            response.message.Unpack(value)
-            return value.value
+            bool_value = BoolValue()
+            response.message.Unpack(bool_value)
+            return bool_value.value
         else:
             return False
 
-    async def replace(self, key: K, value: V) -> V:
+    @_pre_call_cache
+    async def replace(self, key: K, value: V) -> Optional[V]:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.replace_request(key, value))
 
         if response.HasField("message"):
-            value = BytesValue()
-            response.message.Unpack(value)
-            result = self._serializer.deserialize(value.value)
+            bytes_value = BytesValue()
+            response.message.Unpack(bytes_value)
+            result: V = self._serializer.deserialize(bytes_value.value)
             return result
         else:
             return None
 
+    @_pre_call_cache
     async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.replace_mapping_request(key, old_value, new_value)
@@ -1034,6 +1082,7 @@
         else:
             return False
 
+    @_pre_call_cache
     async def contains_key(self, key: K) -> bool:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.contains_key_request(key))
 
@@ -1044,18 +1093,20 @@
         else:
             return False
 
+    @_pre_call_cache
     async def contains_value(self, value: V) -> bool:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.contains_value_request(value)
         )
 
         if response.HasField("message"):
-            value = BoolValue()
+            bool_value = BoolValue()
             response.message.Unpack(value)
-            return value.value
+            return bool_value.value
         else:
             return False
 
+    @_pre_call_cache
     async def is_empty(self) -> bool:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.is_empty_request())
 
@@ -1066,6 +1117,7 @@
         else:
             return False
 
+    @_pre_call_cache
     async def size(self) -> int:
         response: NamedCacheResponse = await self._dispatch_and_wait(self._request_factory.size_request())
 
@@ -1076,7 +1128,8 @@
         else:
             return 0
 
-    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:
+    @_pre_call_cache
+    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:
         response: List[NamedCacheResponse] = await self._dispatch_and_wait(
             self._request_factory.invoke_request(key, processor)
         )
@@ -1090,6 +1143,7 @@
                 entry.message.Unpack(binary_key_value)
                 return self._serializer.deserialize(binary_key_value.value)
 
+    @_pre_call_cache
     async def invoke_all(
         self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
     ) -> AsyncIterator[MapEntry[K, R]]:
@@ -1104,11 +1158,12 @@
                 entry.message.Unpack(binary_key_value)
                 m = MapEntry(binary_key_value.key, binary_key_value.value)
                 lst.append(m)
-        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)
+        return _ListAsyncIterator(self._serializer, lst, _entry_producer_from_list)  # type: ignore
 
+    @_pre_call_cache
     async def aggregate(
         self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
-    ) -> R:
+    ) -> Optional[R]:
         response: NamedCacheResponse = await self._dispatch_and_wait(
             self._request_factory.aggregate_request(aggregator, keys, filter)
         )
@@ -1117,24 +1172,28 @@
         if response.HasField("message"):
             value = BytesValue()
             response.message.Unpack(value)
-            result = self._serializer.deserialize(value.value)
+            result: R = self._serializer.deserialize(value.value)
             return result
         else:
             return None
 
+    @_pre_call_cache
     def values(
         self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False
     ) -> AsyncIterator[V]:
         pass
 
+    @_pre_call_cache
     def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:
         pass
 
+    @_pre_call_cache
     def entries(
         self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False
     ) -> AsyncIterator[MapEntry[K, V]]:
         pass
 
+    @_pre_call_cache
     async def add_index(
         self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None
     ) -> None:
@@ -1143,6 +1202,7 @@
 
         await self._dispatch_and_wait(self._request_factory.add_index_request(extractor, ordered, comparator))
 
+    @_pre_call_cache
     async def remove_index(self, extractor: ValueExtractor[T, E]) -> None:
         if extractor is None:
             raise ValueError("A ValueExtractor must be specified")
@@ -1569,6 +1629,8 @@
         else:
             self._session_options = Options()
 
+        self._protocol_version = "unknown"
+
         self._ready_timeout_seconds: float = self._session_options.ready_timeout_seconds
         self._ready_enabled: bool = self._ready_timeout_seconds > 0
 
@@ -1592,7 +1654,7 @@
         ]
 
         self._is_server_grpc_v1 = False
-        self._v1_init_response_details = None
+        self._v1_init_response_details: dict[str, Any] = dict()
 
         if self._session_options.tls_options is None:
             self._channel: grpc.aio.Channel = grpc.aio.insecure_channel(
@@ -1706,7 +1768,7 @@
     def __str__(self) -> str:
         return (
             f"Session(id={self.session_id}, closed={self.closed}, state={self._channel.get_state(False)},"
-            f" caches/maps={len(self._caches)}, options={self.options})"
+            f" caches/maps={len(self._caches)}, protocol-version={self._protocol_version} options={self.options})"
         )
 
     def update_cache_id_map(self, cache_id: int, cache: NamedCache[K, V]) -> None:
@@ -1727,11 +1789,11 @@
         if not Session._initialized:
             check_result = await self._check_server_grpc_version_is_v1()
             Session._initialized = True
-            if check_result is None:  # Server is running grpc v0
+            if len(check_result) == 0:  # Server is running grpc v0
                 self._is_server_grpc_v1 = False
             else:  # Server is running grpc v1
                 self._is_server_grpc_v1 = True
-                self._v1_init_response_details = check_result
+                self._v1_init_response_details = {**self._v1_init_response_details, **check_result}
 
         if not self._is_server_grpc_v1:
             with self._lock:
@@ -1770,11 +1832,11 @@
         if not Session._initialized:
             check_result = await self._check_server_grpc_version_is_v1()
             Session._initialized = True
-            if check_result is None:  # Server is running grpc v0
+            if len(check_result) == 0:  # Server is running grpc v0
                 self._is_server_grpc_v1 = False
             else:  # Server is running grpc v1
                 self._is_server_grpc_v1 = True
-                self._v1_init_response_details = check_result
+                self._v1_init_response_details = {**self._v1_init_response_details, **check_result}
 
         if not self._is_server_grpc_v1:
             with self._lock:
@@ -1867,8 +1929,8 @@
         client.on(MapLifecycleEvent.DESTROYED, on_destroyed)
         client.on(MapLifecycleEvent.RELEASED, on_released)
 
-    async def _check_server_grpc_version_is_v1(self) -> object:
-        stub = proxy_service_v1_pb2_grpc.ProxyServiceStub(self._channel)
+    async def _check_server_grpc_version_is_v1(self) -> dict[str, Any]:
+        stub = ProxyServiceStub(self._channel)
         stream = stub.subChannel()
         results: dict[str, Any] = dict()
         results["stub"] = stub
@@ -1877,9 +1939,11 @@
         try:
             response = await self._send_init_request(stream)
             results["init_response"] = response
+            self._protocol_version = 1
             return results
         except grpc.aio._call.AioRpcError:
-            return None
+            self._protocol_version = 0
+            return dict()
 
     async def _send_init_request(self, stream) -> object:
         # InitRequest
@@ -2226,7 +2290,6 @@
     if len(the_list) == 0:
         raise StopAsyncIteration
     for item in the_list:
-        await asyncio.sleep(0)
         the_list.pop(0)
         return _entry_deserializer(serializer, item)
 
@@ -2405,6 +2468,7 @@
         self._request_id_request_map[request_id] = request
         await self._stream.write(proxy_request)
 
+    # noinspection PyUnresolvedReferences
     def handle_zero_id_response(self, response) -> None:
         if response.HasField("message"):
             named_cache_response = NamedCacheResponse()
Index: tests/test_session.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2023, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport asyncio\nimport logging\nimport os\nimport urllib\nimport urllib.request\nfrom asyncio import Event\nfrom time import time\nfrom typing import Final\n\nimport pytest\n\nimport tests\nfrom coherence import NamedCache, NamedMap, Options, Session, TlsOptions\nfrom coherence.event import MapLifecycleEvent, SessionLifecycleEvent\nfrom tests import CountingMapListener\n\nCOH_LOG = logging.getLogger(\"coherence-test\")\nEVENT_TIMEOUT: Final[float] = 10.0\n\n\n@pytest.mark.asyncio\nasync def test_basics() -> None:\n    \"\"\"Test initial session state and post-close invocations raise error\"\"\"\n\n    run_secure: str = \"RUN_SECURE\"\n    session: Session = await tests.get_session()\n\n    def check_basics() -> None:\n        assert session.scope == Options.DEFAULT_SCOPE\n        assert session.format == Options.DEFAULT_FORMAT\n        assert session.session_id is not None\n        assert session.options is not None\n\n        if run_secure in os.environ:\n            assert session.options.tls_options is not None\n            assert session.options.tls_options.enabled\n            assert session.options.tls_options.client_key_path == os.environ.get(TlsOptions.ENV_CLIENT_KEY)\n            assert session.options.tls_options.ca_cert_path == os.environ.get(TlsOptions.ENV_CA_CERT)\n            assert session.options.tls_options.client_cert_path == os.environ.get(TlsOptions.ENV_CLIENT_CERT)\n        else:\n            assert session.options.tls_options is None\n            assert session.options.channel_options is None\n\n        assert session.options.session_disconnect_timeout_seconds == Options.DEFAULT_SESSION_DISCONNECT_TIMEOUT\n\n        if Options.ENV_REQUEST_TIMEOUT in os.environ:\n            assert session.options.request_timeout_seconds == float(os.environ.get(Options.ENV_REQUEST_TIMEOUT, \"-1\"))\n        else:\n            assert session.options.request_timeout_seconds == Options.DEFAULT_REQUEST_TIMEOUT\n\n        assert session.options.ready_timeout_seconds == Options.DEFAULT_READY_TIMEOUT\n        assert session.options.format == Options.DEFAULT_FORMAT\n        assert session.options.scope == Options.DEFAULT_SCOPE\n        assert session.options.address == Options.DEFAULT_ADDRESS\n\n    check_basics()\n    assert session.channel is not None\n    assert session.is_ready()\n    assert not session.closed\n\n    cache = await session.get_cache(\"cache\")\n    assert cache is not None\n    assert isinstance(cache, NamedCache)\n\n    map_local = await session.get_map(\"map\")\n    assert map_local is not None\n    assert isinstance(map_local, NamedMap)\n\n    await session.close()\n    await asyncio.sleep(0.1)\n\n    check_basics()\n    assert session.channel is None\n    assert not session.is_ready()\n    assert session.closed\n\n    with pytest.raises(RuntimeError):\n        await cache.size()\n\n    with pytest.raises(RuntimeError):\n        await map_local.size()\n\n    with pytest.raises(RuntimeError):\n        await session.get_cache(\"cache\")\n\n    with pytest.raises(RuntimeError):\n        await session.get_map(\"map\")\n\n    with pytest.raises(RuntimeError):\n        session.on(SessionLifecycleEvent.CLOSED, lambda: None)\n\n\n@pytest.mark.asyncio\nasync def test_cache_release_event() -> None:\n    await _validate_cache_event(MapLifecycleEvent.RELEASED)\n\n\n@pytest.mark.asyncio\nasync def test_cache_destroy_event() -> None:\n    await _validate_cache_event(MapLifecycleEvent.DESTROYED)\n\n\n@pytest.mark.asyncio\nasync def test_session_lifecycle() -> None:\n    conn_event: Event = Event()\n    disconn_event: Event = Event()\n    reconn_event: Event = Event()\n    close_event: Event = Event()\n\n    def conn_callback() -> None:\n        COH_LOG.info(\"Connection active\")\n        nonlocal conn_event\n        conn_event.set()\n\n    def disconn_callback() -> None:\n        COH_LOG.info(\"Detected disconnect\")\n        nonlocal disconn_event\n        disconn_event.set()\n\n    def reconn_callback() -> None:\n        COH_LOG.info(\"Detected reconnect\")\n        nonlocal reconn_event\n        reconn_event.set()\n\n    def close_callback() -> None:\n        COH_LOG.info(\"Detected close\")\n        nonlocal close_event\n        close_event.set()\n\n    session: Session = await tests.get_session()\n    session.on(SessionLifecycleEvent.CONNECTED, conn_callback)\n    session.on(SessionLifecycleEvent.DISCONNECTED, disconn_callback)\n    session.on(SessionLifecycleEvent.RECONNECTED, reconn_callback)\n    session.on(SessionLifecycleEvent.CLOSED, close_callback)\n\n    await tests.wait_for(conn_event, EVENT_TIMEOUT)\n    assert session.is_ready()\n\n    await _shutdown_proxy()\n\n    await tests.wait_for(disconn_event, EVENT_TIMEOUT)\n    assert session.is_ready()\n    await tests.wait_for(reconn_event, EVENT_TIMEOUT)\n    assert session.is_ready()\n\n    await session.close()\n    assert not session.is_ready()\n\n    await tests.wait_for(close_event, EVENT_TIMEOUT)\n    assert not session.is_ready()\n\n\n@pytest.mark.skip(\n    reason=\"COH-28062 - Intermittent \\\n                GitHub action failure ==> test_wait_for_ready - TimeoutError\"\n)\n@pytest.mark.asyncio\nasync def test_wait_for_ready() -> None:\n    session: Session = await tests.get_session(10.0)\n    print(f\"Session -> {session}\")\n\n    logging.debug(\"Getting cache ...\")\n\n    try:\n        count: int = 50\n        cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n        listener: CountingMapListener[str, str] = CountingMapListener(\"Test\")\n\n        await _run_pre_shutdown_logic(cache, listener, count)\n\n        disc_event: Event = Event()\n\n        def disc() -> None:\n            COH_LOG.debug(\"Detected session disconnect!\")\n            nonlocal disc_event\n            disc_event.set()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, disc)\n\n        await _shutdown_proxy()\n\n        COH_LOG.debug(\"Waiting for session disconnect ...\")\n        try:\n            await asyncio.wait_for(disc_event.wait(), 10)\n        except TimeoutError:\n            s = \"Deadline [10 seconds] exceeded for session disconnect\"\n            raise TimeoutError(s)\n\n        # start inserting values as soon as disconnect occurs to ensure\n        # that we properly wait for the session to reconnect before\n        # issuing RPC\n        COH_LOG.debug(\"Inserting second set of values ...\")\n        for i in range(count):\n            await cache.put(str(i), str(i))\n\n        COH_LOG.debug(\"Waiting for [%s] MapEvents ...\", count)\n        await listener.wait_for(count, 10)\n        COH_LOG.debug(\"All events received!\")\n\n    finally:\n        await session.close()\n\n\n@pytest.mark.asyncio\nasync def test_fail_fast() -> None:\n    session: Session = await tests.get_session()\n    logging.debug(\"Getting cache ...\")\n\n    try:\n        count: int = 10\n        cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n        listener: CountingMapListener[str, str] = CountingMapListener(\"Test\")\n\n        await _run_pre_shutdown_logic(cache, listener, count)\n\n        disc_event: Event = Event()\n        reconn_event: Event = Event()\n\n        def disc() -> None:\n            COH_LOG.debug(\"Detected session disconnect!\")\n            nonlocal disc_event\n            disc_event.set()\n\n        def reconn() -> None:\n            COH_LOG.debug(\"Detected session reconnect!\")\n            nonlocal reconn_event\n            reconn_event.set()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, disc)\n        session.on(SessionLifecycleEvent.RECONNECTED, reconn)\n\n        await _shutdown_proxy()\n\n        COH_LOG.debug(\"Waiting for session disconnect ...\")\n        try:\n            await asyncio.wait_for(disc_event.wait(), 10)\n        except TimeoutError:\n            s = \"Deadline [10 seconds] exceeded for session disconnect\"\n            raise TimeoutError(s)\n\n        # start inserting values as soon as disconnect occurs to ensure\n        # that we properly wait for the session to reconnect before\n        # issuing RPC\n        COH_LOG.debug(\"Inserting second set of values; expecting error\")\n        for i in range(count):\n            try:\n                await cache.put(str(i), str(i))\n                pytest.fail(\"No exception thrown by RPC\")\n            except Exception as e:\n                print(\"Caught error: \" + str(e))\n\n        COH_LOG.debug(\"Waiting for session reconnect ...\")\n        try:\n            await asyncio.wait_for(reconn_event.wait(), 10)\n        except TimeoutError:\n            s = \"Deadline [10 seconds] exceeded for session reconnect\"\n            raise TimeoutError(s)\n\n    finally:\n        await session.close()\n\n\nasync def _run_pre_shutdown_logic(\n    cache: NamedCache[str, str], listener: CountingMapListener[str, str], count: int\n) -> None:\n    COH_LOG.debug(\"Adding MapListener ...\")\n    await cache.add_map_listener(listener)\n\n    COH_LOG.debug(\"Inserting values ...\")\n    for i in range(count):\n        await cache.put(str(i), str(i))\n\n    COH_LOG.debug(\"Waiting for [%s] MapEvents ...\", count)\n    await listener.wait_for(count, 15)\n    COH_LOG.debug(\"All events received!\")\n\n    listener.reset()\n\n\nasync def _validate_cache_event(lifecycle_event: MapLifecycleEvent) -> None:\n    session: Session = await tests.get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    session.on(lifecycle_event, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        if lifecycle_event == MapLifecycleEvent.RELEASED:\n            cache.release()\n        else:\n            await cache.destroy()\n\n        await tests.wait_for(event, EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert cache.released\n\n        if lifecycle_event == MapLifecycleEvent.DESTROYED:\n            assert cache.destroyed\n        else:\n            assert not cache.destroyed\n\n        assert not cache.active\n    finally:\n        await session.close()\n\n\nasync def _shutdown_proxy() -> None:\n    COH_LOG.debug(\"Shutting down the gRPC Proxy ...\")\n    req: urllib.request.Request = urllib.request.Request(\n        \"http://127.0.0.1:30000/management/coherence/cluster/services/$GRPC:GrpcProxy/members/1/stop\", method=\"POST\"\n    )\n    with urllib.request.urlopen(req) as response:\n        response.read()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_session.py b/tests/test_session.py
--- a/tests/test_session.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/tests/test_session.py	(date 1726015052578)
@@ -154,20 +154,24 @@
     assert not session.is_ready()
 
 
-@pytest.mark.skip(
-    reason="COH-28062 - Intermittent \
-                GitHub action failure ==> test_wait_for_ready - TimeoutError"
-)
+# @pytest.mark.skip(
+#     reason="COH-28062 - Intermittent \
+#                 GitHub action failure ==> test_wait_for_ready - TimeoutError"
+# )
 @pytest.mark.asyncio
 async def test_wait_for_ready() -> None:
     session: Session = await tests.get_session(10.0)
-    print(f"Session -> {session}")
+
+    print(f"Session (pre-cache) -> {session}")
 
     logging.debug("Getting cache ...")
 
     try:
         count: int = 50
         cache: NamedCache[str, str] = await session.get_cache("test-" + str(int(time() * 1000)))
+
+        print(f"Session (post-cache) -> {session}")
+
         listener: CountingMapListener[str, str] = CountingMapListener("Test")
 
         await _run_pre_shutdown_logic(cache, listener, count)
Index: src/coherence/util.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023 Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport time\nfrom typing import Optional, TypeVar\n\nfrom .aggregator import EntryAggregator\nfrom .comparator import Comparator\nfrom .extractor import ValueExtractor\nfrom .filter import Filter, Filters, MapEventFilter\nfrom .messages_pb2 import (\n    AddIndexRequest,\n    AggregateRequest,\n    ClearRequest,\n    ContainsKeyRequest,\n    ContainsValueRequest,\n    DestroyRequest,\n    Entry,\n    EntrySetRequest,\n    GetAllRequest,\n    GetRequest,\n    InvokeAllRequest,\n    InvokeRequest,\n    IsEmptyRequest,\n    KeySetRequest,\n    MapListenerRequest,\n    PageRequest,\n    PutAllRequest,\n    PutIfAbsentRequest,\n    PutRequest,\n    RemoveIndexRequest,\n    RemoveMappingRequest,\n    RemoveRequest,\n    ReplaceMappingRequest,\n    ReplaceRequest,\n    SizeRequest,\n    TruncateRequest,\n    ValuesRequest,\n)\nfrom .processor import EntryProcessor\nfrom .serialization import Serializer\n\nE = TypeVar(\"E\")\nK = TypeVar(\"K\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\nV = TypeVar(\"V\")\n\n\nclass RequestFactory:\n    def __init__(self, cache_name: str, scope: str, serializer: Serializer) -> None:\n        self._cache_name: str = cache_name\n        self._scope: str = scope\n        self._serializer: Serializer = serializer\n        self.__uidPrefix: str = \"-\" + cache_name + \"-\" + str(time.time_ns())\n        self.__next_request_id: int = 0\n        self.__next_filter_id: int = 0\n\n    def get_serializer(self) -> Serializer:\n        return self._serializer\n\n    def put_request(self, key: K, value: V, ttl: int = -1) -> PutRequest:\n        p = PutRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n            ttl=ttl,\n        )\n        return p\n\n    def get_request(self, key: K) -> GetRequest:\n        g = GetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return g\n\n    def get_all_request(self, keys: set[K]) -> GetRequest:\n        if keys is None:\n            raise ValueError(\"Must specify a set of keys\")\n\n        g: GetAllRequest = GetAllRequest(scope=self._scope, cache=self._cache_name, format=self._serializer.format)\n\n        for key in keys:\n            g.key.append(self._serializer.serialize(key))\n\n        return g\n\n    def put_if_absent_request(self, key: K, value: V, ttl: int = -1) -> PutIfAbsentRequest:\n        p = PutIfAbsentRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n            ttl=ttl,\n        )\n        return p\n\n    def put_all_request(self, map: dict[K, V]) -> PutAllRequest:\n        entry_list = list()\n        for key, value in map.items():\n            k = self._serializer.serialize(key)\n            v = self._serializer.serialize(value)\n            e = Entry(key=k, value=v)\n            entry_list.append(e)\n        p = PutAllRequest(scope=self._scope, cache=self._cache_name, format=self._serializer.format, entry=entry_list)\n        return p\n\n    def clear_request(self) -> ClearRequest:\n        r = ClearRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def destroy_request(self) -> DestroyRequest:\n        r = DestroyRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def truncate_request(self) -> TruncateRequest:\n        r = TruncateRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def remove_request(self, key: K) -> RemoveRequest:\n        r = RemoveRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def remove_mapping_request(self, key: K, value: V) -> RemoveMappingRequest:\n        r = RemoveMappingRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def replace_request(self, key: K, value: V) -> ReplaceRequest:\n        r = ReplaceRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> ReplaceMappingRequest:\n        r = ReplaceMappingRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            previousValue=self._serializer.serialize(old_value),\n            newValue=self._serializer.serialize(new_value),\n        )\n        return r\n\n    def contains_key_request(self, key: K) -> ContainsKeyRequest:\n        r = ContainsKeyRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def contains_value_request(self, value: V) -> ContainsValueRequest:\n        r = ContainsValueRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def is_empty_request(self) -> IsEmptyRequest:\n        r = IsEmptyRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def size_request(self) -> SizeRequest:\n        r = SizeRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def invoke_request(self, key: K, processor: EntryProcessor[R]) -> InvokeRequest:\n        r = InvokeRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            processor=self._serializer.serialize(processor),\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def invoke_all_request(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> InvokeAllRequest:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        r = InvokeAllRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            processor=self._serializer.serialize(processor),\n        )\n\n        if keys is not None:\n            for key in keys:\n                r.keys.append(self._serializer.serialize(key))\n        else:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def aggregate_request(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AggregateRequest:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        r: AggregateRequest = AggregateRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            aggregator=self._serializer.serialize(aggregator),\n        )\n\n        if keys is not None:\n            for key in keys:\n                r.keys.append(self._serializer.serialize(key))\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def values_request(self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None) -> ValuesRequest:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        r: ValuesRequest = ValuesRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def keys_request(self, filter: Optional[Filter] = None) -> KeySetRequest:\n        r: KeySetRequest = KeySetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def entries_request(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None\n    ) -> EntrySetRequest:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        r: EntrySetRequest = EntrySetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def page_request(self, cookie: bytes) -> PageRequest:\n        \"\"\"\n        Creates a gRPC PageRequest.\n\n        :param cookie: the cookie used for paging\n        :return: a new PageRequest\n        \"\"\"\n\n        r: PageRequest = PageRequest(\n            scope=self._scope, cache=self._cache_name, format=self._serializer.format, cookie=cookie\n        )\n\n        return r\n\n    def map_listener_request(\n        self, subscribe: bool, lite: bool = False, *, key: Optional[K] = None, filter: Optional[Filter] = None\n    ) -> MapListenerRequest:\n        \"\"\"Creates a gRPC generated MapListenerRequest\"\"\"\n\n        if key is None and filter is None:\n            raise AssertionError(\"Must specify a key or a filter\")\n\n        request: MapListenerRequest = MapListenerRequest(\n            cache=self._cache_name, scope=self._scope, format=self._serializer.format\n        )\n\n        request.lite = lite\n        request.subscribe = subscribe\n        request.uid = self.__generate_next_request_id(\"key\" if key is not None else \"filter\")\n        request.trigger = bytes()\n        request.priming = False\n\n        if key is not None:  # registering a key listener\n            request.type = MapListenerRequest.RequestType.KEY\n            request.key = self._serializer.serialize(key)\n        else:  # registering a Filter listener\n            request.type = MapListenerRequest.RequestType.FILTER\n            self.__next_filter_id += 1\n            request.filterId = self.__next_filter_id\n            filter_local: Filter = filter if filter is not None else Filters.always()\n            if not isinstance(filter_local, MapEventFilter):\n                filter_local = MapEventFilter.from_filter(filter_local)\n\n            request.filter = self._serializer.serialize(filter_local)\n\n        return request\n\n    def map_event_subscribe(self) -> MapListenerRequest:\n        request: MapListenerRequest = MapListenerRequest(\n            cache=self._cache_name, scope=self._scope, format=self._serializer.format\n        )\n        request.uid = self.__generate_next_request_id(\"init\")\n        request.subscribe = True\n        request.type = MapListenerRequest.RequestType.INIT\n\n        return request\n\n    def __generate_next_request_id(self, prefix: str) -> str:\n        \"\"\"Generates a prefix map-specific prefix when starting a MapEvent gRPC stream.\"\"\"\n        self.__next_request_id += 1\n        return prefix + self.__uidPrefix + str(self.__next_request_id)\n\n    def add_index_request(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> AddIndexRequest:\n        r = AddIndexRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            extractor=self._serializer.serialize(extractor),\n        )\n        r.sorted = ordered\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def remove_index_request(self, extractor: ValueExtractor[T, E]) -> RemoveIndexRequest:\n        r = RemoveIndexRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            extractor=self._serializer.serialize(extractor),\n        )\n\n        return r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/util.py b/src/coherence/util.py
--- a/src/coherence/util.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/src/coherence/util.py	(date 1726012780631)
@@ -4,10 +4,23 @@
 
 from __future__ import annotations
 
+import sys
+import threading
 import time
-from typing import Optional, TypeVar
+from typing import Any, Optional, TypeVar
+
+from google.protobuf.any_pb2 import Any as GrpcAny  # type: ignore
+from google.protobuf.wrappers_pb2 import BytesValue  # type: ignore
 
 from .aggregator import EntryAggregator
+from .cache_service_messages_v1_pb2 import EnsureCacheRequest, ExecuteRequest, IndexRequest, KeyOrFilter, KeysOrFilter
+from .cache_service_messages_v1_pb2 import MapListenerRequest as V1MapListenerRequest
+from .cache_service_messages_v1_pb2 import NamedCacheRequest, NamedCacheRequestType
+from .cache_service_messages_v1_pb2 import PutAllRequest as V1PutAllRequest
+from .cache_service_messages_v1_pb2 import PutRequest as V1PutRequest
+from .cache_service_messages_v1_pb2 import QueryRequest
+from .cache_service_messages_v1_pb2 import ReplaceMappingRequest as V1ReplaceMappingRequest
+from .common_messages_v1_pb2 import BinaryKeyAndValue, CollectionOfBytesValues
 from .comparator import Comparator
 from .extractor import ValueExtractor
 from .filter import Filter, Filters, MapEventFilter
@@ -41,6 +54,7 @@
     ValuesRequest,
 )
 from .processor import EntryProcessor
+from .proxy_service_messages_v1_pb2 import ProxyRequest
 from .serialization import Serializer
 
 E = TypeVar("E")
@@ -82,16 +96,18 @@
         )
         return g
 
-    def get_all_request(self, keys: set[K]) -> GetRequest:
+    def get_all_request(self, keys: set[K]) -> GetAllRequest:
         if keys is None:
             raise ValueError("Must specify a set of keys")
 
-        g: GetAllRequest = GetAllRequest(scope=self._scope, cache=self._cache_name, format=self._serializer.format)
+        get_all: GetAllRequest = GetAllRequest(
+            scope=self._scope, cache=self._cache_name, format=self._serializer.format
+        )
 
         for key in keys:
-            g.key.append(self._serializer.serialize(key))
+            get_all.key.append(self._serializer.serialize(key))
 
-        return g
+        return get_all
 
     def put_if_absent_request(self, key: K, value: V, ttl: int = -1) -> PutIfAbsentRequest:
         p = PutIfAbsentRequest(
@@ -244,7 +260,9 @@
 
         return r
 
-    def values_request(self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None) -> ValuesRequest:
+    def values_request(
+        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
+    ) -> ValuesRequest:
         if filter is None and comparator is not None:
             raise ValueError("Filter cannot be None")
 
@@ -327,14 +345,17 @@
         request.priming = False
 
         if key is not None:  # registering a key listener
+            # noinspection PyUnresolvedReferences
             request.type = MapListenerRequest.RequestType.KEY
             request.key = self._serializer.serialize(key)
         else:  # registering a Filter listener
+            # noinspection PyUnresolvedReferences
             request.type = MapListenerRequest.RequestType.FILTER
             self.__next_filter_id += 1
             request.filterId = self.__next_filter_id
             filter_local: Filter = filter if filter is not None else Filters.always()
             if not isinstance(filter_local, MapEventFilter):
+                # noinspection PyUnresolvedReferences
                 filter_local = MapEventFilter.from_filter(filter_local)
 
             request.filter = self._serializer.serialize(filter_local)
@@ -347,6 +368,7 @@
         )
         request.uid = self.__generate_next_request_id("init")
         request.subscribe = True
+        # noinspection PyUnresolvedReferences
         request.type = MapListenerRequest.RequestType.INIT
 
         return request
@@ -381,3 +403,388 @@
         )
 
         return r
+
+
+class RequestIdGenerator:
+    _generator = None
+
+    def __init__(self) -> None:
+        self._lock = threading.Lock()
+        self._counter = 0
+
+    @classmethod
+    def generator(cls) -> RequestIdGenerator:
+        if RequestIdGenerator._generator is None:
+            RequestIdGenerator._generator = RequestIdGenerator()
+        return RequestIdGenerator._generator
+
+    @classmethod
+    def next(cls) -> int:
+        generator = cls.generator()
+        with generator._lock:
+            if generator._counter == sys.maxsize:
+                generator._counter = 0
+            else:
+                generator._counter += 1
+            return generator._counter
+
+
+class RequestFactoryV1:
+
+    def __init__(self, cache_name: str, cache_id: int, scope: str, serializer: Serializer) -> None:
+        self._cache_name: str = cache_name
+        self._cache_id: int = cache_id
+        self._scope: str = scope
+        self._serializer: Serializer = serializer
+        # self.__uidPrefix: str = "-" + cache_name + "-" + str(time.time_ns())
+        # self.__next_request_id: int = 0
+        # self.__next_filter_id: int = 0
+
+    @property
+    def cache_id(self) -> int:
+        return self._cache_id
+
+    @cache_id.setter
+    def cache_id(self, value: int) -> None:
+        self._cache_id = value
+
+    def get_serializer(self) -> Serializer:
+        return self._serializer
+
+    def _create_named_cache_request(self, request: Any, request_type: NamedCacheRequestType) -> NamedCacheRequest:
+        any_cache_request = GrpcAny()
+        any_cache_request.Pack(request)
+
+        return NamedCacheRequest(
+            type=request_type,
+            cacheId=self.cache_id,
+            message=any_cache_request,
+        )
+
+    @staticmethod
+    def create_proxy_request(named_cache_request: NamedCacheRequest) -> ProxyRequest:
+        any_named_cache_request = GrpcAny()
+        any_named_cache_request.Pack(named_cache_request)
+        req_id = RequestIdGenerator.next()
+        proxy_request = ProxyRequest(
+            id=req_id,
+            message=any_named_cache_request,
+        )
+        return proxy_request
+
+    @staticmethod
+    def ensure_request(cache_name: str) -> NamedCacheRequest:
+        cache_request = EnsureCacheRequest(cache=cache_name)
+
+        any_cache_request = GrpcAny()
+        any_cache_request.Pack(cache_request)
+
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.EnsureCache,
+            message=any_cache_request,
+        )
+        return named_cache_request
+
+    def put_request(self, key: K, value: V, ttl: int = 0) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            V1PutRequest(
+                key=self._serializer.serialize(key),  # Serialized key
+                value=self._serializer.serialize(value),  # Serialized value
+                ttl=ttl,
+            ),
+            NamedCacheRequestType.Put,
+        )
+
+    def get_request(self, key: K) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Get
+        )
+
+    def get_all_request(self, keys: set[K]) -> NamedCacheRequest:
+        if keys is None:
+            raise ValueError("Must specify a set of keys")
+
+        return self._create_named_cache_request(
+            CollectionOfBytesValues(
+                values=list(self._serializer.serialize(k) for k in keys),
+            ),
+            NamedCacheRequestType.GetAll,
+        )
+
+    def put_if_absent_request(self, key: K, value: V, ttl: int = 0) -> NamedCacheRequest:
+
+        return self._create_named_cache_request(
+            PutRequest(
+                key=self._serializer.serialize(key),  # Serialized key
+                value=self._serializer.serialize(value),  # Serialized value
+                ttl=ttl,
+            ),
+            NamedCacheRequestType.PutIfAbsent,
+        )
+
+    def put_all_request(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            V1PutAllRequest(
+                entries=list(
+                    BinaryKeyAndValue(key=self._serializer.serialize(k), value=self._serializer.serialize(v))
+                    for k, v in kv_map.items()
+                ),
+                ttl=ttl,
+            ),
+            NamedCacheRequestType.PutAll,
+        )
+
+    def clear_request(self) -> NamedCacheRequest:
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.Clear,
+            cacheId=self.cache_id,
+        )
+        return named_cache_request
+
+    def destroy_request(self) -> NamedCacheRequest:
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.Destroy,
+            cacheId=self.cache_id,
+        )
+        return named_cache_request
+
+    def truncate_request(self) -> NamedCacheRequest:
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.Truncate,
+            cacheId=self.cache_id,
+        )
+        return named_cache_request
+
+    def remove_request(self, key: K) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Remove
+        )
+
+    def remove_mapping_request(self, key: K, value: V) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),
+            NamedCacheRequestType.RemoveMapping,
+        )
+
+    def replace_request(self, key: K, value: V) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),
+            NamedCacheRequestType.Replace,
+        )
+
+    def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            V1ReplaceMappingRequest(
+                key=self._serializer.serialize(key),
+                previousValue=self._serializer.serialize(old_value),
+                newValue=self._serializer.serialize(new_value),
+            ),
+            NamedCacheRequestType.ReplaceMapping,
+        )
+
+    def contains_key_request(self, key: K) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.ContainsKey
+        )
+
+    def contains_value_request(self, value: V) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            BytesValue(value=self._serializer.serialize(value)), NamedCacheRequestType.ContainsValue
+        )
+
+    def is_empty_request(self) -> NamedCacheRequest:
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.IsEmpty,
+            cacheId=self.cache_id,
+        )
+        return named_cache_request
+
+    def size_request(self) -> NamedCacheRequest:
+        named_cache_request = NamedCacheRequest(
+            type=NamedCacheRequestType.Size,
+            cacheId=self.cache_id,
+        )
+        return named_cache_request
+
+    def invoke_request(self, key: K, processor: EntryProcessor[R]) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            ExecuteRequest(
+                agent=self._serializer.serialize(processor),
+                keys=KeysOrFilter(
+                    key=self._serializer.serialize(key),
+                ),
+            ),
+            NamedCacheRequestType.Invoke,
+        )
+
+    def invoke_all_request(
+        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
+    ) -> NamedCacheRequest:
+        if keys is not None and filter is not None:
+            raise ValueError("keys and filter are mutually exclusive")
+
+        if keys is not None:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(processor),
+                keys=KeysOrFilter(
+                    keys=CollectionOfBytesValues(
+                        values=list(self._serializer.serialize(key) for key in keys),
+                    ),
+                ),
+            )
+        elif filter is not None:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(processor),
+                keys=KeysOrFilter(
+                    filter=self._serializer.serialize(filter),
+                ),
+            )
+        else:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(processor),
+            )
+
+        return self._create_named_cache_request(cache_request, NamedCacheRequestType.Invoke)
+
+    def aggregate_request(
+        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
+    ) -> NamedCacheRequest:
+        if keys is not None and filter is not None:
+            raise ValueError("keys and filter are mutually exclusive")
+
+        if keys is not None:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(aggregator),
+                keys=KeysOrFilter(
+                    keys=CollectionOfBytesValues(
+                        values=list(self._serializer.serialize(key) for key in keys),
+                    ),
+                ),
+            )
+        elif filter is not None:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(aggregator),
+                keys=KeysOrFilter(
+                    filter=self._serializer.serialize(filter),
+                ),
+            )
+        else:
+            cache_request = ExecuteRequest(
+                agent=self._serializer.serialize(aggregator),
+            )
+
+        return self._create_named_cache_request(cache_request, NamedCacheRequestType.Aggregate)
+
+    def values_request(
+        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
+    ) -> NamedCacheRequest:
+        if filter is None and comparator is not None:
+            raise ValueError("Filter cannot be None")
+
+        if filter is not None:
+            query_request = QueryRequest(filter=self._serializer.serialize(filter))
+        elif comparator is not None:
+            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))
+        else:
+            query_request = QueryRequest()
+
+        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryValues)
+
+    def keys_request(self, filter: Optional[Filter] = None) -> NamedCacheRequest:
+
+        if filter is not None:
+            query_request = QueryRequest(filter=self._serializer.serialize(filter))
+        else:
+            query_request = QueryRequest()
+
+        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryKeys)
+
+    def entries_request(
+        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
+    ) -> NamedCacheRequest:
+        if filter is None and comparator is not None:
+            raise ValueError("Filter cannot be None")
+
+        if filter is not None:
+            query_request = QueryRequest(filter=self._serializer.serialize(filter))
+        elif comparator is not None:
+            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))
+        else:
+            query_request = QueryRequest()
+
+        return self._create_named_cache_request(query_request, NamedCacheRequestType.QueryEntries)
+
+    def page_request(self, cookie: bytes) -> PageRequest:
+        """
+        Creates a gRPC PageRequest.
+
+        :param cookie: the cookie used for paging
+        :return: a new PageRequest
+        """
+
+        r: PageRequest = PageRequest(
+            scope=self._scope, cache=self._cache_name, format=self._serializer.format, cookie=cookie
+        )
+
+        return r
+
+    def map_listener_request(
+        self, subscribe: bool, lite: bool = False, *, key: Optional[K] = None, filter: Optional[Filter] = None
+    ) -> NamedCacheRequest:
+        """Creates a gRPC generated MapListenerRequest"""
+
+        if key is None and filter is None:
+            raise AssertionError("Must specify a key or a filter")
+
+        listener_request: V1MapListenerRequest = V1MapListenerRequest(subscribe=subscribe, lite=lite, priming=False)
+
+        if filter is not None:
+            listener_request.filterId = RequestIdGenerator.next()
+
+        if key is not None:  # registering a key listener
+            listener_request.keyOrFilter = KeyOrFilter(key=self._serializer.serialize(key))
+        else:  # registering a Filter listener
+            filter_local: Filter = filter if filter is not None else Filters.always()
+            if not isinstance(filter_local, MapEventFilter):
+                # noinspection PyUnresolvedReferences
+                filter_local = MapEventFilter.from_filter(filter_local)
+
+            listener_request.keyOrFilter = KeyOrFilter(filter=self._serializer.serialize(filter_local))
+
+        return self._create_named_cache_request(listener_request, NamedCacheRequestType.MapListenerRequest)
+
+    # def map_event_subscribe(self) -> MapListenerRequest:
+    #     request: MapListenerRequest = MapListenerRequest(
+    #         cache=self._cache_name, scope=self._scope, format=self._serializer.format
+    #     )
+    #     request.uid = self.__generate_next_request_id("init")
+    #     request.subscribe = True
+    #     request.type = MapListenerRequest.RequestType.INIT
+    #
+    #     return request
+    #
+    # def __generate_next_request_id(self, prefix: str) -> str:
+    #     """Generates a prefix map-specific prefix when starting a MapEvent gRPC stream."""
+    #     self.__next_request_id += 1
+    #     return prefix + self.__uidPrefix + str(self.__next_request_id)
+
+    def add_index_request(
+        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None
+    ) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            IndexRequest(
+                add=True,
+                extractor=self._serializer.serialize(extractor),
+                sorted=ordered,
+            ),
+            NamedCacheRequestType.Index,
+        )
+
+    def remove_index_request(self, extractor: ValueExtractor[T, E]) -> NamedCacheRequest:
+        return self._create_named_cache_request(
+            IndexRequest(
+                add=False,
+                extractor=self._serializer.serialize(extractor),
+            ),
+            NamedCacheRequestType.Index,
+        )
Index: src/coherence/aggregator.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nfrom abc import ABC\nfrom decimal import Decimal\nfrom enum import Enum, IntEnum\nfrom typing import Any, Dict, Generic, List, Optional, TypeVar, Union\n\nfrom typing_extensions import TypeAlias\n\nfrom .comparator import Comparator, InverseComparator, SafeComparator\nfrom .extractor import ExtractorExpression, Extractors, ValueExtractor\nfrom .filter import Filter\nfrom .serialization import proxy\n\nE = TypeVar(\"E\")\nG = TypeVar(\"G\")\nK = TypeVar(\"K\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\nV = TypeVar(\"V\")\n\nReducerResult: TypeAlias = Dict[K, Union[Any, List[Any]]]\n\n\nclass EntryAggregator(ABC, Generic[R]):\n    \"\"\"An EntryAggregator represents processing that can be directed to occur against some subset of the entries in\n    n cache, resulting in an aggregated result. Common examples of aggregation include functions such as min(),\n    max() and avg(). However, the concept of aggregation applies to any process that needs to evaluate a group of\n    entries to come up with a single answer.\"\"\"\n\n    def __init__(self, extractor_or_property: Optional[ExtractorExpression[T, E]] = None):\n        \"\"\"\n        Construct an AbstractAggregator that will aggregate values extracted from the cache entries.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__()\n        if extractor_or_property is not None:\n            if isinstance(extractor_or_property, ValueExtractor):\n                self.extractor = extractor_or_property\n            else:\n                self.extractor = Extractors.extract(extractor_or_property)\n\n    def and_then(self, aggregator: EntryAggregator[R]) -> EntryAggregator[List[R]]:\n        \"\"\"\n        Returns a :class:`coherence.aggregator.CompositeAggregator` comprised of this and the provided aggregator.\n\n        :param aggregator: the next aggregator\n        :return: a :class:`coherence.aggregator.CompositeAggregator` comprised of this and the provided aggregator\n        \"\"\"\n        return CompositeAggregator[R]([self, aggregator])\n\n\nclass AbstractComparableAggregator(EntryAggregator[R]):\n    \"\"\"Abstract aggregator that processes values extracted from a set of entries in a Map, with knowledge of how to\n    compare those values. There are two-way to use the AbstractComparableAggregator:\n\n    * All the extracted objects must implement the Java Comparable interface, or\n\n    * The AbstractComparableAggregator has to be provided with a :class:`coherence.comparator.Comparator` object.\n      This :class:`coherence.comparator.Comparator` must exist on the server in order to be usable.\n\n    If there are no entries to aggregate, the returned result will be `None`.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Construct an AbstractComparableAggregator that will aggregate Java-Comparable values extracted from the cache\n        entries.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\nclass AbstractDoubleAggregator(EntryAggregator[Decimal]):\n    \"\"\"Abstract aggregator that processes numeric values extracted from a set of entries in a Map. All the extracted\n    Number objects will be treated as Java `double` values and the result of the aggregator is a Double. If\n    the set of entries is empty, a `None` result is returned.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Construct an AbstractDoubleAggregator that will aggregate numeric values extracted from the cache entries.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.CompositeAggregator\")\nclass CompositeAggregator(EntryAggregator[List[R]]):\n    \"\"\"`CompositeAggregator` provides an ability to execute a collection of aggregators against the same subset of\n    the entries in a Map, resulting in a list of corresponding aggregation results. The size of the returned list\n    will always be equal to the length of the aggregators list.\"\"\"\n\n    def __init__(self, aggregators: list[EntryAggregator[R]]):\n        \"\"\"\n        Construct a CompositeAggregator based on a specified :class:`coherence.aggregator.EntryAggregator` list.\n\n        :param aggregators: an array of :class:`coherence.aggregator.EntryAggregator` objects; may not be `None`\n        \"\"\"\n        super().__init__()\n        if aggregators is not None:\n            self.aggregators = aggregators\n        else:\n            raise ValueError(\"no aggregators provided\")\n\n\n@proxy(\"aggregator.ComparableMax\")\nclass MaxAggregator(AbstractComparableAggregator[R]):\n    \"\"\"Calculates a maximum of numeric values extracted from a set of entries in a Map in a form of a numerical\n    value. All the extracted objects will be treated as numerical values. If the set of entries is empty,\n    a `None` result is returned.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Constructs a new `MaxAggregator`.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.ComparableMin\")\nclass MinAggregator(AbstractComparableAggregator[R]):\n    \"\"\"Calculates a minimum of numeric values extracted from a set of entries in a Map in a form of a numerical\n    value. All the extracted objects will be treated as numerical values. If the set of entries is empty,\n    a `None` result is returned.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Constructs a new `MinAggregator`.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.BigDecimalSum\")\nclass SumAggregator(AbstractDoubleAggregator):\n    \"\"\"Calculates a sum for values of any numeric type extracted from a set of entries in a Map in a form of a\n    numeric value.\n\n    If the set of entries is empty, a 'None' result is returned.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Constructs a new `SumAggregator`.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.BigDecimalAverage\")\nclass AverageAggregator(AbstractDoubleAggregator):\n    \"\"\"Calculates an average for values of any numeric type extracted from a set of entries in a Map in a form of a\n    numerical value. All the extracted objects will be treated as numerical values. If the set of entries is empty,\n    a `None` result is returned.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Construct an `AverageAggregator` that will sum numeric values extracted from the cache entries.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.Count\")\nclass CountAggregator(EntryAggregator[int]):\n    \"\"\"Calculates a number of values in an entry set.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Constructs a new `CountAggregator`.\n        \"\"\"\n        super().__init__()\n\n\n@proxy(\"aggregator.DistinctValues\")\nclass DistinctValuesAggregator(EntryAggregator[R]):\n    \"\"\"Return the set of unique values extracted from a set of entries in a Map. If the set of entries is empty,\n    an empty array is returned.\n\n    This aggregator could be used in combination with :class:`coherence.extractor.UniversalExtractor` allowing to\n    collect all unique combinations (tuples) of a given set of attributes.\n\n    The DistinctValues aggregator covers a simple case of a more generic aggregation pattern implemented by the\n    `GroupAggregator`, which in addition to collecting all distinct values or tuples, runs an aggregation against\n    each distinct entry set (group).\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Construct a DistinctValuesAggregator that will aggregate numeric values extracted from the cache entries.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\n@proxy(\"aggregator.TopNAggregator\")\nclass TopAggregator(Generic[E, R], EntryAggregator[List[R]]):\n    \"\"\"`TopAggregator` aggregates the top *N* extracted values into an array.  The extracted values must not be\n    `None`, but do not need to be unique.\"\"\"\n\n    def __init__(\n        self,\n        number: int = 0,\n        inverse: bool = False,\n        extractor: ValueExtractor[Any, Any] = Extractors.identity(),\n        comparator: Optional[Comparator] = None,\n        property_name: Optional[str] = None,\n    ):\n        \"\"\"\n        Constructs a new `TopAggregator`.\n\n        :param number: the maximum number of results to include in the aggregation result.\n        :param inverse: Result order.  By default, results will be ordered in descending order.\n        :param extractor: The extractor to obtain the values to aggregate.  If not explicitly set, this will default\n            to an :class:`coherence.extractor.IdentityExtractor`.\n        :param comparator: The :class:`coherence.comparator.Comparator` to apply against the extracted values.\n        :param property_name:  The property that results will be ordered by.\n        \"\"\"\n        super().__init__()\n        self.results = number\n        self.inverse = inverse\n        self.extractor = extractor\n        self.comparator = comparator\n        self.property = property_name\n\n    def order_by(self, property_name: str) -> TopAggregator[E, R]:\n        \"\"\"\n        Order the results based on the values of the specified property.\n\n        :param property_name: the property name\n        :return: an instance of :class:`coherence.aggregator.TopAggregator`\n        \"\"\"\n        self.property = property_name\n        self.comparator = InverseComparator(property_name) if self.inverse else SafeComparator(property_name)\n        return self\n\n    @property\n    def ascending(self) -> TopAggregator[E, R]:\n        \"\"\"\n        Sort the returned values in ascending order.\n\n        :return: an instance of :class:`coherence.aggregator.TopAggregator`\n        \"\"\"\n        if self.property is not None:\n            self.inverse = True\n            self.comparator = InverseComparator(self.property)\n        return self\n\n    @property\n    def descending(self) -> TopAggregator[E, R]:\n        \"\"\"\n        Sort the returned values in descending order.\n\n        :return: an instance of :class:`coherence.aggregator.TopAggregator`\n        \"\"\"\n        if self.property is not None:\n            self.inverse = False\n            self.comparator = SafeComparator(self.property)\n        return self\n\n    def extract(self, property_name: str) -> TopAggregator[E, R]:\n        \"\"\"\n        The property name of the value to extract.\n\n        :param property_name: the property name\n        :return:\n        \"\"\"\n        self.extractor = Extractors.extract(property_name)\n        return self\n\n\n@proxy(\"aggregator.GroupAggregator\")\nclass GroupAggregator(EntryAggregator[R]):\n    \"\"\"The `GroupAggregator` provides an ability to split a subset of entries in a Map into a collection of\n    non-intersecting subsets and then aggregate them separately and independently. The splitting (grouping) is\n    performed using the results of the underlying :class:`coherence.extractor.UniversalExtractor` in such a way that\n    two entries will belong to the same group if and only if the result of the corresponding extract call produces\n    the same value or tuple (list of values). After the entries are split into the groups, the underlying aggregator\n    is applied separately to each group. The result of the aggregation by the` GroupAggregator` is a Map that has\n    distinct values (or tuples) as keys and results of the individual aggregation as values. Additionally,\n    those results could be further reduced using an optional :class:`coherence.filter.Filter` object.\n\n    Informally speaking, this aggregator is analogous to the SQL `group by` and `having` clauses. Note that the\n    `having` Filter is applied independently on each server against the partial aggregation results; this generally\n    implies that data affinity is required to ensure that all required data used to generate a given result exists\n    within a single cache partition. In other words, the `group by` predicate should not span multiple partitions if\n    the `having` clause is used.\n\n    The `GroupAggregator` is somewhat similar to the DistinctValues aggregator, which returns back a list of distinct\n    values (tuples) without performing any additional aggregation work.\"\"\"\n\n    def __init__(\n        self,\n        extractor_or_property: ExtractorExpression[T, E],\n        aggregator: EntryAggregator[R],\n        filter: Optional[Filter] = None,\n    ):\n        \"\"\"\n        Construct a `GroupAggregator` based on a specified :class:`coherence.extractor.ValueExtractor` and underlying\n        :class:`coherence.aggregator.EntryAggregator`.\n\n        :param extractor_or_property:  a :class:`coherence.extractor.ValueExtractor` object that is used to split\n         entries into non-intersecting subsets; may not be `None`. This parameter can also be a dot-delimited sequence\n         of method names which would result in an aggregator based on the :class:`coherence.extractor.ChainedExtractor`\n         that is based on an array of corresponding :class:`coherence.extractor.UniversalExtractor` objects; may not be\n         `NONE`\n\n        :param aggregator: an EntryAggregator object; may not be null\n        :param filter: an optional Filter object used to filter out results of individual group aggregation results\n        \"\"\"\n        super().__init__(extractor_or_property)\n        if aggregator is not None:\n            self.aggregator = aggregator\n        else:\n            raise ValueError(\"no aggregator provided\")\n        self.filter = filter\n\n\nclass Timeout(IntEnum):\n    NONE: int = -1\n    \"\"\"A special timeout value to indicate that this task or request can run indefinitely.\"\"\"\n\n    DEFAULT: int = 0\n    \"\"\"A special timeout value to indicate that the corresponding service's default timeout value should be used.\"\"\"\n\n\nclass Schedule(Enum):\n    STANDARD = 0\n    \"\"\"Scheduling value indicating that this task is to be queued and execute in a natural (based on the request\n    arrival time) order.\"\"\"\n\n    FIRST = 1\n    \"\"\"Scheduling value indicating that this task is to be queued in front of any equal or lower scheduling priority\n    tasks and executed as soon as any of the worker threads become available.\"\"\"\n\n    IMMEDIATE = 2\n    \"\"\"Scheduling value indicating that this task is to be immediately executed by any idle worker thread; if all\n    of them are active, a new thread will be created to execute this task.\"\"\"\n\n\n@proxy(\"aggregator.PriorityAggregator\")\nclass PriorityAggregator(Generic[R], EntryAggregator[R]):\n    \"\"\"A `PriorityAggregator` is used to explicitly control the scheduling priority and timeouts for execution of\n    EntryAggregator-based methods.\n\n    For example, lets assume that there is an `Orders` cache that belongs to a partitioned cache service configured\n    with a *request-timeout* and *task-timeout* of 5 seconds. Also assume that we are willing to wait longer for a\n    particular aggregation request that scans the entire cache. Then we could override the default timeout values by\n    using the PriorityAggregator as follows::\n\n        sumAggr = SumAggregator(\"cost\")\n        priorityAgg = PriorityAggregator(sumAggr)\n        priorityAgg.executionTimeout = Timeout.NONE\n        priorityAgg.requestTimeout = Timeout.NONE\n        cacheOrders.aggregate(aFilter, priorityAgg)\n\n    This is an advanced feature which should be used judiciously.\"\"\"\n\n    def __init__(\n        self,\n        aggregator: EntryAggregator[R],\n        execution_timeout: int = Timeout.DEFAULT,\n        request_timeout: int = Timeout.DEFAULT,\n        scheduling_priority: Schedule = Schedule.STANDARD,\n    ):\n        \"\"\"\n        Construct a new `PriorityAggregator`.\n\n        :param aggregator: The wrapped :class:`coherence.aggregator.EntryAggregator`.\n        :param execution_timeout: The task execution timeout value.\n        :param request_timeout: The request timeout value.\n        :param scheduling_priority: The scheduling priority.\n        \"\"\"\n        super().__init__()\n        self.aggregator = aggregator\n        self._execution_timeout = execution_timeout\n        self._request_timeout = request_timeout\n        self._scheduling_priority = scheduling_priority\n\n    @property\n    def scheduling_priority(self) -> Schedule:\n        \"\"\"\n        Return the scheduling priority or, if not explicitly set, the default is\n        :class:`coherence.aggregator.Schedule.STANDARD`\n\n        :return: the scheduling priority\n        \"\"\"\n        return self._scheduling_priority\n\n    @scheduling_priority.setter\n    def scheduling_priority(self, scheduling_priority: Schedule) -> None:\n        \"\"\"\n        Set the scheduling priority.\n\n        :param scheduling_priority: the scheduling priority.\n        \"\"\"\n        self._scheduling_priority = scheduling_priority\n\n    @property\n    def execution_timeout_in_millis(self) -> int:\n        \"\"\"\n        Return the execution timeout in milliseconds.\n\n        :return: the execution timeout\n        \"\"\"\n        return self._execution_timeout\n\n    @execution_timeout_in_millis.setter\n    def execution_timeout_in_millis(self, execution_timeout: int) -> None:\n        \"\"\"\n        Set the execution timeout in milliseconds.\n\n        :param execution_timeout: the new execution timeout in milliseconds\n        \"\"\"\n        self._execution_timeout = execution_timeout\n\n    @property\n    def request_timeout_in_millis(self) -> int:\n        \"\"\"\n        Return the request timeout in milliseconds.\n\n        :return: the request timeout\n        \"\"\"\n        return self._request_timeout\n\n    @request_timeout_in_millis.setter\n    def request_timeout_in_millis(self, request_timeout: int) -> None:\n        \"\"\"\n        Set the request timeout in milliseconds.\n\n        :param request_timeout: the new request timeout in milliseconds\n        \"\"\"\n        self._request_timeout = request_timeout\n\n\n@proxy(\"aggregator.ScriptAggregator\")\nclass ScriptAggregator(Generic[R], EntryAggregator[R]):\n    \"\"\"ScriptAggregator is a :class:`coherence.aggregator.EntryAggregator` that wraps a script written in one of the\n    languages supported by Graal VM.\"\"\"\n\n    def __init__(self, language: str, script_name: str, characteristics: int = 0, *args: Any):\n        \"\"\"\n        Create a :class:`coherence.aggregator.EntryAggregator` that wraps the specified script.\n\n        :param language: The language with which the script is written in.\n        :param script_name: The name of the :class:`coherence.aggregator.EntryAggregator` that needs to be evaluated.\n        :param characteristics: Present only for serialization purposes.\n        :param args: The arguments to be passed to the script for evaluation\n        \"\"\"\n        super().__init__()\n        self.language = language\n        self.name = script_name\n        self.args = list()\n        for arg in args:\n            self.args.append(arg)\n        self.characteristics = characteristics\n\n\nclass RecordType(Enum):\n    EXPLAIN = 0\n    \"\"\"Produce an object that contains an estimated cost of the query execution.\"\"\"\n\n    TRACE = 1\n    \"\"\"Produce an object that contains the actual cost of the query execution.\"\"\"\n\n\n# TODO IMPROVE\n@proxy(\"aggregator.QueryRecorder\")\nclass QueryRecorder(EntryAggregator[Any]):\n    \"\"\"This aggregator is used to produce an object that contains an estimated or actual cost of the query execution\n    for a given :class:`coherence.filter.Filter`.\n\n    For example, the following code will print a *QueryRecord*,\n    containing the estimated query cost and corresponding execution steps::\n\n        agent  = QueryRecorder(RecordType.EXPLAIN);\n        record = cache.aggregate(someFilter, agent);\n        print(json.dumps(record));\n    \"\"\"\n\n    EXPLAIN: str = \"EXPLAIN\"\n    \"\"\"String constant for serialization purposes.\"\"\"\n\n    TRACE: str = \"TRACE\"\n    \"\"\"String constant for serialization purposes.\"\"\"\n\n    def __init__(self, query_type: RecordType):\n        \"\"\"\n        Construct a new `QueryRecorder`.\n\n        :param query_type: the type for this aggregator\n        \"\"\"\n        super().__init__()\n        self.type = QueryRecorder.get_type(query_type)\n\n    @classmethod\n    def get_type(cls, query_type: RecordType) -> dict[str, str]:\n        if query_type == RecordType.EXPLAIN:\n            return {\"enum\": cls.EXPLAIN}\n        elif query_type == RecordType.TRACE:\n            return {\"enum\": cls.TRACE}\n\n\n@proxy(\"aggregator.ReducerAggregator\")\nclass ReducerAggregator(EntryAggregator[R]):\n    \"\"\"The `ReducerAggregator` is used to implement functionality similar to :class:`coherence.client.NamedMap.getAll(\n    )` API.  Instead of returning the complete set of values, it will return a portion of value attributes based on\n    the provided :class:`coherence.extractor.ValueExtractor`.\n\n    This aggregator could be used in combination with {@link MultiExtractor} allowing one to collect tuples that are\n    a subset of the attributes of each object stored in the cache.\"\"\"\n\n    def __init__(self, extractor_or_property: ExtractorExpression[T, E]):\n        \"\"\"\n        Creates a new `ReducerAggregator`.\n\n        :param extractor_or_property: the extractor that provides values to aggregate or the name of the method that\n            could be invoked via Java reflection and that returns values to aggregate; this parameter can also be a\n            dot-delimited sequence of method names which would result in an aggregator based on the\n            :class:`coherence.extractor.ChainedExtractor` that is based on an array of corresponding\n            :class:`coherence.extractor.UniversalExtractor` objects; must not be `None`\n        \"\"\"\n        super().__init__(extractor_or_property)\n\n\nclass Aggregators:\n    \"\"\"Simple Aggregator DSL.\n\n    The methods in this class are for the most part simple factory methods for various\n    :class:`coherence.aggregator.EntryAggregator`  classes, but in some cases provide additional type safety. They\n    also tend to make the code more readable, especially if imported statically, so their use is strongly encouraged\n    in lieu of direct construction of :class:`coherence.aggregator.EntryAggregator`  classes.\"\"\"\n\n    @staticmethod\n    def max(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[R]:\n        \"\"\"\n        Return an aggregator that calculates a maximum of the numeric values extracted from a set of entries in a Map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that calculates a maximum of the numeric values extracted from a set of entries in a Map\n        \"\"\"\n        return MaxAggregator(extractor_or_property)\n\n    @staticmethod\n    def min(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[R]:\n        \"\"\"\n        Return an aggregator that calculates a minimum of the numeric values extracted from a set of entries in a Map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that calculates a minimum of the numeric values extracted from a set of entries in a Map.\n        \"\"\"\n        return MinAggregator(extractor_or_property)\n\n    @staticmethod\n    def sum(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[Decimal]:\n        \"\"\"\n        Return an aggregator that calculates a sum of the numeric values extracted from a set of entries in a Map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that calculates a sum of the numeric values extracted from a set of entries in a Map.\n        \"\"\"\n        return SumAggregator(extractor_or_property)\n\n    @staticmethod\n    def average(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[Decimal]:\n        \"\"\"\n        Return an aggregator that calculates an average of the numeric values extracted from a set of entries in a Map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that calculates an average of the numeric values extracted from a\n                 set of entries in a Map.\n        \"\"\"\n        return AverageAggregator(extractor_or_property)\n\n    @staticmethod\n    def distinct(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[List[R]]:\n        \"\"\"\n        Return an aggregator that calculates the set of distinct values from the entries in a Map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that calculates the set of distinct values from the entries in a Map.\n        \"\"\"\n        return DistinctValuesAggregator(extractor_or_property)\n\n    @staticmethod\n    def count() -> EntryAggregator[int]:\n        \"\"\"\n        Return an aggregator that calculates a number of values in an entry set.\n\n        :return: an aggregator that calculates a number of values in an entry set.\n        \"\"\"\n        return CountAggregator()\n\n    @staticmethod\n    def top(count: int) -> TopAggregator[Any, Any]:\n        \"\"\"\n        Return an aggregator that aggregates the top *N* extracted values into an array.\n\n        :param count: the maximum number of results to include in the aggregation result\n        :return: an aggregator that aggregates the top *N* extracted values into an array.\n        \"\"\"\n        return TopAggregator(count)\n\n    @staticmethod\n    def group_by(\n        extractor_or_property: ExtractorExpression[T, E],\n        aggregator: EntryAggregator[Any],\n        filter: Optional[Filter] = None,\n    ) -> EntryAggregator[Dict[G, T]]:\n        \"\"\"\n        Return a :class:`coherence.aggregator.GroupAggregator` based on a specified property or method name(s) and an\n        :class:`coherence.aggregator.EntryAggregator`.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :param aggregator: the underlying :class:`coherence.aggregator.EntryAggregator`\n        :param filter: an optional :class:`coherence.filter.Filter` object used to filter out results of individual\n          group aggregation results\n        :return: a :class:`coherence.aggregator.GroupAggregator` based on a specified property or method name(s) and an\n          :class:`coherence.aggregator.EntryAggregator`.\n        \"\"\"\n        return GroupAggregator(extractor_or_property, aggregator, filter)\n\n    @staticmethod\n    def priority(\n        aggregator: EntryAggregator[R],\n        execution_timeout: Timeout = Timeout.DEFAULT,\n        request_timeout: Timeout = Timeout.DEFAULT,\n        scheduling_priority: Schedule = Schedule.STANDARD,\n    ) -> EntryAggregator[R]:\n        \"\"\"\n        Return a new :class:`coherence.aggregator.PriorityAggregator` to control scheduling priority of an aggregation\n        operation.\n\n        :param aggregator: the underlying :class:`coherence.aggregator.EntryAggregator`\n        :param execution_timeout: the execution :class:`coherence.aggregator.Timeout`\n        :param request_timeout: the request :class:`coherence.aggregator.Timeout`\n        :param scheduling_priority: the :class:`coherence.aggregator.Schedule` priority\n        :return: a new :class:`coherence.aggregator.PriorityAggregator` to control scheduling priority of an aggregation\n         operation.\n        \"\"\"\n        return PriorityAggregator(aggregator, execution_timeout, request_timeout, scheduling_priority)\n\n    @staticmethod\n    def script(language: str, script_name: str, characteristics: int = 0, *args: Any) -> EntryAggregator[R]:\n        \"\"\"\n        Return an aggregator that is implemented in a script using the specified language.\n\n        :param language: The language with which the script is written in.\n        :param script_name: The name of the :class:`coherence.aggregator.EntryAggregator` that needs to be evaluated.\n        :param characteristics: Present only for serialization purposes.\n        :param args: The arguments to be passed to the script for evaluation\n        :return: an aggregator that is implemented in a script using the specified language.\n        \"\"\"\n        return ScriptAggregator(language, script_name, characteristics, *args)\n\n    @staticmethod\n    def record(query_type: RecordType = RecordType.EXPLAIN) -> EntryAggregator[Any]:\n        \"\"\"\n        Returns a new :class:`coherence.aggregator.QueryRecorder` aggregator which may be used is used to produce an\n        object that contains an estimated or actual cost of the query execution for a given\n        :class:`coherence.filter.Filter`.\n\n        :param query_type: the :class:`coherence.aggregator.RecordType`\n        :return: a new :class:`coherence.aggregator.QueryRecorder` aggregator which may be used is used to produce an\n         object that contains an estimated or actual cost of the query execution for a given\n         :class:`coherence.filter.Filter`.\n        \"\"\"\n        return QueryRecorder(query_type)\n\n    @staticmethod\n    def reduce(extractor_or_property: ExtractorExpression[T, E]) -> EntryAggregator[ReducerResult[K]]:\n        \"\"\"\n        Return an aggregator that will return the extracted value for each entry in the map.\n\n        :param extractor_or_property: the extractor or method/property name to provide values for aggregation\n        :return: an aggregator that will return the extracted value for each entry in the map.\n        \"\"\"\n        return ReducerAggregator(extractor_or_property)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/aggregator.py b/src/coherence/aggregator.py
--- a/src/coherence/aggregator.py	(revision 92f434777646d1cced9a1612e9b4264d4066a77e)
+++ b/src/coherence/aggregator.py	(date 1726012780634)
@@ -346,8 +346,9 @@
          that is based on an array of corresponding :class:`coherence.extractor.UniversalExtractor` objects; may not be
          `NONE`
 
-        :param aggregator: an EntryAggregator object; may not be null
-        :param filter: an optional Filter object used to filter out results of individual group aggregation results
+        :param aggregator:   an EntryAggregator object; may not be null
+        :param filter: an optional Filter object used to filter out results
+         of individual group aggregation results
         """
         super().__init__(extractor_or_property)
         if aggregator is not None:
@@ -654,8 +655,8 @@
 
         :param extractor_or_property: the extractor or method/property name to provide values for aggregation
         :param aggregator: the underlying :class:`coherence.aggregator.EntryAggregator`
-        :param filter: an optional :class:`coherence.filter.Filter` object used to filter out results of individual
-          group aggregation results
+        :param filter: an optional :class:`coherence.filter.Filter` object used to filter out results
+          of individual group aggregation results
         :return: a :class:`coherence.aggregator.GroupAggregator` based on a specified property or method name(s) and an
           :class:`coherence.aggregator.EntryAggregator`.
         """
