Index: tests/test_aggregators.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport os\nfrom decimal import Decimal\nfrom typing import Any, AsyncGenerator, Final, List, cast\n\nimport pytest\nimport pytest_asyncio\n\nfrom coherence import Aggregators, Filters, NamedCache, Options, Session, TlsOptions\nfrom coherence.aggregator import (\n    EntryAggregator,\n    PriorityAggregator,\n    RecordType,\n    ReducerResult,\n    Schedule,\n    ScriptAggregator,\n    Timeout,\n    TopAggregator,\n)\nfrom coherence.serialization import JSONSerializer\nfrom tests.person import Person\n\n\nasync def get_session() -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = Session(options)\n    else:\n        session = await Session.create()\n\n    return session\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown() -> AsyncGenerator[NamedCache[Any, Any], None]:\n    session: Session = await get_session()\n    cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n\n    await cache.put(Person.Pat().name, Person.Pat())\n    await cache.put(Person.Paula().name, Person.Paula())\n    await cache.put(Person.Andy().name, Person.Andy())\n    await cache.put(Person.Alice().name, Person.Alice())\n    await cache.put(Person.Jim().name, Person.Jim())\n    await cache.put(Person.Fred().name, Person.Fred())\n    await cache.put(Person.Fiona().name, Person.Fiona())\n    print(\"\\n\")\n    print(Person.Pat())\n    print(Person.Paula())\n    print(Person.Andy())\n    print(Person.Alice())\n    print(Person.Jim())\n    print(Person.Fred())\n    print(Person.Fiona())\n    yield cache\n\n    await cache.clear()\n    await cache.destroy()\n    await session.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_max(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag: EntryAggregator[int] = Aggregators.max(\"age\")\n    r: int = await cache.aggregate(ag)\n    assert r == Person.Pat().age\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_min(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag: EntryAggregator[int] = Aggregators.min(\"age\")\n    r: int = await cache.aggregate(ag)\n    assert r == Person.Alice().age\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_sum(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag = Aggregators.sum(\"age\")\n    r = await cache.aggregate(ag)\n    assert r == (\n        Person.Andy().age\n        + Person.Alice().age\n        + Person.Pat().age\n        + Person.Paula().age\n        + Person.Fred().age\n        + Person.Fiona().age\n        + Person.Jim().age\n    )\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_average(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag = Aggregators.average(\"age\")\n    r: Decimal = await cache.aggregate(ag)\n    assert float(r) == round(\n        (\n            Person.Andy().age\n            + Person.Alice().age\n            + Person.Pat().age\n            + Person.Paula().age\n            + Person.Fred().age\n            + Person.Fiona().age\n            + Person.Jim().age\n        )\n        / 7,\n        8,\n    )\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_count(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag = Aggregators.count()\n    r: int = await cache.aggregate(ag)\n    assert r == 7\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_distinct_values(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag: EntryAggregator[List[str]] = Aggregators.distinct(\"gender\")\n    r: list[str] = await cache.aggregate(ag)\n    assert sorted(r) == [\"Female\", \"Male\"]\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_top(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag: TopAggregator[int, Person] = Aggregators.top(2).order_by(\"age\").ascending\n    r: list[Person] = await cache.aggregate(ag)\n    assert r == [Person.Alice(), Person.Andy()]\n\n    ag = Aggregators.top(2).order_by(\"age\").ascending\n    r = await cache.aggregate(ag, None, Filters.between(\"age\", 30, 40))\n    assert r == [Person.Paula(), Person.Jim()]\n\n    ag = Aggregators.top(2).order_by(\"age\").descending\n    r = await cache.aggregate(ag)\n    assert r == [Person.Pat(), Person.Fred()]\n\n    ag = Aggregators.top(2).order_by(\"age\").descending\n    r = await cache.aggregate(ag, None, Filters.between(\"age\", 20, 30))\n    assert r == [Person.Fiona(), Person.Andy()]\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_group(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    ag: EntryAggregator[dict[str, int]] = Aggregators.group_by(\"gender\", Aggregators.min(\"age\"), Filters.always())\n\n    r: dict[str, int] = await cache.aggregate(ag)\n    print(\"\\n\" + str(r))\n    assert r == {\"Male\": 25, \"Female\": 22}\n\n    f = Filters.between(\"age\", 20, 24)\n    r = await cache.aggregate(ag, None, f)\n    print(\"\\n\" + str(r))\n    assert r == {\"Female\": 22}\n\n    r = await cache.aggregate(ag, {\"Pat\", \"Paula\", \"Fred\"})\n    print(\"\\n\" + str(r))\n    assert r == {\"Male\": 58, \"Female\": 35}\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_priority(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    agg: EntryAggregator[Decimal] = Aggregators.priority(Aggregators.sum(\"age\"))\n    agg_actual: PriorityAggregator[Decimal] = cast(PriorityAggregator[Decimal], agg)\n    assert agg_actual.execution_timeout_in_millis == Timeout.DEFAULT\n    assert agg_actual.request_timeout_in_millis == Timeout.DEFAULT\n    assert agg_actual.scheduling_priority == Schedule.STANDARD\n\n    r = await cache.aggregate(agg)\n    assert r == (\n        Person.Andy().age\n        + Person.Alice().age\n        + Person.Pat().age\n        + Person.Paula().age\n        + Person.Fred().age\n        + Person.Fiona().age\n        + Person.Jim().age\n    )\n\n    agg2: EntryAggregator[Decimal] = Aggregators.priority(\n        Aggregators.sum(\"age\"),\n        execution_timeout=Timeout.NONE,\n        request_timeout=Timeout.NONE,\n        scheduling_priority=Schedule.IMMEDIATE,\n    )\n    agg2_actual: PriorityAggregator[Decimal] = cast(PriorityAggregator[Decimal], agg2)\n    assert agg2_actual.execution_timeout_in_millis == Timeout.NONE\n    assert agg2_actual.request_timeout_in_millis == Timeout.NONE\n    assert agg2_actual.scheduling_priority == Schedule.IMMEDIATE\n\n    filter = Filters.equals(\"gender\", \"Male\")\n    r = await cache.aggregate(agg, None, filter)\n    assert r == (Person.Andy().age + Person.Pat().age + Person.Fred().age + Person.Jim().age)\n\n    r = await cache.aggregate(agg, {\"Alice\", \"Paula\", \"Fiona\"})\n    assert r == (Person.Alice().age + Person.Paula().age + Person.Fiona().age)\n\n\n# noinspection PyShadowingNames\ndef test_script() -> None:\n    agg: EntryAggregator[Any] = Aggregators.script(\"py\", \"test_script.py\", 0, \"abc\", 2, 4.0)\n    serializer = JSONSerializer()\n    j = serializer.serialize(agg)\n\n    script_aggregator: ScriptAggregator[Any] = serializer.deserialize(j)\n    assert script_aggregator.name == \"test_script.py\"\n    assert script_aggregator.language == \"py\"\n    assert script_aggregator.args == [\"abc\", 2, 4.0]\n    assert script_aggregator.characteristics == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_query_recorder(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    agg = Aggregators.record()\n    f = Filters.between(\"age\", 20, 30)\n    my_result: dict[str, Any | list[Any]] = await cache.aggregate(agg, None, f)\n    assert my_result.get(\"results\") is not None\n    my_list: Any | list[Any] = my_result.get(\"results\")\n    assert len(my_list) == 1\n    assert my_list[0].get(\"partitionSet\") is not None\n    assert my_list[0].get(\"steps\") is not None\n\n    agg = Aggregators.record(RecordType.TRACE)\n    f = Filters.between(\"age\", 20, 30)\n    my_result = await cache.aggregate(agg, None, f)\n    assert my_result.get(\"results\") is not None\n    my_list = my_result.get(\"results\")\n    assert len(my_list) == 1  # type: ignore\n    assert my_list[0].get(\"partitionSet\") is not None  # type: ignore\n    assert my_list[0].get(\"steps\") is not None  # type: ignore\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_reducer(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[str, Person] = setup_and_teardown\n\n    agg: EntryAggregator[ReducerResult[str]] = Aggregators.reduce(\"age\")\n    f = Filters.between(\"age\", 20, 30)\n    my_result: ReducerResult[str] = await cache.aggregate(agg, None, f)\n    print(\"\\n\" + str(my_result))\n    assert my_result == {\"Andy\": 25, \"Fiona\": 29, \"Alice\": 22}\n\n    my_result = await cache.aggregate(agg, {\"Andy\", \"Fiona\", \"Alice\"})\n    print(\"\\n\" + str(my_result))\n    assert my_result == {\"Andy\": 25, \"Alice\": 22, \"Fiona\": 29}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_aggregators.py b/tests/test_aggregators.py
--- a/tests/test_aggregators.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/tests/test_aggregators.py	(date 1687412420739)
@@ -43,7 +43,7 @@
         tls_options.enabled = True
         tls_options.locked()
 
-        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)
+        options: Options = Options(default_address, default_scope, default_request_timeout, ser_format=default_format)
         options.tls_options = tls_options
         options.channel_options = (("grpc.ssl_target_name_override", "Star-Lord"),)
         session = Session(options)
Index: tests/test_events.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport asyncio\nimport os\nimport time\nfrom typing import Any, AsyncGenerator, Final, Generic, List, TypeVar, cast\n\nimport pytest\nimport pytest_asyncio\n\nfrom coherence import Filters, NamedCache, Options, Session, TlsOptions\nfrom coherence.event import MapEvent, MapEventType\nfrom coherence.filter import Filter, LessFilter, MapEventFilter\nfrom tests import CountingMapListener\nfrom tests.person import Person\n\nK = TypeVar(\"K\")\n\"\"\"Generic type for cache keys\"\"\"\n\nV = TypeVar(\"V\")\n\"\"\"Generic type for cache values\"\"\"\n\n\nclass ValidateEvent(Generic[K, V]):\n    \"\"\"Simple class to validate expected values against a MapEvent.\"\"\"\n\n    def __init__(self, name: str, source: NamedCache[K, V], key: K, old: V | None, new: V | None, _type: MapEventType):\n        \"\"\"\n        Constructs a new ValidateEvent.\n        :param name:    the expected cache name\n        :param source:  the expected event source\n        :param key:     the expected key\n        :param old:     the expected old value, if any\n        :param new:     the expected new value, if any\n        :param _type:   the MapEventType\n        \"\"\"\n        self._name: str = name\n        self._source: NamedCache[K, V] = source\n        self._key: K = key\n        self._old: V | None = old\n        self._new: V | None = new\n        self._type: MapEventType = _type\n\n    def __str__(self) -> str:\n        \"\"\"\n        Returns a string representation of this event.\n        :return: a string representation of this event\n        \"\"\"\n        return (\n            \"ValidateEvent{\"\n            + str(self.type.name)\n            + \", cache=\"\n            + str(self.name)\n            + \", key=\"\n            + str(self.key)\n            + \", old=\"\n            + str(self.old)\n            + \", new=\"\n            + str(self.new)\n            + \"}\"\n        )\n\n    def equals(self, o: object) -> bool:\n        \"\"\"\n        Returns `True` if the comparing against a MapEvent and the MapEvent has the same value for the\n        aligned properties, otherwise returns `False`.\n        :param o:  the object to test\n        :return: `True` if the comparing against a MapEvent and the MapEvent has the same value for the\n        aligned properties, otherwise returns `False`\n        \"\"\"\n        if isinstance(o, MapEvent):\n            event: MapEvent[K, V] = cast(MapEvent[K, V], o)\n            return (\n                event.name == self.name\n                and event.description == self.description\n                and event.source == self.source\n                and event.key == self.key\n                and event.old == self.old\n                and event.new == self.new\n                and event.type == self.type\n            )\n\n        return False\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        Returns the expected cache name.\n        :return: the expected cache name\n        \"\"\"\n        return self._name\n\n    @property\n    def description(self) -> str:\n        \"\"\"\n        Returns the event's description.\n        :return: the event's description\n        \"\"\"\n        match self.type:\n            case MapEventType.ENTRY_INSERTED:\n                return \"insert\"\n            case MapEventType.ENTRY_UPDATED:\n                return \"update\"\n            case MapEventType.ENTRY_DELETED:\n                return \"delete\"\n            case _:\n                return \"unknown\"\n\n    @property\n    def source(self) -> NamedCache[K, V]:\n        \"\"\"\n        Returns the expected event source.\n        :return: the expected event source\n        \"\"\"\n        return self._source\n\n    @property\n    def key(self) -> K:\n        \"\"\"\n        Returns the expected key.\n        :return:  the expected key\n        \"\"\"\n        return self._key\n\n    @property\n    def old(self) -> V | None:\n        \"\"\"\n        Returns the expected old value.\n        :return: the expected old value\n        \"\"\"\n        return self._old\n\n    @property\n    def new(self) -> V | None:\n        \"\"\"\n        Returns the expected new value.\n        :return: the expected new value\n        \"\"\"\n        return self._new\n\n    @property\n    def type(self) -> MapEventType:\n        \"\"\"\n        Return the expected MapEventType\n        :return: the expected MapEventType\n        \"\"\"\n        return self._type\n\n\nclass ExpectedEvents(Generic[K, V]):\n    \"\"\"Class for validating expected results against those produced by a CountingMapListener.\"\"\"\n\n    def __init__(\n        self, inserts: List[ValidateEvent[K, V]], updates: List[ValidateEvent[K, V]], deletes: List[ValidateEvent[K, V]]\n    ) -> None:\n        \"\"\"\n        Constructs a new ExpectedEvents.\n        :param inserts: a list of expected inserts\n        :param updates: a list of expected updates\n        :param deletes: a list of expected deletes\n        \"\"\"\n        super().__init__()\n        self._inserts: List[ValidateEvent[K, V]] = inserts\n        self._updates: List[ValidateEvent[K, V]] = updates\n        self._deletes: List[ValidateEvent[K, V]] = deletes\n\n    @property\n    def inserts(self) -> List[ValidateEvent[K, V]]:\n        \"\"\"\n        Returns the list of expected insert events.\n        :return: the list of expected insert events\n        \"\"\"\n        return self._inserts\n\n    @property\n    def updates(self) -> List[ValidateEvent[K, V]]:\n        \"\"\"\n        Returns the list of expected update events.\n        :return: the list of expected update events\n        \"\"\"\n        return self._updates\n\n    @property\n    def deletes(self) -> List[ValidateEvent[K, V]]:\n        \"\"\"\n        Returns the list of expected delete events.\n        :return: the list of expected delete events\n        \"\"\"\n        return self._deletes\n\n    @property\n    def total(self) -> int:\n        \"\"\"\n        Returns the expected total of events that should be captured.\n        :return:  the expected total of events that should be captured\n        \"\"\"\n        return self.inserts_count + self.updates_count + self.deletes_count\n\n    @property\n    def inserts_count(self) -> int:\n        \"\"\"\n        Returns the expected number of insert events.\n        :return: the expected number of insert events\n        \"\"\"\n        return len(self.inserts)\n\n    @property\n    def updates_count(self) -> int:\n        \"\"\"\n        Returns the expected number of update events.\n        :return: the expected number of update events\n        \"\"\"\n        return len(self.updates)\n\n    @property\n    def deletes_count(self) -> int:\n        \"\"\"\n        Returns the expected number of delete events.\n        :return: the expected number of delete events\n        \"\"\"\n        return len(self.deletes)\n\n    def validate(self, listener: CountingMapListener[K, V]) -> None:\n        \"\"\"\n        Validate the expected events against those captured by the provided listener.\n        :param listener: the listener with captured events\n        \"\"\"\n        assert listener.count == self.total\n        assert len(listener.inserted) == self.inserts_count\n        assert len(listener.updated) == self.updates_count\n        assert len(listener.deleted) == self.deletes_count\n\n        self.ensure_equal(self.inserts, listener.inserted)\n        self.ensure_equal(self.updates, listener.updated)\n        self.ensure_equal(self.deletes, listener.deleted)\n\n        ordered_expected: List[ValidateEvent[K, V]] = self.inserts + self.updates + self.deletes\n        ordered_actual: List[MapEvent[K, V]] = listener.order\n        self.ensure_equal(ordered_expected, ordered_actual)\n\n    @staticmethod\n    def ensure_equal(expected: List[ValidateEvent[K, V]], actual: List[MapEvent[K, V]]) -> None:\n        \"\"\"\n        Validate event lists are essentially equal.\n        :param expected: the expected event list\n        :param actual:  the actual event list\n        \"\"\"\n        for index, exp in enumerate(expected):\n            act: MapEvent[K, V] = actual[index]\n            assert exp.equals(act), \"Expected [\" + str(exp) + \"], received: [\" + str(act) + \"]\"\n\n\nasync def _run_basic_test(\n    cache: NamedCache[str, str], expected: ExpectedEvents[str, str], filter_mask: int | None = None\n) -> None:\n    \"\"\"\n    Common logic for basic event tests.\n    :param cache:        the cache under test\n    :param expected:     the ExpectedEvents for this test\n    :param filter_mask:  the event mask, if any\n    \"\"\"\n    listener: CountingMapListener[str, str] = CountingMapListener(\"basic\")\n\n    if filter_mask is None:\n        await cache.add_map_listener(listener)\n    else:\n        await cache.add_map_listener(listener, MapEventFilter(filter_mask, Filters.always()))\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"A\", \"C\")\n    await cache.remove(\"A\")\n\n    await listener.wait_for(expected.total)\n\n    expected.validate(listener)\n\n    # remove the listener and trigger some events.  Ensure no events captured.\n    listener.reset()\n    await cache.remove_map_listener(listener)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"A\", \"C\")\n    await cache.remove(\"A\")\n\n    await listener.wait_for(0)\n\n    expected2: ExpectedEvents[str, str] = ExpectedEvents([], [], [])\n    expected2.validate(listener)\n\n\nasync def get_session() -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = await Session.create(options)\n    else:\n        session = await Session.create()\n\n    return session\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown() -> AsyncGenerator[NamedCache[Any, Any], None]:\n    \"\"\"\n    Fixture for test setup/teardown.\n    \"\"\"\n    session: Session = await get_session()\n    cache: NamedCache[Any, Any] = await session.get_cache(\"test-\" + str(time.time_ns()))\n\n    yield cache\n\n    await cache.clear()\n    await cache.destroy()\n    await session.close()\n\n\n# ----- test functions ------------------------------------------------------\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_all(setup_and_teardown: NamedCache[str, str]) -> None:\n    \"\"\"Ensure the registered MapListener is able to receive insert, update, and delete events.\"\"\"\n\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = cache.name\n\n    expected: ExpectedEvents[str, str] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"A\", None, \"B\", MapEventType.ENTRY_INSERTED)],\n        [ValidateEvent(name, cache, \"A\", \"B\", \"C\", MapEventType.ENTRY_UPDATED)],\n        [ValidateEvent(name, cache, \"A\", \"C\", None, MapEventType.ENTRY_DELETED)],\n    )\n\n    await _run_basic_test(cache, expected)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_inserts_only(setup_and_teardown: NamedCache[str, str]) -> None:\n    \"\"\"Ensure the registered MapListener is able to receive insert events only.\"\"\"\n\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = cache.name\n\n    expected: ExpectedEvents[str, str] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"A\", None, \"B\", MapEventType.ENTRY_INSERTED)], [], []\n    )\n\n    await _run_basic_test(cache, expected, MapEventFilter.INSERTED)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_updates_only(setup_and_teardown: NamedCache[str, str]) -> None:\n    \"\"\"Ensure the registered MapListener is able to receive update events only.\"\"\"\n\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = cache.name\n\n    expected: ExpectedEvents[str, str] = ExpectedEvents(\n        [], [ValidateEvent(name, cache, \"A\", \"B\", \"C\", MapEventType.ENTRY_UPDATED)], []\n    )\n\n    await _run_basic_test(cache, expected, MapEventFilter.UPDATED)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_deletes_only(setup_and_teardown: NamedCache[str, str]) -> None:\n    \"\"\"Ensure the registered MapListener is able to receive delete events only.\"\"\"\n\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = cache.name\n\n    expected: ExpectedEvents[str, str] = ExpectedEvents(\n        [], [], [ValidateEvent(name, cache, \"A\", \"C\", None, MapEventType.ENTRY_DELETED)]\n    )\n\n    await _run_basic_test(cache, expected, MapEventFilter.DELETED)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_multiple_listeners(setup_and_teardown: NamedCache[str, str]) -> None:\n    \"\"\"Ensure the multiple registered MapListeners are able to receive insert, update, and delete events.\"\"\"\n\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = cache.name\n\n    expected: ExpectedEvents[str, str] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"A\", None, \"B\", MapEventType.ENTRY_INSERTED)],\n        [ValidateEvent(name, cache, \"A\", \"B\", \"C\", MapEventType.ENTRY_UPDATED)],\n        [ValidateEvent(name, cache, \"A\", \"C\", None, MapEventType.ENTRY_DELETED)],\n    )\n\n    listener: CountingMapListener[str, str] = CountingMapListener(\"basic\")\n    listener2: CountingMapListener[str, str] = CountingMapListener(\"basic\")\n\n    await cache.add_map_listener(listener)\n    await cache.add_map_listener(listener2)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"A\", \"C\")\n    await cache.remove(\"A\")\n\n    await listener.wait_for(expected.total)\n    await listener2.wait_for(expected.total)\n\n    expected.validate(listener)\n    expected.validate(listener2)\n\n    # remove the listener and trigger some events.  Ensure no events captured for listener but\n    # events captured by the listener2\n    listener.reset()\n    listener2.reset()\n    await cache.remove_map_listener(listener)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"A\", \"C\")\n    await cache.remove(\"A\")\n\n    # give some time for any events\n    await asyncio.sleep(1)\n    await listener.wait_for(0)\n    await listener2.wait_for(expected.total)\n\n    no_events: ExpectedEvents[str, str] = ExpectedEvents([], [], [])\n    no_events.validate(listener)\n\n    expected.validate(listener2)\n\n    # remove the remaining listener and trigger some events.  Ensure no events captured.\n    listener.reset()\n    listener2.reset()\n    await cache.remove_map_listener(listener2)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"A\", \"C\")\n    await cache.remove(\"A\")\n\n    # give some time for any events\n    await asyncio.sleep(1)\n    await listener.wait_for(0)\n    await listener2.wait_for(0)\n\n    no_events.validate(listener)\n    no_events.validate(listener2)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_custom_filter_listener(setup_and_teardown: NamedCache[str, Person]) -> None:\n    \"\"\"Ensure a custom filter is applied when filtering values for events.\"\"\"\n\n    cache: NamedCache[str, Person] = setup_and_teardown\n    name: str = cache.name\n\n    fred: Person = Person.Fred()\n    fiona: Person = Person.Fiona()\n    pat: Person = Person.Pat()\n\n    expected: ExpectedEvents[str, Person] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"C\", None, fiona, MapEventType.ENTRY_INSERTED)],\n        [],\n        [],\n    )\n\n    listener: CountingMapListener[str, Person] = CountingMapListener(\"basic\")\n    filter: Filter = LessFilter(\"age\", 30)\n    no_events: ExpectedEvents[str, Person] = ExpectedEvents([], [], [])\n\n    await cache.add_map_listener(listener, filter)\n\n    await cache.put(\"A\", fred)\n    await asyncio.sleep(1)\n    no_events.validate(listener)\n\n    await cache.put(\"B\", pat)\n    await asyncio.sleep(1)\n    no_events.validate(listener)\n\n    await cache.put(\"C\", fiona)\n    await listener.wait_for(expected.total)\n    expected.validate(listener)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_key_listener(setup_and_teardown: NamedCache[str, Person]) -> None:\n    \"\"\"Ensure a listener can be associated with a key.\"\"\"\n\n    cache: NamedCache[str, Person] = setup_and_teardown\n    name: str = cache.name\n\n    fred: Person = Person.Fred()\n    fiona: Person = Person.Fiona()\n    pat: Person = Person.Pat()\n\n    expected: ExpectedEvents[str, Person] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"C\", None, fiona, MapEventType.ENTRY_INSERTED)],\n        [],\n        [],\n    )\n\n    listener: CountingMapListener[str, Person] = CountingMapListener(\"basic\")\n    no_events: ExpectedEvents[str, Person] = ExpectedEvents([], [], [])\n\n    await cache.add_map_listener(listener, \"C\")\n\n    await cache.put(\"A\", fred)\n    await asyncio.sleep(1)\n    no_events.validate(listener)\n\n    await cache.put(\"B\", pat)\n    await asyncio.sleep(1)\n    no_events.validate(listener)\n\n    await cache.put(\"C\", fiona)\n    await listener.wait_for(expected.total)\n    expected.validate(listener)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_lite_listeners(setup_and_teardown: NamedCache[str, Person]) -> None:\n    \"\"\"Ensure lite event handling works as expected alone or when similar listeners\n    are registered that are non-lite.  See test comments for details.\"\"\"\n\n    cache: NamedCache[str, Person] = setup_and_teardown\n    name: str = cache.name\n    always: Filter = Filters.always()\n\n    key_listener: CountingMapListener[str, Person] = CountingMapListener(\"key\")\n    filter_listener: CountingMapListener[str, Person] = CountingMapListener(\"filter\")\n    key_listener_lite: CountingMapListener[str, Person] = CountingMapListener(\"lite-key\")\n    filter_listener_lite: CountingMapListener[str, Person] = CountingMapListener(\"lite-filter\")\n\n    await cache.add_map_listener(key_listener_lite, \"A\", True)\n    await cache.add_map_listener(filter_listener_lite, always, True)\n\n    fiona: Person = Person.Fiona()\n\n    expected_lite: ExpectedEvents[str, Person] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"A\", None, None, MapEventType.ENTRY_INSERTED)],\n        [],\n        [],\n    )\n\n    expected_non_lite: ExpectedEvents[str, Person] = ExpectedEvents(\n        [ValidateEvent(name, cache, \"A\", None, fiona, MapEventType.ENTRY_INSERTED)],\n        [],\n        [],\n    )\n\n    await cache.put(\"A\", fiona)\n\n    await key_listener_lite.wait_for(expected_lite.total)\n    expected_lite.validate(key_listener_lite)\n\n    await filter_listener_lite.wait_for(expected_lite.total)\n    expected_lite.validate(filter_listener_lite)\n\n    await cache.clear()\n    await asyncio.sleep(1)\n    key_listener_lite.reset()\n    filter_listener_lite.reset()\n\n    # adding non-lite listeners for same key and filter values\n    # should result in non-lite events being returned.\n    # From the Coherence docs:\n    # Note:\n    # Obviously, a lite event's old value and new value may be null.\n    # However, even if you request lite events, the old and the new value\n    # may be included if there is no additional cost to generate and deliver\n    # the event. In other words, requesting that a MapListener receive lite\n    # events is simply a hint to the system that the MapListener does\n    # not have to know the old and new values for the event.\n    await cache.add_map_listener(key_listener, \"A\")\n    await cache.add_map_listener(filter_listener, always)\n\n    await cache.put(\"A\", fiona)\n\n    await key_listener_lite.wait_for(expected_non_lite.total)\n    expected_non_lite.validate(key_listener_lite)\n\n    await key_listener.wait_for(expected_non_lite.total)\n    expected_non_lite.validate(key_listener)\n\n    await filter_listener_lite.wait_for(expected_non_lite.total)\n    expected_non_lite.validate(filter_listener_lite)\n\n    await filter_listener.wait_for(expected_non_lite.total)\n    expected_non_lite.validate(filter_listener)\n\n    await cache.clear()\n    await asyncio.sleep(1)\n    key_listener_lite.reset()\n    key_listener.reset()\n    filter_listener_lite.reset()\n    filter_listener.reset()\n\n    # now, remove the non-lite listeners and ensure lite events are received again\n    await cache.remove_map_listener(key_listener, \"A\")\n    await cache.remove_map_listener(filter_listener, always)\n\n    await cache.put(\"A\", fiona)\n\n    await key_listener_lite.wait_for(expected_lite.total)\n    expected_lite.validate(key_listener_lite)\n\n    await filter_listener_lite.wait_for(expected_lite.total)\n    expected_lite.validate(filter_listener_lite)\n\n    # wait for a few seconds to ensure events didn't come in on the other listeners\n    await asyncio.sleep(3)\n\n    assert key_listener.count == 0\n    assert filter_listener.count == 0\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_events.py b/tests/test_events.py
--- a/tests/test_events.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/tests/test_events.py	(date 1687412426137)
@@ -309,7 +309,7 @@
         tls_options.enabled = True
         tls_options.locked()
 
-        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)
+        options: Options = Options(default_address, default_scope, default_request_timeout, ser_format=default_format)
         options.tls_options = tls_options
         options.channel_options = (("grpc.ssl_target_name_override", "Star-Lord"),)
         session = await Session.create(options)
Index: src/coherence/event.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023 Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom abc import ABCMeta, abstractmethod\nfrom asyncio import Event, Task\nfrom enum import Enum, unique\nfrom typing import Callable, Generic, Optional, Set, TypeVar, cast\n\n# noinspection PyPackageRequirements\nimport grpc\nfrom pymitter import EventEmitter\n\nimport coherence.client\n\nfrom .filter import Filter, Filters, MapEventFilter\nfrom .messages_pb2 import MapEventResponse, MapListenerRequest, MapListenerResponse  # type: ignore\nfrom .serialization import Serializer\nfrom .services_pb2_grpc import NamedCacheServiceStub\nfrom .util import RequestFactory\n\nK = TypeVar(\"K\")\n\"\"\"the type of the map entry keys.\"\"\"\n\nV = TypeVar(\"V\")\n\"\"\"the type of the map entry values.\"\"\"\n\n\n@unique\nclass MapEventType(Enum):\n    \"\"\"Enum of possible events that could raise a MapEvent.\"\"\"\n\n    ENTRY_INSERTED = \"insert\"\n    \"\"\"This event indicates that an entry has been added to the cache.\"\"\"\n\n    ENTRY_UPDATED = \"update\"\n    \"\"\"This event indicates that an entry has been updated in the cache.\"\"\"\n\n    ENTRY_DELETED = \"delete\"\n    \"\"\"This event indicates that an entry has been removed from the cache.\"\"\"\n\n\n@unique\nclass MapLifecycleEvent(Enum):\n    \"\"\"Enum of possible events that may be raised at different\n    points of the cache lifecycle.\"\"\"\n\n    DESTROYED = \"map_destroyed\"\n    \"\"\"Raised when a storage for a given cache is destroyed\n     (usually as a result of a call to NamedMap.destroy()).\"\"\"\n\n    TRUNCATED = \"map_truncated\"\n    \"\"\"Raised when a storage for a given cache is truncated\n     as a result of a call to NamedMap.truncate().\"\"\"\n\n    RELEASED = \"map_released\"\n    \"\"\"Raised when the local resources for a cache has been\n    released as a result of a call to NamedMap.release().\n    Entries within the cache remain untouched\"\"\"\n\n\n@unique\nclass SessionLifecycleEvent(Enum):\n    \"\"\"Enum of possible events that may be raised at different\n    points of the session lifecycle.\"\"\"\n\n    CONNECTED = \"session_connected\"\n    \"\"\"Raised when the session has connected.\"\"\"\n\n    DISCONNECTED = \"session_disconnected\"\n    \"\"\"Raised when the session has disconnected.\"\"\"\n\n    RECONNECTED = \"session_reconnected\"\n    \"\"\"Raised when the session has re-connected.\"\"\"\n\n    CLOSED = \"session_closed\"\n    \"\"\"Raised when the session has been closed.\"\"\"\n\n\nclass MapEvent(Generic[K, V]):\n    \"\"\"An event which indicates that the content of a map has changed:\n\n    * an entry has been added\n    * an entry has been removed\n    * an entry has been changed\n    \"\"\"\n\n    def __init__(\n        self, source: coherence.client.NamedMap[K, V], response: MapEventResponse, serializer: Serializer\n    ) -> None:\n        \"\"\"\n        Constructs a new MapEvent.\n        :param source:      the event source\n        :param response:    the MapListenerResponse sent from the server\n        :param serializer:  the Serializer that should be used to deserialize event keys and values\n        \"\"\"\n        self._key: Optional[K] = None\n        self._new_value: Optional[V] = None\n        self._old_value: Optional[V] = None\n        self._id: MapEventType = self._from_event_id(response.id)\n        self._name: str = source.name\n        self._source: coherence.client.NamedMap[K, V] = source\n        self._serializer: Serializer = serializer\n        self._key_bytes: bytearray = response.key\n        self._new_value_bytes: bytearray = response.newValue\n        self._old_value_bytes: bytearray = response.oldValue\n\n    @property\n    def source(self) -> coherence.client.NamedMap[K, V]:\n        \"\"\"\n        The source of the event.\n        :return: the event source\n        \"\"\"\n        return self._source\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        The name of the cache from which the event originated.\n        :return:  the cache name from which the event originated\n        \"\"\"\n        return self._name\n\n    @property\n    def description(self) -> str:\n        \"\"\"\n        Returns the event's description.\n        :return: the event's description\n        \"\"\"\n        match self.type:\n            case MapEventType.ENTRY_INSERTED:\n                return \"insert\"\n            case MapEventType.ENTRY_UPDATED:\n                return \"update\"\n            case MapEventType.ENTRY_DELETED:\n                return \"delete\"\n            case _:\n                return \"unknown\"\n\n    @property\n    def type(self) -> MapEventType:\n        \"\"\"\n        The MapEventType.  This may be one of:\n        * MapEventType.ENTRY_INSERTED\n        * MapEventType.ENTRY_UPDATED\n        * MapEventType.ENTRY_DELETED\n        :return: the event type\n        \"\"\"\n        return self._id\n\n    @property\n    def key(self) -> K:\n        \"\"\"\n        Return the key for the entry generating the event.\n        :return: the key for the entry generating the event\n        \"\"\"\n        if self._key is None:\n            self._key = self._serializer.deserialize(self._key_bytes)\n\n        return self._key\n\n    @property\n    def new(self) -> Optional[V]:\n        \"\"\"\n        Return the new value for the entry generating the event.\n        :return: the new value, if any, for the entry generating the event\n        \"\"\"\n        if self._new_value is None and self._new_value_bytes is not None:\n            self._new_value = self._serializer.deserialize(self._new_value_bytes)\n\n        return self._new_value\n\n    @property\n    def old(self) -> Optional[V]:\n        \"\"\"\n        Return the old value for the entry generating the event.\n        :return:the old value, if any, for the entry generating the event\n        \"\"\"\n        if self._old_value is None and self._old_value_bytes is not None:\n            self._old_value = self._serializer.deserialize(self._old_value_bytes)\n\n        return self._old_value\n\n    def __str__(self) -> str:\n        \"\"\"\n        Returns a string representation of this event.\n        :return: a string representation of this event\n        \"\"\"\n        return (\n            \"MapEvent{\"\n            + str(self.type.name)\n            + \", cache=\"\n            + self.name\n            + \", key=\"\n            + str(self.key)\n            + \", old=\"\n            + str(self.old)\n            + \", new=\"\n            + str(self.new)\n            + \"}\"\n        )\n\n    @staticmethod\n    def _from_event_id(_id: int) -> MapEventType:\n        \"\"\"Return the MapEventType based on the on-wire value for the event.\"\"\"\n        match _id:\n            case 1:\n                return MapEventType.ENTRY_INSERTED\n            case 2:\n                return MapEventType.ENTRY_UPDATED\n            case 3:\n                return MapEventType.ENTRY_DELETED\n            case _:\n                raise Exception(\"Unhandled MapEventType [\" + str(_id) + \"]\")\n\n\nMapListenerCallback = Callable[[MapEvent[K, V]], None]\n\"\"\"A type alias for MapEventListener callback functions.\"\"\"\n\n\nclass MapListener(Generic[K, V]):\n    \"\"\"A listener interface for receiving MapEvents.\"\"\"\n\n    _emitter: EventEmitter\n    \"\"\"The internal emitter used to emit events.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Constructs a new MapListener.\"\"\"\n        self._emitter = EventEmitter()\n        pass\n\n    def _on(self, event: MapEventType, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Define a callback for the specified event type.\n\n        :param event:     the event type of interest\n        :param callback:  the callback that will be invoked when the specified event has occurred\n        \"\"\"\n        self._emitter.on(str(event.value), callback)\n        return self\n\n    def on_inserted(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when an insertion event has occurred.\n\n        :param callback:  the callback that will be invoked when an insertion event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_INSERTED, callback)\n\n    def on_updated(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when an update event has occurred.\n\n        :param callback:  the callback that will be invoked when an update event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_UPDATED, callback)\n\n    def on_deleted(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when a deletion event has occurred.\n\n        :param callback:  the callback that will be invoked when a deletion event has occurred\n        \"\"\"\n        return self._on(MapEventType.ENTRY_DELETED, callback)\n\n    def on_any(self, callback: MapListenerCallback[K, V]) -> MapListener[K, V]:\n        \"\"\"\n        Defines the callback that should be invoked when any entry event has occurred.\n\n        :param callback:  the callback that will be invoked when a deletion event has occurred\n        \"\"\"\n        return self.on_deleted(callback).on_updated(callback).on_inserted(callback)\n\n\nclass _ListenerGroup(Generic[K, V], metaclass=ABCMeta):\n    \"\"\"Manages a collection of MapEventListeners that will be notified when an event is raised.\n    This also manages the on-wire activities for registering/deregistering a listener with the\n    gRPC proxy.\"\"\"\n\n    _key_or_filter: K | Filter\n    \"\"\"The key or Filter for which this group of listeners will receive events.\"\"\"\n\n    _registered_lite: bool\n    \"\"\"The flag indicating if any listeners have been registered as lite.\"\"\"\n\n    _listeners: dict[MapListener[K, V], bool]\n    \"\"\"A map of listeners and associated lite flag.\"\"\"\n\n    _lite_false_count: int\n    \"\"\"The number of callbacks that aren't lite.\"\"\"\n\n    _manager: _MapEventsManager[K, V]\n    \"\"\"The associated MapEventsManager for this group.\"\"\"\n\n    _request: MapListenerRequest\n    \"\"\"The subscription request.  A reference is maintained for unsubscribe purposes.\"\"\"\n\n    _subscription_waiter: Event\n    \"\"\"Used by a caller to be notified when the listener subscription as been completed.\"\"\"\n\n    _unsubscription_waiter: Event\n    \"\"\"Used by a caller to be notified when the listener unsubscribe as been completed.\"\"\"\n\n    def _init_(self, manager: _MapEventsManager[K, V], key_or_filter: K | Filter) -> None:\n        \"\"\"\n        Constructs a new _ListenerGroup.\n        :param manager:        the _MapEventManager\n        :param key_or_filter:  the key or filter for this group of listeners\n        :raises ValueError:    if either `manager` or `key_or_filter` is `None`\n        \"\"\"\n        if manager is None:\n            raise ValueError(\"Argument `manager` must not be None\")\n        if key_or_filter is None:\n            raise ValueError(\"Argument `key_or_filter` must not be None\")\n\n        self._manager = manager\n        self._key_or_filter = key_or_filter\n        self._listeners = {}\n        self._lite_false_count = 0\n        self._registered_lite = False\n        self._subscribed_waiter = Event()\n        self._unsubscribed_waiter = Event()\n\n    async def add_listener(self, listener: MapListener[K, V], lite: bool) -> None:\n        \"\"\"\n        Add a callback to this group. This causes a subscription message to be sent through the stream\n        if (a) either this is the first callback, or (b) the lite param is false but all\n        the previous callback have lite == True.\n        :param listener:  the MapListener to add/subscribe\n        :param lite:      `True` if the event should only include the key, or `False`\n                           if the event should include old and new values as well as the key\n        \"\"\"\n        listeners: dict[MapListener[K, V], bool] = self._listeners\n        prev_lite_status: Optional[bool] = listeners.get(listener, None)\n        if prev_lite_status is not None and prev_lite_status == lite:\n            return\n\n        listeners[listener] = lite\n\n        if not lite:\n            self._lite_false_count += 1\n\n        size: int = len(listeners)\n        requires_registration: bool = size == 1 or self._registered_lite and not lite\n\n        if requires_registration:\n            self._registered_lite = lite\n            if size > 1:\n                await self._unsubscribe()\n\n            await self._subscribe(lite)\n\n    async def remove_listener(self, listener: MapListener[K, V]) -> None:\n        \"\"\"\n        Remove the specified listener from this group.\n        :param listener:  the listener to remove\n        \"\"\"\n        listeners: dict[MapListener[K, V], bool] = self._listeners\n        prev_lite_status: Optional[bool] = self._listeners.get(listener, None)\n        if prev_lite_status is not None and prev_lite_status or len(listeners) == 0:\n            return\n\n        del listeners[listener]\n\n        if len(listeners) == 0:\n            await self._unsubscribe()\n            return\n\n        if not prev_lite_status:\n            self._lite_false_count -= 1\n\n            if self._lite_false_count == 0:\n                await self._unsubscribe()\n                await self._subscribe(True)\n\n    # noinspection PyProtectedMember\n    async def _write(self, request: MapListenerRequest) -> None:\n        \"\"\"Write the request to the event stream.\"\"\"\n        event_stream: grpc.aio.StreamStreamCall = await self._manager._ensure_stream()\n        await event_stream.write(request)\n\n    # noinspection PyProtectedMember\n    async def _subscribe(self, lite: bool) -> None:\n        \"\"\"\n        Send a gRPC MapListener subscription request for a key or filter.\n        :param lite:  `True` if the event should only include the key, or `False`\n                      if the event should include old and new values as well as the key\n        \"\"\"\n        request: MapListenerRequest\n        if isinstance(self._key_or_filter, Filter):\n            request = self._manager._request_factory.map_listener_request(True, lite, filter=self._key_or_filter)\n        else:\n            request = self._manager._request_factory.map_listener_request(True, lite, key=self._key_or_filter)\n\n        self._request = request\n\n        # set this registration as pending\n        self._manager._pending_registrations[request.uid] = self\n\n        await self._write(request)\n\n        await self._subscribed_waiter.wait()\n        self._subscribed_waiter.clear()\n\n    # noinspection PyProtectedMember\n    def _subscribe_complete(self) -> None:\n        \"\"\"Called when the response to the subscription request has been received.\"\"\"\n\n        # no longer pending\n        del self._manager._pending_registrations[self._request.uid]\n        self._post_subscribe(self._request)\n\n        # notify caller that subscription is active\n        self._subscribed_waiter.set()\n\n    # noinspection PyProtectedMember\n    async def _unsubscribe(self) -> None:\n        \"\"\"\n        Send a gRPC MapListener request to unsubscribe a listener for a key or filter.\n        \"\"\"\n\n        request: MapListenerRequest\n        if isinstance(self._key_or_filter, MapEventFilter):\n            request = self._manager._request_factory.map_listener_request(False, filter=self._key_or_filter)\n        else:\n            request = self._manager._request_factory.map_listener_request(False, key=self._key_or_filter)\n\n        request.filterId = self._request.filterId\n        await self._write(request)\n        self._post_unsubscribe(request)\n\n    # noinspection PyProtectedMember\n    def _notify_listeners(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Notify all listeners within this group of the provided event.\n        :param event:\n        \"\"\"\n        event_label: str = self._get_emitter_label(event)\n        listener: MapListener[K, V]\n        for listener in self._listeners.keys():\n            listener._emitter.emit(event_label, event)\n\n    # noinspection PyProtectedMember\n    @staticmethod\n    def _get_emitter_label(event: MapEvent[K, V]) -> str:\n        \"\"\"\n        The string label required by the internal event emitter.\n        :param event:  the MapEvent whose label will be generated\n        :return: the emitter-friendly event label\n        \"\"\"\n        match event.type:\n            case MapEventType.ENTRY_DELETED:\n                return MapEventType.ENTRY_DELETED.value\n            case MapEventType.ENTRY_INSERTED:\n                return MapEventType.ENTRY_INSERTED.value\n            case MapEventType.ENTRY_UPDATED:\n                return MapEventType.ENTRY_UPDATED.value\n            case _:\n                raise AssertionError(f\"Unknown EventType [{event}]\")\n\n    @abstractmethod\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        \"\"\"\n        Custom actions that implementations may need to make after a subscription has been completed.\n        :param request:  the request that was used to subscribe\n        \"\"\"\n        return\n\n    @abstractmethod\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        \"\"\"\n        Custom actions that implementations may need to make after an unsubscription has been completed.\n        :param request:  the request that was used to unsubscribe\n        \"\"\"\n        return\n\n\nclass _KeyListenerGroup(_ListenerGroup[K, V]):\n    \"\"\"A ListenerGroup for key-based MapListeners\"\"\"\n\n    def __init__(self, manager: _MapEventsManager[K, V], key: K) -> None:\n        \"\"\"\n        Creates a new _KeyListenerGroup\n        :param manager:  the _MapEventManager\n        :param key:      the group key\n        \"\"\"\n        super()._init_(manager, key)\n        pass\n\n    # noinspection PyProtectedMember\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        manager: _MapEventsManager[K, V] = self._manager\n        key: K = manager._serializer.deserialize(request.key)\n        self._manager._key_group_subscribed(key, self)\n\n    # noinspection PyProtectedMember\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        manager: _MapEventsManager[K, V] = self._manager\n        key: K = manager._serializer.deserialize(request.key)\n        manager._key_group_unsubscribed(key)\n\n\nclass _FilterListenerGroup(_ListenerGroup[K, V]):\n    \"\"\"A ListenerGroup for Filter-based MapListeners\"\"\"\n\n    def __init__(self, manager: _MapEventsManager[K, V], filter: Filter) -> None:\n        \"\"\"\n        Creates a new _KeyListenerGroup\n        :param manager:  the _MapEventManager\n        :param filter:   the group Filter\n        \"\"\"\n        super()._init_(manager, filter)\n        pass\n\n    # noinspection PyProtectedMember\n    def _post_subscribe(self, request: MapListenerRequest) -> None:\n        self._manager._filter_group_subscribed(request.filterId, cast(Filter, self._key_or_filter), self)\n\n    # noinspection PyProtectedMember\n    def _post_unsubscribe(self, request: MapListenerRequest) -> None:\n        self._manager._filter_group_unsubscribed(request.filterId, cast(Filter, self._key_or_filter))\n\n\nclass _MapEventsManager(Generic[K, V]):\n    \"\"\"MapEventsManager handles registration, de-registration of callbacks, and\n    notification of {@link MapEvent}s to callbacks. Since multiple callbacks can\n    be registered for a single key / filter, this class relies on another internal\n    class called ListenerGroup which maintains the collection of callbacks.\n\n    There are two maps that are maintained:\n\n    1. A Map of string keys mapped to a ListenerGroup, which is used to identify\n       thd group of callbacks for a single key.\n    2. A Map of filter => ListenerGroup that is used to identify the group of callbacks\n       for a MapEventFilter.\n\n    When a filter is subscribed, the server responds with a unique filterID.This filterID\n    is what is specified is a MapEvent. So, this class maintains a third Map of\n    filterID to ListenerGroup for efficiently identifying the ListenerGroup for a filterID.\n    \"\"\"\n\n    _DEFAULT_FILTER: MapEventFilter[K, V] = MapEventFilter.from_filter(Filters.always())\n    \"\"\"The default filter to use if none is specified.\"\"\"\n\n    _named_map: coherence.client.NamedMap[K, V]\n    \"\"\"the NamedMap that is to be the source of the events.\"\"\"\n\n    _client: NamedCacheServiceStub\n    \"\"\"the gRPC cache client.\"\"\"\n\n    _serializer: Serializer\n    \"\"\"the Serializer to applied to in and outbound payloads.\"\"\"\n\n    _emitter: EventEmitter\n    \"\"\"the EventEmitter that will be used to emit MapEvents.\"\"\"\n\n    _map_name: str\n    \"\"\"The logical name of the provided NamedMap.\"\"\"\n\n    _key_map: dict[K, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a key and its group of MapListeners.\"\"\"\n\n    _filter_map: dict[Filter, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a Filter and its group of MapListeners.\"\"\"\n\n    _filter_id_listener_group_map: dict[int, _ListenerGroup[K, V]]\n    \"\"\"Contains mappings between a logical filter ID and its ListenerGroup.\"\"\"\n\n    _request_factory: RequestFactory\n    \"\"\"The RequestFactory used to obtain the necessary gRPC requests.\"\"\"\n\n    _event_stream: Optional[grpc.aio.StreamStreamCall]\n    \"\"\"gRPC bidirectional stream for subscribing/unsubscribing MapListeners and receiving MapEvents from\n       the proxy.\"\"\"\n\n    _open: bool\n    \"\"\"\"Flag indicating the event stream is open and ready for listener registrations and\n    incoming events.\"\"\"\n\n    _pending_registrations: dict[str, _ListenerGroup[K, V]]\n    \"\"\"The mapping of pending listener registrations keyed by request uid.\"\"\"\n\n    _background_tasks: Set[Task[None]]\n\n    # noinspection PyProtectedMember\n    def __init__(\n        self,\n        named_map: coherence.client.NamedMap[K, V],\n        session: coherence.Session,\n        client: NamedCacheServiceStub,\n        serializer: Serializer,\n        emitter: EventEmitter,\n    ) -> None:\n        \"\"\"\n        Constructs a new _MapEventManager.\n        :param named_map:   the 'source' of the events\n        :param session:     the Session associated with this NamedMap\n        :param client:      the gRPC client\n        :param serializer:  the Serializer that will be used for ser/deser operations\n        :param emitter:     the internal event emitter used to notify registered MapListeners\n        \"\"\"\n        self._named_map = named_map\n        self._client = client\n        self._serializer = serializer\n        self._emitter = emitter\n        self._map_name = named_map.name\n        self._session = session\n\n        self._key_map = {}\n        self._filter_map = {}\n        self._filter_id_listener_group_map = {}\n        self._pending_registrations = {}\n\n        self._request_factory = RequestFactory(self._map_name, session.scope, serializer)\n\n        self._event_stream = None\n        self._open = False\n        self._background_tasks = set()\n        self._stream_waiter = Event()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, self._close)\n\n        # intentionally ignoring the typing here to avoid complicating the\n        # callback API exposed on the session\n        # noinspection PyTypeChecker\n        session.on(SessionLifecycleEvent.RECONNECTED, self._reconnect)\n\n    def _close(self) -> None:\n        \"\"\"Close the gRPC event stream and any background tasks.\"\"\"\n\n        event_stream: grpc.aio.StreamStreamCall = self._event_stream\n        if event_stream is not None:\n            event_stream.cancel()\n            self._event_stream = None\n\n        self._open = False\n        for task in self._background_tasks:\n            task.cancel()\n        self._background_tasks.clear()\n\n    # noinspection PyProtectedMember\n    async def _reconnect(self) -> None:\n        group: _ListenerGroup[K, V]\n        for group in self._key_map.values():\n            await group._subscribe(group._registered_lite)\n\n        for group in self._filter_map.values():\n            await group._subscribe(group._registered_lite)\n\n    async def _ensure_stream(self) -> grpc.aio.StreamStreamCall:\n        \"\"\"\n        Initialize the event stream for MapListener events.\n        \"\"\"\n        if self._event_stream is None:\n            event_stream: grpc.aio.StreamStreamCall = self._client.events()\n            await event_stream.write(self._request_factory.map_event_subscribe())\n            self._event_stream = event_stream\n            read_task: Task[None] = asyncio.create_task(self._handle_response())\n            self._background_tasks.add(read_task)\n            try:\n                async with asyncio.timeout(self._session.options.request_timeout_seconds):\n                    await self._stream_waiter.wait()\n            except TimeoutError:\n                raise TimeoutError(\n                    \"Unable to establish session with [{0}] within [{1}] seconds)\".format(\n                        self._session.options.address, str(self._session.options.request_timeout_seconds)\n                    )\n                )\n\n        return self._event_stream\n\n    async def _register_key_listener(self, listener: MapListener[K, V], key: K, lite: bool = False) -> None:\n        \"\"\"\n        Registers the specified listener to listen for events matching the provided key.\n        :param listener:  the MapListener to register\n        :param key:       the key to listener to\n        :param lite:      `True` if the event should only include the key, or `False`\n                          if the event should include old and new values as well as the key\n        \"\"\"\n        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)\n\n        if group is None:\n            group = _KeyListenerGroup(self, key)\n            self._key_map[key] = group\n\n        await group.add_listener(listener, lite)\n\n    async def _remove_key_listener(self, listener: MapListener[K, V], key: K) -> None:\n        \"\"\"\n        Removes the registration of the listener for the provided key.\n        :param listener:  the MapListener to remove\n        :param key:       they key the listener was associated with\n        \"\"\"\n        group: Optional[_ListenerGroup[K, V]] = self._key_map.get(key, None)\n\n        if group is not None:\n            await group.remove_listener(listener)\n\n    async def _register_filter_listener(\n        self, listener: MapListener[K, V], filter: Optional[Filter], lite: bool = False\n    ) -> None:\n        \"\"\"\n        Registers the specified listener to listen for events matching the provided filter.\n        :param listener:  the MapListener to register\n        :param filter:    the Filter associated with the listener\n        :param lite:      `True` if the event should only include the key, or `False`\n                           if the event should include old and new values as well as the key\n        \"\"\"\n        filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER\n        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)\n\n        if group is None:\n            group = _FilterListenerGroup(self, filter_local)\n            self._filter_map[filter_local] = group\n        await group.add_listener(listener, lite)\n\n    async def _remove_filter_listener(self, listener: MapListener[K, V], filter: Optional[Filter]) -> None:\n        \"\"\"\n        Removes the registration of the listener for the provided filter.\n        :param listener:  the MapListener to remove\n        :param filter:    the Filter that was used with the listener registration\n        \"\"\"\n        filter_local: Filter = filter if filter is not None else self._DEFAULT_FILTER\n        group: Optional[_ListenerGroup[K, V]] = self._filter_map.get(filter_local, None)\n\n        if group is not None:\n            await group.remove_listener(listener)\n\n    def _key_group_subscribed(self, key: K, group: _ListenerGroup[K, V]) -> None:\n        \"\"\"\n        Called internally by _KeyListenerGroup when a key listener is subscribed.\n        :param key:    the registration key\n        :param group:  the registered group\n        \"\"\"\n        self._key_map[key] = group\n\n    def _key_group_unsubscribed(self, key: K) -> None:\n        \"\"\"\n        Called internally by _KeyListenerGroup when a listener is unsubscribed.\n        :param key:  the key used at registration\n        \"\"\"\n        del self._key_map[key]\n\n    def _filter_group_subscribed(self, filter_id: int, filter: Filter, group: _ListenerGroup[K, V]) -> None:\n        \"\"\"\n        Called internally by _FilterListenerGroup when a filter listener is subscribed.\n        :param filter_id:  the ID of the filter\n        :param filter:     the Filter associated with the listener registration\n        :param group:      the registered group\n        \"\"\"\n        self._filter_id_listener_group_map[filter_id] = group\n        self._filter_map[filter] = group\n\n    def _filter_group_unsubscribed(self, filter_id: int, filter: Filter) -> None:\n        \"\"\"\n        Called internally by _FilterListenerGroup when a filter listener is unsubscribed.\n        :param filter_id:  the ID of the filter\n        :param filter:     the Filter used at registration\n        \"\"\"\n        del self._filter_id_listener_group_map[filter_id]\n        del self._filter_map[filter]\n\n    # noinspection PyProtectedMember\n    async def _handle_response(self) -> None:\n        \"\"\"\n        Handles reading data from the event stream and invoking the appropriate logic\n        for various MapListenerResponse messages that may be sent by the backend.\n        \"\"\"\n        if not self._open:  # will be triggered on first response\n            event_stream: grpc.aio.StreamStreamCall = await self._ensure_stream()\n            await event_stream.read()\n            self._open = True\n            self._stream_waiter.set()  # notify any callers waiting for stream init\n            self._stream_waiter.clear()\n            try:\n                while self._open:\n                    await asyncio.sleep(0.1)\n                    response: MapListenerResponse = await event_stream.read()\n                    if response.HasField(\"subscribed\"):\n                        subscribed = response.subscribed\n                        group: Optional[_ListenerGroup[K, V]] = self._pending_registrations.get(subscribed.uid, None)\n                        if group is not None:\n                            group._subscribe_complete()\n                    elif response.HasField(\"destroyed\"):\n                        destroyed_cache: str = response.destroyed.cache\n                        if destroyed_cache == self._map_name:\n                            self._emitter.emit(MapLifecycleEvent.DESTROYED.value, self._map_name)\n                    elif response.HasField(\"truncated\"):\n                        truncated_cache: str = response.truncated.cache\n                        if truncated_cache == self._map_name:\n                            self._emitter.emit(MapLifecycleEvent.TRUNCATED.value, self._map_name)\n                    elif response.HasField(\"event\"):\n                        response_event = response.event\n                        event: MapEvent[K, V] = MapEvent(self._named_map, response_event, self._serializer)\n                        for _id in response_event.filterIds:\n                            filter_group: Optional[_ListenerGroup[K, V]] = self._filter_id_listener_group_map.get(\n                                _id, None\n                            )\n                            if filter_group is not None:\n                                filter_group._notify_listeners(event)\n\n                        key_group = self._key_map.get(event.key, None)\n                        if key_group is not None:\n                            key_group._notify_listeners(event)\n            except asyncio.CancelledError:\n                return\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/event.py b/src/coherence/event.py
--- a/src/coherence/event.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/src/coherence/event.py	(date 1687468404234)
@@ -660,13 +660,15 @@
             self._event_stream = event_stream
             read_task: Task[None] = asyncio.create_task(self._handle_response())
             self._background_tasks.add(read_task)
+            # we use asyncio.timeout here instead of using the gRPC timeout
+            # as any deadline set on the stream will result in a loss of events
             try:
                 async with asyncio.timeout(self._session.options.request_timeout_seconds):
                     await self._stream_waiter.wait()
             except TimeoutError:
                 raise TimeoutError(
-                    "Unable to establish session with [{0}] within [{1}] seconds)".format(
-                        self._session.options.address, str(self._session.options.request_timeout_seconds)
+                    "Deadline [{0} seconds] exceeded waiting for event stream to become ready)".format(
+                        str(self._session.options.request_timeout_seconds)
                     )
                 )
 
Index: tests/test_filters.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport os\nfrom typing import Any, AsyncGenerator, Final\n\nimport pytest\nimport pytest_asyncio\n\nfrom coherence import NamedCache, Options, Session, TlsOptions\nfrom coherence.filter import Filters\nfrom coherence.processor import ConditionalRemove, EntryProcessor\n\n\nasync def get_session() -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = await Session.create(options)\n    else:\n        session = await Session.create()\n\n    return session\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown() -> AsyncGenerator[NamedCache[Any, Any], None]:\n    session: Session = await get_session()\n    cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n\n    yield cache\n\n    await cache.clear()\n    await cache.destroy()\n    await session.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_and(setup_and_teardown: NamedCache[str, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 123).And(Filters.equals(\"my_str\", \"123\"))\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 1234).And(Filters.equals(\"my_str\", \"123\"))\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_or(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 123).Or(Filters.equals(\"my_str\", \"123\"))\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 1234).Or(Filters.equals(\"my_str\", \"1234\"))\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_xor(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 123).Xor(Filters.equals(\"my_str\", \"123\"))\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should fail since filter should return false\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 1234).Xor(Filters.equals(\"my_str\", \"1234\"))\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n    await cache.put(k, v)\n    f = Filters.equals(\"id\", 1234).Xor(Filters.equals(\"my_str\", \"123\"))\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_all(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f1 = Filters.equals(\"id\", 123)\n    f2 = Filters.equals(\"my_str\", \"123\")\n    f3 = Filters.equals(\"ival\", 123)\n    all_f = Filters.all([f1, f2, f3])\n    cp: EntryProcessor[Any] = ConditionalRemove(all_f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f1 = Filters.equals(\"id\", 123)\n    f2 = Filters.equals(\"my_str\", \"1234\")\n    f3 = Filters.equals(\"ival\", 123)\n    all_f = Filters.all([f1, f2, f3])\n    cp = ConditionalRemove(all_f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_any(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f1 = Filters.equals(\"id\", 1234)  # False\n    f2 = Filters.equals(\"my_str\", \"1234\")  # False\n    f3 = Filters.equals(\"ival\", 123)  # True\n    all_f = Filters.any([f1, f2, f3])\n    cp: EntryProcessor[Any] = ConditionalRemove(all_f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f1 = Filters.equals(\"id\", 1234)  # False\n    f2 = Filters.equals(\"my_str\", \"1234\")  # False\n    f3 = Filters.equals(\"ival\", 1234)  # False\n    all_f = Filters.any([f1, f2, f3])\n    cp = ConditionalRemove(all_f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_greater(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.greater(\"id\", 122)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.greater(\"id\", 123)\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_greater_equals(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.greater_equals(\"id\", 122)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.greater_equals(\"id\", 123)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_less(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.less(\"id\", 124)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.less(\"id\", 123)\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_less_equals(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.less_equals(\"id\", 124)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.less_equals(\"id\", 123)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_between(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.between(\"id\", 122, 124)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.between(\"id\", 123, 124, True)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.between(\"id\", 122, 123, False, True)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_not_equals(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.not_equals(\"id\", 123)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n    await cache.put(k, v)\n    f = Filters.not_equals(\"id\", 124)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_not(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.negate(Filters.equals(\"id\", 1234))\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.negate(Filters.equals(\"id\", 123))\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_is_none(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.is_none(\"id\")\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n    await cache.put(k, v)\n    f = Filters.is_none(\"id2\")\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_is_not_none(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.is_not_none(\"id\")\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.is_not_none(\"id2\")\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_any(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.contains_any(\"iarr\", {1, 5, 6})\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.contains_any(\"iarr\", {4, 5, 6})\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_all(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.contains_all(\"iarr\", {1, 2})\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.contains_all(\"iarr\", {1, 2, 4})\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.array_contains(\"iarr\", 2)\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.array_contains(\"iarr\", 5)\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_in(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.is_in(\"my_str\", {\"123\", 4, 12.3})\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.is_in(\"ival\", {\"123\", 4, 12.3})\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_like(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123-my-test-string\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.like(\"my_str\", \"123-my-test%\")\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.like(\"my_str\", \"123-my-test%\", \"0\", True)\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.like(\"my_str\", \"123-my-test-s_r_ng\")\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_present(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123-my-test-string\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.present()\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.present()\n    cp = ConditionalRemove(f)  # Should fail since filter should return False\n    await cache.invoke(\"k2\", cp)  # No such key so ConditionalRemove with filter should fail\n    assert await cache.size() == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_regex(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache = setup_and_teardown\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"test\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    f = Filters.regex(\"my_str\", \"..st\")\n    cp: EntryProcessor[Any] = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.regex(\"my_str\", \"[ets]+\")\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.regex(\"my_str\", \"[aets]*\")\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 0\n\n    await cache.put(k, v)\n    f = Filters.regex(\"my_str\", \"[^abc]\")\n    cp = ConditionalRemove(f)  # Should pass since filter should return True\n    await cache.invoke(k, cp)\n    assert await cache.size() == 1\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_filters.py b/tests/test_filters.py
--- a/tests/test_filters.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/tests/test_filters.py	(date 1687412407160)
@@ -32,7 +32,7 @@
         tls_options.enabled = True
         tls_options.locked()
 
-        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)
+        options: Options = Options(default_address, default_scope, default_request_timeout, ser_format=default_format)
         options.tls_options = tls_options
         options.channel_options = (("grpc.ssl_target_name_override", "Star-Lord"),)
         session = await Session.create(options)
Index: tests/test_processors.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport os\nfrom typing import Any, AsyncGenerator, Final\n\nimport pytest\nimport pytest_asyncio\n\nfrom coherence import MapEntry, NamedCache, Options, Session, TlsOptions\nfrom coherence.filter import Filter, Filters\nfrom coherence.processor import EntryProcessor, Numeric, PreloadRequest, Processors, ScriptProcessor, TouchProcessor\nfrom coherence.serialization import JSONSerializer\nfrom tests.address import Address\nfrom tests.person import Person\n\n\nasync def get_session() -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = await Session.create(options)\n    else:\n        session = await Session.create()\n\n    return session\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown() -> AsyncGenerator[NamedCache[Any, Any], None]:\n    session: Session = await get_session()\n    cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n\n    yield cache\n\n    await cache.clear()\n    await cache.destroy()\n    await session.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_extractor(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k1 = \"one\"\n    v1 = \"only-one\"\n    await cache.put(k1, v1)\n    k2 = \"two\"\n    v2 = \"only-two\"\n    await cache.put(k2, v2)\n\n    r: Any = await cache.invoke(k2, Processors.extract(\"length()\"))\n    assert r == len(v2)\n\n    r = await cache.invoke(k2, Processors.extract(\"isEmpty()\"))\n    assert r is False\n\n    r = await cache.invoke(k2, Processors.extract(\"toUpperCase()\"))\n    assert r == v2.upper()\n\n    k3 = Person.Andy().name\n    v3 = Person.Andy()\n    await cache.put(k3, v3)\n    r = await cache.invoke(k3, Processors.extract(\"name\"))\n    assert r == k3\n    r = await cache.invoke(k3, Processors.extract(\"address\"))\n    assert type(r) == Address\n    assert r.zipcode == v3.address.zipcode\n    r = await cache.invoke(k3, Processors.extract(\"address.zipcode\"))\n    assert r == v3.address.zipcode\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_composite(setup_and_teardown: NamedCache[str, Any]) -> None:\n    cache: NamedCache[str, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    cp: EntryProcessor[str] = Processors.extract(\"id\").and_then(Processors.extract(\"my_str\"))\n    r: Any = await cache.invoke(k, cp)\n    assert r == [123, \"123\"]\n\n    k3 = Person.Pat().name\n    v3 = Person.Pat()\n    await cache.put(k3, v3)\n    cp = Processors.extract(\"weight\").and_then(Processors.extract(\"address.zipcode\"))\n    r = await cache.invoke(k3, cp)\n    assert r == [Person.Pat().weight, Person.Pat().address.zipcode]\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_conditional(setup_and_teardown: NamedCache[str, Any]) -> None:\n    cache: NamedCache[str, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    ext: EntryProcessor[str] = Processors.extract(\"my_str\")\n    cp: EntryProcessor[str] = ext.when(Filters.equals(\"id\", 123))\n    r: Any = await cache.invoke(k, cp)\n    assert r == \"123\"\n\n    await cache.put(k, v)\n    cp = ext.when(Filters.equals(\"id\", 1234))\n    r = await cache.invoke(k, cp)\n    assert r is None\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_null(setup_and_teardown: NamedCache[str, Any]) -> None:\n    cache: NamedCache[str, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    cp: EntryProcessor[bool] = Processors.nop()\n    r: Any = await cache.invoke(k, cp)\n    assert r is True\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_multiplier(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    cp: EntryProcessor[Numeric] = Processors.multiply(\"ival\", 2)\n    r: Numeric = await cache.invoke(k, cp)\n    assert r == 246\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_incrementor(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    cp = Processors.increment(\"ival\", 2)\n    r: Any = await cache.invoke(k, cp)\n    assert r == 125\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_conditional_put(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k1 = \"one\"\n    v1 = \"only-one\"\n    await cache.put(k1, v1)\n\n    f: Filter = Filters.never()  # This will always return False\n    cp = Processors.conditional_put(f, \"only-one-one\", True)\n    r: Any = await cache.invoke(k1, cp)\n    assert r == v1\n    cp = Processors.conditional_put(f, \"only-one-one\", False)\n    r = await cache.invoke(k1, cp)\n    assert r is None\n\n    f = Filters.always()  # This will always return True\n    cp = Processors.conditional_put(f, \"only-one-one\")\n    await cache.invoke(k1, cp)\n    assert await cache.get(k1) == \"only-one-one\"\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_conditional_put_all(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k1 = \"one\"\n    v1 = \"only-one\"\n    await cache.put(k1, v1)\n\n    k2 = \"two\"\n    v2 = \"only-two\"\n    await cache.put(k2, v2)\n\n    f = Filters.always()  # This will always return True\n    cp = Processors.conditional_put_all(f, dict([(k1, \"only-one-one\"), (k2, \"only-two-two\")]))\n    async for _ in cache.invoke_all(cp):\n        break  # ignore the results\n\n    assert await cache.get(k1) == \"only-one-one\"\n    assert await cache.get(k2) == \"only-two-two\"\n\n    pf = Filters.present()\n    cp = Processors.conditional_put_all(Filters.negate(pf), dict([(\"three\", \"only-three\")]))\n    async for _ in cache.invoke_all(cp, {\"one\", \"three\"}):\n        break  # ignore the results\n\n    assert await cache.get(k1) == \"only-one-one\"\n    assert await cache.get(k2) == \"only-two-two\"\n    assert await cache.get(\"three\") == \"only-three\"\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_conditional_remove(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1 = \"one\"\n    v1 = \"only-one\"\n    await cache.put(k1, v1)\n\n    f: Filter = Filters.never()  # This will always return False\n    cp: EntryProcessor[str] = Processors.conditional_remove(f, True)\n    r: str = await cache.invoke(k1, cp)\n    assert r == v1\n    assert await cache.get(k1) == \"only-one\"\n    cp = Processors.conditional_remove(f)\n    r = await cache.invoke(k1, cp)\n    assert r is None\n    assert await cache.get(k1) == \"only-one\"\n\n    f = Filters.always()  # This will always return True\n    cp = Processors.conditional_remove(f, True)\n    r = await cache.invoke(k1, cp)\n    assert r is None\n    assert await cache.get(k1) is None\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_method_invocation(setup_and_teardown: NamedCache[str, Any]) -> None:\n    cache: NamedCache[str, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    p: EntryProcessor[str] = Processors.invoke_accessor(\"get\", \"ival\")  # Non-mutating form\n    r: str = await cache.invoke(k, p)\n    assert r == 123\n\n    p = Processors.invoke_accessor(\"size\")  # Non-mutating form\n    r = await cache.invoke(k, p)\n    assert r == 6\n\n    p = Processors.invoke_accessor(\"isEmpty\")  # Non-mutating form\n    r = await cache.invoke(k, p)\n    assert r is False\n\n    p = Processors.invoke_mutator(\"remove\", \"ival\")  # Mutating form\n    r = await cache.invoke(k, p)\n    assert r == 123\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_touch() -> None:\n    tp = Processors.touch()\n    serializer = JSONSerializer()\n    j = serializer.serialize(tp)\n    json_object: EntryProcessor[None] = serializer.deserialize(j)\n    assert json_object is not None\n    assert isinstance(json_object, TouchProcessor)\n\n\n# noinspection PyShadowingNames,PyUnresolvedReferences\n@pytest.mark.asyncio\nasync def test_script() -> None:\n    sp = Processors.script(\"test_script.py\", \"py\", \"abc\", 2, 4.0)\n    serializer = JSONSerializer()\n    j = serializer.serialize(sp)\n    json_object: EntryProcessor[Any] = serializer.deserialize(j)\n    assert json_object is not None\n    assert isinstance(json_object, ScriptProcessor)\n    assert json_object.name == \"test_script.py\"\n    assert json_object.language == \"py\"\n    assert json_object.args == [\"abc\", 2, 4.0]\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_preload() -> None:\n    tp = Processors.preload()\n    serializer = JSONSerializer()\n    j = serializer.serialize(tp)\n    json_object: EntryProcessor[None] = serializer.deserialize(j)\n    assert json_object is not None\n    assert isinstance(json_object, PreloadRequest)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_updater(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k = \"k1\"\n    v = {\"id\": 123, \"my_str\": \"123\", \"ival\": 123, \"fval\": 12.3, \"iarr\": [1, 2, 3], \"group:\": 1}\n    await cache.put(k, v)\n    ep = Processors.update(\"my_str\", \"12300\").and_then(Processors.update(\"ival\", 12300))\n    r: Any = await cache.invoke(k, ep)\n    assert r == [True, True]\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_versioned_put(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n\n    k = \"123\"\n    versioned123 = {\n        \"@version\": 1,\n        \"id\": 123,\n        \"my_str\": \"123\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n    versioned123_update = {\n        \"@version\": 1,\n        \"id\": 123,\n        \"my_str\": \"123-update\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n\n    expected_result = {\n        \"@version\": 2,\n        \"id\": 123,\n        \"my_str\": \"123-update\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n\n    await cache.put(k, versioned123)\n    vp = Processors.versioned_put(versioned123_update)\n    r: Any = await cache.invoke(k, vp)\n    assert r is None\n    result = await cache.get(k)\n    assert result == expected_result\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_versioned_put_all(setup_and_teardown: NamedCache[Any, Any]) -> None:\n    cache: NamedCache[Any, Any] = setup_and_teardown\n    k1 = \"123\"\n    versioned123 = {\n        \"@version\": 1,\n        \"id\": 123,\n        \"my_str\": \"123\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n\n    versioned123_update = {\n        \"@version\": 1,\n        \"id\": 123,\n        \"my_str\": \"123-update\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n\n    expected_versioned123_update = {\n        \"@version\": 2,\n        \"id\": 123,\n        \"my_str\": \"123-update\",\n        \"ival\": 123,\n        \"fval\": 12.3,\n        \"iarr\": [1, 2, 3],\n        \"group:\": 1,\n    }\n\n    k2 = \"234\"\n    versioned234 = {\n        \"@version\": 2,\n        \"id\": 234,\n        \"my_str\": \"234\",\n        \"ival\": 234,\n        \"fval\": 23.4,\n        \"iarr\": [2, 3, 4],\n        \"group:\": 2,\n    }\n\n    versioned234_update = {\n        \"@version\": 2,\n        \"id\": 234,\n        \"my_str\": \"234_update\",\n        \"ival\": 234,\n        \"fval\": 23.4,\n        \"iarr\": [2, 3, 4],\n        \"group:\": 2,\n    }\n\n    expected_versioned234_update = {\n        \"@version\": 3,\n        \"id\": 234,\n        \"my_str\": \"234_update\",\n        \"ival\": 234,\n        \"fval\": 23.4,\n        \"iarr\": [2, 3, 4],\n        \"group:\": 2,\n    }\n\n    await cache.put(k1, versioned123)\n    await cache.put(k2, versioned234)\n\n    vpa = Processors.versioned_put_all(dict([(k1, versioned123_update), (k2, versioned234_update)]))\n    e: MapEntry[Any, Any]\n    async for e in cache.invoke_all(vpa):\n        break\n\n    assert await cache.get(k1) == expected_versioned123_update\n    assert await cache.get(k2) == expected_versioned234_update\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_processors.py b/tests/test_processors.py
--- a/tests/test_processors.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/tests/test_processors.py	(date 1687412392430)
@@ -35,7 +35,7 @@
         tls_options.enabled = True
         tls_options.locked()
 
-        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)
+        options: Options = Options(default_address, default_scope, default_request_timeout, ser_format=default_format)
         options.tls_options = tls_options
         options.channel_options = (("grpc.ssl_target_name_override", "Star-Lord"),)
         session = await Session.create(options)
Index: tests/test_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nimport asyncio\nimport logging\nimport logging.config\nimport os\nimport urllib\nimport urllib.request\nfrom asyncio import Event\nfrom time import time\nfrom typing import Any, AsyncGenerator, Final, Optional, TypeVar\n\nimport pytest\nimport pytest_asyncio\n\nfrom coherence import Filters, MapEntry, NamedCache, Options, Session, TlsOptions\nfrom coherence.event import MapLifecycleEvent, SessionLifecycleEvent\nfrom coherence.extractor import ChainedExtractor, UniversalExtractor\nfrom coherence.processor import ExtractorProcessor\nfrom tests import CountingMapListener\nfrom tests.address import Address\nfrom tests.person import Person\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\nR = TypeVar(\"R\")\n\nCOH_LOG = logging.getLogger(\"coherence-test\")\n\n\nasync def _insert_large_number_of_entries(cache: NamedCache[str, str]) -> int:\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_bulk_ops: int = 10\n    num_entries: int = 40000\n    bulk_ops: int = int(num_entries / num_bulk_ops)\n    to_send: dict[str, str] = {}\n    for i in range(num_bulk_ops):\n        offset: int = i * bulk_ops\n        for n in range(bulk_ops):\n            to_insert: str = str(offset + n)\n            to_send[to_insert] = to_insert\n\n        await cache.put_all(to_send)\n\n    return num_entries\n\n\nasync def get_session() -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = await Session.create(options)\n    else:\n        session = await Session.create()\n\n    return session\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown() -> AsyncGenerator[NamedCache[Any, Any], None]:\n    session: Session = await get_session()\n\n    cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n\n    yield cache  # this is what is returned to the test functions\n\n    await cache.truncate()\n    await cache.destroy()\n    await session.close()\n\n\n@pytest_asyncio.fixture\nasync def setup_and_teardown_person_cache() -> AsyncGenerator[NamedCache[str, Person], None]:\n    session: Session = await get_session()\n\n    cache: NamedCache[str, Person] = await session.get_cache(\"test\")\n\n    await cache.put(Person.Pat().name, Person.Pat())\n    await cache.put(Person.Paula().name, Person.Paula())\n    await cache.put(Person.Andy().name, Person.Andy())\n    await cache.put(Person.Alice().name, Person.Alice())\n    await cache.put(Person.Jim().name, Person.Jim())\n    await cache.put(Person.Fred().name, Person.Fred())\n    await cache.put(Person.Fiona().name, Person.Fiona())\n    print(\"\\n\")\n    print(Person.Pat())\n    print(Person.Paula())\n    print(Person.Andy())\n    print(Person.Alice())\n    print(Person.Jim())\n    print(Person.Fred())\n    print(Person.Fiona())\n    yield cache\n\n    await cache.truncate()\n    await cache.destroy()\n    await session.close()\n\n\n@pytest.mark.asyncio\nasync def test_session_basics() -> None:\n    \"\"\"Test initial session state; CLOSED lifecycle event; and post-close invocations raise error\"\"\"\n\n    session: Session = await get_session()\n\n    assert session.channel is not None\n    assert session.scope == \"\"\n    assert session.options is not None\n    assert session.format == \"json\"\n    assert not session.closed\n\n    event: Event = Event()\n    session.on(SessionLifecycleEvent.CLOSED, lambda: event.set())\n    await session.close()\n    await asyncio.wait_for(_waiter(event), 0.5)\n\n    # ensure close is idempotent\n    event.clear()\n    await session.close()\n\n    with pytest.raises(asyncio.TimeoutError):\n        await asyncio.wait_for(_waiter(event), 0.5)\n\n    assert session.channel is not None\n    assert session.scope == \"\"\n    assert session.options is not None\n    assert session.format == \"json\"\n    assert session.closed\n\n    with pytest.raises(Exception):\n        await session.get_cache(\"test\")\n\n    with pytest.raises(Exception):\n        session.on(SessionLifecycleEvent.CLOSED, lambda: None)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_and_put(setup_and_teardown: NamedCache[str, str | int | Person]) -> None:\n    cache: NamedCache[str, str | int | Person] = setup_and_teardown\n\n    k: str = \"one\"\n    v: str = \"only-one\"\n    # c.put(k, v, 60000)\n    await cache.put(k, v)\n    r = await cache.get(k)\n    assert r == v\n\n    k1: str = \"two\"\n    v1: int = 2\n    await cache.put(k1, v1)\n    r = await cache.get(k1)\n    assert r == v1\n\n    k2: str = Person.Andy().name\n    v2: Person = Person.Andy()\n    await cache.put(k2, v2)\n    r = await cache.get(k2)\n    assert type(r) == Person\n    assert r.name == k2\n    assert r.address.city == Person.Andy().address.city\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_put_if_absent(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    r = await cache.put_if_absent(k1, v1)\n    assert r is None\n\n    r = await cache.put_if_absent(k, v)\n    assert r == v\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_keys_filtered(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_set: set[str] = set()\n    async for e in cache.keys(Filters.equals(\"length()\", 8)):\n        local_set.add(e)\n\n    assert len(local_set) == 2\n    assert \"one\" in local_set\n    assert \"two\" in local_set\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_keys_paged(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries: int = await _insert_large_number_of_entries(cache)\n\n    # Stream the keys and locally cache the results\n    local_set: set[str] = set()\n    async for e in cache.keys(by_page=True):\n        local_set.add(e)\n\n    assert len(local_set) == num_entries\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_entries_filtered(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_dict: dict[str, str] = {}\n    async for e in cache.entries(Filters.equals(\"length()\", 8)):\n        local_dict[e.key] = e.value\n\n    assert len(local_dict) == 2\n    assert local_dict[\"one\"] == \"only-one\"\n    assert local_dict[\"two\"] == \"only-two\"\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_entries_paged(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries = await _insert_large_number_of_entries(cache)\n\n    assert await cache.size() == num_entries\n\n    # Stream the keys and locally cache the results\n    local_dict: dict[str, str] = {}\n    async for e in cache.entries(by_page=True):\n        local_dict[e.key] = e.value\n\n    assert len(local_dict) == num_entries\n\n\n@pytest.mark.asyncio\nasync def test_values_filtered(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_list: list[str] = []\n    async for e in cache.values(Filters.equals(\"length()\", 8)):\n        local_list.append(e)\n\n    assert len(local_list) == 2\n    assert \"only-one\" in local_list\n    assert \"only-two\" in local_list\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_values_paged(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries: int = await _insert_large_number_of_entries(cache)\n\n    # Stream the keys and locally cache the results\n    local_list: list[str] = []\n    async for e in cache.values(by_page=True):\n        local_list.append(e)\n\n    assert len(local_list) == num_entries\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_put_all(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"three\"\n    v1: str = \"only-three\"\n    k2: str = \"four\"\n    v2: str = \"only-four\"\n    my_map: dict[str, str] = {k1: v1, k2: v2}\n    await cache.put_all(my_map)\n    r1 = await cache.get(k1)\n    r2 = await cache.get(k2)\n    assert r1 == v1\n    assert r2 == v2\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_or_default(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    k: str = \"five\"\n    default_v: str = \"five-only\"\n    r: Optional[str] = await cache.get_or_default(k1, default_v)\n    assert r == v1\n    r2: Optional[str] = await cache.get_or_default(k, default_v)\n    assert r2 == default_v\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_all(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    k3: str = \"three\"\n    v3: str = \"only-three\"\n    await cache.put(k3, v3)\n\n    r: dict[str, str] = {}\n    async for e in cache.get_all({k1, k3}):\n        r[e.key] = e.value\n\n    assert r == {k1: v1, k3: v3}\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_all_no_keys_raises_error(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    with pytest.raises(ValueError):\n        # noinspection PyTypeChecker\n        await cache.get_all(None)  # type: ignore\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_remove(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: str = await cache.remove(k1)\n    assert r == v1\n\n    r = await cache.remove(\"some-key\")\n    assert r is None\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_remove_mapping(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.remove_mapping(k1, v1)\n    assert r is True\n\n    r = await cache.remove_mapping(\"some-key\", \"some-value\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_replace(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    v2: str = \"only-one-one\"\n    r: str = await cache.replace(k1, v2)\n    assert r == v1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_replace_mapping(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    v2: str = \"only-one-one\"\n    r: bool = await cache.replace_mapping(k1, v1, v2)\n    assert r is True\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_key(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.contains_key(k1)\n    assert r is True\n\n    r = await cache.contains_key(\"two\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_value(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.contains_value(v1)\n    assert r is True\n\n    r = await cache.contains_key(\"two-only\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_is_empty(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.is_empty()\n    assert r is False\n\n    await cache.clear()\n    r = await cache.is_empty()\n    assert r is True\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_size(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    r: int = await cache.size()\n    assert r == 1\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n    r = await cache.size()\n    assert r == 2\n\n    await cache.clear()\n    r = await cache.size()\n    assert r == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_invoke(setup_and_teardown: NamedCache[str, str | Person]) -> None:\n    cache: NamedCache[str, str | Person] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    r: int = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"length()\")))\n    assert r == len(v2)\n\n    r2: bool = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"isEmpty()\")))\n    assert r2 is False\n\n    r3: str = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"toUpperCase()\")))\n    assert r3 == v2.upper()\n\n    k3: str = Person.Andy().name\n    v3: Person = Person.Andy()\n    await cache.put(k3, v3)\n    r4: str = await cache.invoke(k3, ExtractorProcessor(UniversalExtractor(\"name\")))\n    assert r4 == k3\n    r5: Address = await cache.invoke(k3, ExtractorProcessor(UniversalExtractor(\"address\")))\n    assert type(r5) == Address\n    assert r5.zipcode == v3.address.zipcode\n    r6: int = await cache.invoke(k3, ExtractorProcessor(ChainedExtractor(\"address.zipcode\")))\n    assert r6 == v3.address.zipcode\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_invoke_all_keys(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    k3: str = \"three\"\n    v3: str = \"only-three\"\n    await cache.put(k3, v3)\n\n    r: dict[str, int] = {}\n    e: MapEntry[str, int]\n    async for e in cache.invoke_all(ExtractorProcessor(UniversalExtractor(\"length()\")), keys={k1, k3}):\n        r[e.key] = e.value\n\n    assert r == {k1: 8, k3: 10}\n\n\nEVENT_TIMEOUT: Final[float] = 20.0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_cache_truncate_event(setup_and_teardown: NamedCache[str, str]) -> None:\n    cache: NamedCache[str, str] = setup_and_teardown\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    cache.on(MapLifecycleEvent.TRUNCATED, callback)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"C\", \"D\")\n    assert await cache.size() == 2\n\n    await cache.truncate()\n    await asyncio.wait_for(_waiter(event), EVENT_TIMEOUT)\n\n    assert name == cache.name\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames,DuplicatedCode\n@pytest.mark.asyncio\nasync def test_cache_release_event() -> None:\n    session: Session = await get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    cache.on(MapLifecycleEvent.RELEASED, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        cache.release()\n        await asyncio.wait_for(_waiter(event), EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert cache.released\n        assert not cache.destroyed\n        assert not cache.active\n    finally:\n        await session.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_cache_destroy_event() -> None:\n    session: Session = await get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    cache.on(MapLifecycleEvent.DESTROYED, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        await cache.destroy()\n        await asyncio.wait_for(_waiter(event), EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert not cache.released\n        assert cache.destroyed\n        assert not cache.active\n    finally:\n        await session.close()\n\n\n# noinspection PyShadowingNames,DuplicatedCode\n@pytest.mark.asyncio\nasync def test_session_release_event() -> None:\n    session: Session = await get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    session.on(MapLifecycleEvent.RELEASED, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        cache.release()\n        await asyncio.wait_for(_waiter(event), EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert cache.released\n        assert not cache.destroyed\n        assert not cache.active\n    finally:\n        await session.close()\n\n\n@pytest.mark.asyncio\nasync def test_session_reconnect() -> None:\n    session: Session = await get_session()\n    logging.debug(\"Getting cache ...\")\n\n    try:\n        count: int = 50\n        cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n\n        listener: CountingMapListener[str, str] = CountingMapListener(\"Test\")\n\n        COH_LOG.debug(\"Adding MapListener ...\")\n        await cache.add_map_listener(listener)\n\n        COH_LOG.debug(\"Inserting values ...\")\n        for i in range(count):\n            await cache.put(str(i), str(i))\n\n        COH_LOG.debug(\"Waiting for [%s] MapEvents ...\", count)\n        await listener.wait_for(count, 15)\n        COH_LOG.debug(\"All events received!\")\n\n        listener.reset()\n\n        disc_event: Event = Event()\n\n        def disc() -> None:\n            COH_LOG.debug(\"Detected session disconnect!\")\n            nonlocal disc_event\n            disc_event.set()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, disc)\n\n        COH_LOG.debug(\"Shutting down the gRPC Proxy ...\")\n        req: urllib.request.Request = urllib.request.Request(\n            \"http://127.0.0.1:30000/management/coherence/cluster/services/$GRPC:GrpcProxy/members/1/stop\", method=\"POST\"\n        )\n        with urllib.request.urlopen(req) as response:\n            response.read()\n\n        COH_LOG.debug(\"Waiting for session disconnect ...\")\n        async with asyncio.timeout(10):\n            await disc_event.wait()\n\n        # start inserting values as soon as disconnect occurs to ensure\n        # that we properly wait for the session to reconnect before\n        # issuing RPC\n        COH_LOG.debug(\"Inserting second set of values ...\")\n        for i in range(count):\n            await cache.put(str(i), str(i))\n\n        COH_LOG.debug(\"Waiting for [%s] MapEvents ...\", count)\n        await listener.wait_for(count, 15)\n        COH_LOG.debug(\"All events received!\")\n\n    finally:\n        await session.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_session_destroy_event() -> None:\n    session: Session = await get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    session.on(MapLifecycleEvent.DESTROYED, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        await cache.destroy()\n        await asyncio.wait_for(_waiter(event), EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert not cache.released\n        assert cache.destroyed\n        assert not cache.active\n    finally:\n        await session.close()\n\n\nasync def _waiter(event: Event) -> None:\n    await event.wait()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_client.py b/tests/test_client.py
--- a/tests/test_client.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/tests/test_client.py	(date 1687466844608)
@@ -48,7 +48,7 @@
     return num_entries
 
 
-async def get_session() -> Session:
+async def get_session(wait_for_ready: float = -1.0) -> Session:
     default_address: Final[str] = "localhost:1408"
     default_scope: Final[str] = ""
     default_request_timeout: Final[float] = 30.0
@@ -67,12 +67,14 @@
         tls_options.enabled = True
         tls_options.locked()
 
-        options: Options = Options(default_address, default_scope, default_request_timeout, default_format)
+        options: Options = Options(
+            default_address, default_scope, default_request_timeout, wait_for_ready, default_format
+        )
         options.tls_options = tls_options
         options.channel_options = (("grpc.ssl_target_name_override", "Star-Lord"),)
         session = await Session.create(options)
     else:
-        session = await Session.create()
+        session = await Session.create(Options(ready_timeout_seconds=wait_for_ready))
 
     return session
 
@@ -701,8 +703,8 @@
 
 
 @pytest.mark.asyncio
-async def test_session_reconnect() -> None:
-    session: Session = await get_session()
+async def test_session_reconnect_wait_for_ready() -> None:
+    session: Session = await get_session(10.0)
     logging.debug("Getting cache ...")
 
     try:
@@ -755,6 +757,77 @@
         await listener.wait_for(count, 15)
         COH_LOG.debug("All events received!")
 
+    finally:
+        await session.close()
+
+@pytest.mark.asyncio
+async def test_session_reconnect_fail_fast() -> None:
+    session: Session = await get_session()
+    logging.debug("Getting cache ...")
+
+    try:
+        count: int = 10
+        cache: NamedCache[str, str] = await session.get_cache("test-" + str(int(time() * 1000)))
+
+        listener: CountingMapListener[str, str] = CountingMapListener("Test")
+
+        COH_LOG.debug("Adding MapListener ...")
+        await cache.add_map_listener(listener)
+
+        COH_LOG.debug("Inserting values ...")
+        for i in range(count):
+            await cache.put(str(i), str(i))
+
+        COH_LOG.debug("Waiting for [%s] MapEvents ...", count)
+        await listener.wait_for(count, 15)
+        COH_LOG.debug("All events received!")
+
+        listener.reset()
+
+        disc_event: Event = Event()
+        reconn_event: Event = Event()
+
+        def disc() -> None:
+            COH_LOG.debug("Detected session disconnect!")
+            nonlocal disc_event
+            disc_event.set()
+
+        def reconn() -> None:
+            COH_LOG.debug("Detected session reconnect!")
+            nonlocal reconn_event
+            reconn_event.set()
+
+        session.on(SessionLifecycleEvent.DISCONNECTED, disc)
+        session.on(SessionLifecycleEvent.RECONNECTED, reconn)
+
+        COH_LOG.debug("Shutting down the gRPC Proxy ...")
+        req: urllib.request.Request = urllib.request.Request(
+            "http://127.0.0.1:30000/management/coherence/cluster/services/$GRPC:GrpcProxy/members/1/stop", method="POST"
+        )
+        with urllib.request.urlopen(req) as response:
+            response.read()
+
+        COH_LOG.debug("Waiting for session disconnect ...")
+        async with asyncio.timeout(10):
+            await disc_event.wait()
+
+        # start inserting values as soon as disconnect occurs to ensure
+        # that we properly wait for the session to reconnect before
+        # issuing RPC
+        COH_LOG.debug("Inserting second set of values; expecting error")
+        for i in range(count):
+            try:
+                await cache.put(str(i), str(i))
+                pytest.fail("No exception thrown by RPC")
+            except Exception as e:
+                print("Caught error: " + str(e))
+
+        COH_LOG.debug("Waiting for session reconnect ...")
+        async with asyncio.timeout(10):
+            await reconn_event.wait()
+
+
+
     finally:
         await session.close()
 
Index: src/coherence/client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport abc\nimport asyncio\nimport logging\nimport os\nfrom asyncio import Condition, Task\nfrom threading import Lock\nfrom typing import (\n    Any,\n    AsyncIterator,\n    Awaitable,\n    Callable,\n    Final,\n    Generic,\n    Literal,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    TypeVar,\n    cast,\n    no_type_check,\n)\n\n# noinspection PyPackageRequirements\nimport grpc\nfrom pymitter import EventEmitter\n\nfrom .aggregator import AverageAggregator, EntryAggregator, PriorityAggregator, SumAggregator\nfrom .comparator import Comparator\nfrom .event import MapLifecycleEvent, MapListener, SessionLifecycleEvent\nfrom .filter import Filter\nfrom .messages_pb2 import PageRequest  # type: ignore\nfrom .processor import EntryProcessor\nfrom .serialization import Serializer, SerializerRegistry\nfrom .services_pb2_grpc import NamedCacheServiceStub\nfrom .util import RequestFactory\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\n\nCOH_LOG = logging.getLogger(\"coherence\")\n\n\n@no_type_check\ndef _pre_call_cache(func):\n    def inner(self, *args, **kwargs):\n        if not self.active:\n            raise Exception(\"Cache [] has been \" + \"released\" if self.released else \"destroyed\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if not self.active:\n            raise Exception(\"Cache [{}] has been {}.\".format(self.name, \"released\" if self.released else \"destroyed\"))\n\n        # noinspection PyProtectedMember\n        await self._session._wait_for_active()\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\n@no_type_check\ndef _pre_call_session(func):\n    def inner(self, *args, **kwargs):\n        if self._closed:\n            raise Exception(\"Session has been closed.\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if self._closed:\n            raise Exception(\"Session has been closed.\")\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\nclass MapEntry(Generic[K, V]):\n    \"\"\"\n    A map entry (key-value pair).\n    \"\"\"\n\n    def __init__(self, key: K, value: V):\n        self.key = key\n        self.value = value\n\n\nclass NamedMap(abc.ABC, Generic[K, V]):\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored persistently, on disk.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"documentation\"\"\"\n\n    @abc.abstractmethod\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        \"\"\"\n        Add a callback that will be invoked when the specified MapLifecycleEvent is raised.\n        :param event:     the MapLifecycleEvent to listen for\n        :param callback:  the callback that will be invoked when the event occurs\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def destroyed(self) -> bool:\n        pass\n\n    @property\n    @abc.abstractmethod\n    def released(self) -> bool:\n        pass\n\n    @property\n    def active(self) -> bool:\n        return not self.released and not self.destroyed\n\n    @abc.abstractmethod\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        \"\"\"\n        Add a MapListener that will receive events (inserts, updates, deletes) that occur\n        against the map, with the key, old-value and new-value included.\n\n        :param listener:      the MapListener to register\n        :param listener_for:  the optional key that identifies the entry for which to raise events or a Filter\n         that will be passed MapEvent objects to select from; a MapEvent will be delivered to the listener only if the\n         filter evaluates to `True` for that MapEvent. `None` is equivalent to a Filter that always returns `True`\n        :param lite:          optionally pass `True` to indicate that the MapEvent objects do not have to include the\n         old or new values in order to allow optimizations\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        \"\"\"\n        Remove a standard map listener that previously registered to receive events.\n        :param listener:      the MapListener to be removed\n        :param listener_for:  the key or filter, if any, passed to a previous addMapListener invocation\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get(self, key: K) -> Optional[V]:\n        \"\"\"\n        Returns the value to which this cache maps the specified key.\n\n        :param key: the key whose associated value is to be returned\n\n        :Example:\n\n         >>> import asyncio\n         >>> from typing import Any, AsyncGenerator, Optional, TypeVar\n         >>> from coherence import NamedCache, Session\n         >>> K = TypeVar(\"K\")\n         >>> V = TypeVar(\"V\")\n         >>> R = TypeVar(\"R\")\n         >>> session: Session = Session(None)\n         >>> cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n         >>> k: str = \"one\"\n         >>> v: str = \"only-one\"\n         >>> await cache.put(k, v)\n         >>> r = await cache.get(k)\n         >>> print(r)\n         only-one\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        \"\"\"\n        Returns the value to which the specified key is mapped, or the specified `defaultValue`\n        if this map contains no mapping for the key.\n\n        :param key: the key whose associated value is to be returned\n        :param default_value: defaultValue if this map contains no mapping for the key.\n        :return: value for the key in the map or the `defaultValue`\n        \"\"\"\n\n    @abc.abstractmethod\n    def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Get all the specified keys if they are in the map. For each key that is in the map,\n        that key and its corresponding value will be placed in the map that is returned by\n        this method. The absence of a key in the returned map indicates that it was not in the cache,\n        which may imply (for caches that can load behind the scenes) that the requested data\n        could not be loaded.\n\n        :param keys: an Iterable of keys that may be in this map\n        :return: an AsyncIterator of MapEntry instances for the specified keys passed in `keys`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V) -> V:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the\n        map previously contained a mapping for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None`\n         if there was no mapping for key. A `None` return can also indicate\n         that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V) -> V:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to `None`) associates\n        it with the given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None` if there was no mapping for key. A\n         `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_all(self, map: dict[K, V]) -> None:\n        \"\"\"\n        Copies all mappings from the specified map to this map\n\n        :param map: the map to copy from\n        \"\"\"\n\n    @abc.abstractmethod\n    async def clear(self) -> None:\n        \"\"\"\n        Clears all the mappings in the 'NamedMap'.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def destroy(self) -> None:\n        \"\"\"\n        Release and destroy this cache.\n\n        Warning: This method is used to completely destroy the specified cache\n        across the cluster. All references in the entire cluster to this cache\n        will be invalidated, the cached data will be cleared, and all resources\n        will be released.\n        \"\"\"\n\n    @abc.abstractmethod\n    def release(self) -> None:\n        \"\"\"\n        Release local resources associated with instance.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def truncate(self) -> None:\n        \"\"\"\n        Truncates the cache.  Unlike :func:`coherence.client.NamedMap.clear()`, this function does not generate an\n        event for each removed entry.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove(self, key: K) -> V:\n        \"\"\"\n        Removes the mapping for a key from this map if it is present.\n\n        :param key: key whose mapping is to be removed from the map\n        :return: the previous value associated with key, or `None` if there was no mapping for key\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        \"\"\"\n        Removes the entry for the specified key only if it is currently mapped to the specified value.\n\n        :param key: key with which the specified value is associated\n        :param value: expected to be associated with the specified key\n        :return: resolving to true if the value was removed\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace(self, key: K, value: V) -> V:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key: key whose associated value is to be replaced\n        :param value: value expected to be associated with the specified key\n        :return: resolving to the previous value associated with the specified key, or `None` if there was no mapping\n         for the key. (A `None` return can also indicate that the map previously associated `None` with the key\n         if the implementation supports `None` values.)\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key:         key whose associated value is to be removed\n        :param old_value:   value expected to be associated with the specified key\n        :param new_value:   value to be associated with the specified key\n        :return: resolving to `true` if the value was replaced\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_key(self, key: K) -> bool:\n        \"\"\"\n        Returns `true` if the specified key is mapped a value within the cache.\n\n        :param key: the key whose presence in this cache is to be tested\n        :return: resolving to `true` if the key is mapped to a value, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_value(self, value: V) -> bool:\n        \"\"\"\n        Returns `true` if the specified value is mapped to some key.\n\n        :param value: the value expected to be associated with some key\n        :return: resolving to `true` if a mapping exists, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def is_empty(self) -> bool:\n        \"\"\"\n        Returns `true` if this map contains no key-value mappings.\n\n        :return: `true` if this map contains no key-value mappings.\n        \"\"\"\n\n    @abc.abstractmethod\n    async def size(self) -> int:\n        \"\"\"\n        Signifies the number of key-value mappings in this map.\n\n        :return: the number of key-value mappings in this map\n        \"\"\"\n\n    @abc.abstractmethod\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:\n        \"\"\"\n        Invoke the passed EntryProcessor against the Entry specified by the\n        passed key, returning the result of the invocation.\n\n        :param key: the key to process - it is not required to exist within the Map\n        :param processor: the EntryProcessor to use to process the specified key\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        \"\"\"\n        Invoke the passed EntryProcessor against the set of entries that are selected by the given Filter,\n        returning the result of the invocation for each.\n\n        Unless specified otherwise, implementations will perform this operation in two steps:\n            1. use the filter to retrieve a matching entry set\n            2. apply the agent to every filtered entry.\n\n        This algorithm assumes that the agent's processing does not affect the result of the specified filter\n        evaluation, since the filtering and processing could be performed in parallel on different threads. If this\n        assumption does not hold, the processor logic has to be idempotent, or at least re-evaluate the filter. This\n        could be easily accomplished by wrapping the processor with the ConditionalProcessor.\n\n        :param processor: the EntryProcessor to use to process the specified keys\n        :param keys: the keys to process these keys are not required to exist within the Map\n        :param filter: a Filter that results in the set of keys to be processed\n        :return: an AsyncIterator of MapEntry instances containing the results of invoking the EntryProcessor against\n         each of the specified keys\n        \"\"\"\n\n    @abc.abstractmethod\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> R:\n        \"\"\"\n        Perform an aggregating operation against the entries specified by the passed keys.\n\n        :param aggregator: the EntryAggregator that is used to aggregate across the specified entries of this Map\n        :param keys: the Iterable of keys that specify the entries within this Map to aggregate across\n        :param filter: the Filter that is used to select entries within this Map to aggregate across\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        \"\"\"\n        Return a Set of the values contained in this map that satisfy the criteria expressed by the filter.\n        If no filter or comparator is specified, it returns a Set view of the values contained in this map.The\n        collection is backed by the map, so changes to the map are reflected in the collection, and vice-versa. If\n        the map is modified while an iteration over the collection is in progress (except through the iterator's own\n        `remove` operation), the results of the iteration are undefined.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator:  the Comparator object which imposes an ordering on entries in the resulting set; or null\n         if the entries' natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances resolving to the values that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        \"\"\"\n        Return a set view of the keys contained in this map for entries that satisfy the criteria expressed by the\n        filter.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter is provided.\n        :return: an AsyncIterator of keys for entries that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Return a set view of the entries contained in this map that satisfy the criteria expressed by the filter.\n        Each element in the returned set is a :class:`coherence.client.MapEntry`.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator: the Comparator object which imposes an ordering on entries in the resulting set; or `None`\n         if the entries' values natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances that satisfy the specified criteria\n        \"\"\"\n\n\nclass NamedCache(NamedMap[K, V]):\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored in an external system, for example, a database,\n    or data that has been assembled or calculated at some significant cost.  Such entries are referred to as being\n    `cached`.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V, ttl: int = -1) -> V:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the map previously contained a mapping\n        for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V, ttl: int = -1) -> V:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to null) associates it with the\n        given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n\nclass NamedCacheClient(NamedCache[K, V]):\n    def __init__(self, cache_name: str, session: Session, serializer: Serializer):\n        self._cache_name: str = cache_name\n        self._serializer: Serializer = serializer\n        self._client_stub: NamedCacheServiceStub = NamedCacheServiceStub(session.channel)\n        self._request_factory: RequestFactory = RequestFactory(cache_name, session.scope, serializer)\n        self._emitter: EventEmitter = EventEmitter()\n        self._internal_emitter: EventEmitter = EventEmitter()\n        self._destroyed: bool = False\n        self._released: bool = False\n        self._session: Session = session\n        from .event import _MapEventsManager\n\n        self._setup_event_handlers()\n\n        self._events_manager: _MapEventsManager[K, V] = _MapEventsManager(\n            self, session, self._client_stub, serializer, self._internal_emitter\n        )\n\n    @property\n    def name(self) -> str:\n        return self._cache_name\n\n    @property\n    def destroyed(self) -> bool:\n        return self._destroyed\n\n    @property\n    def released(self) -> bool:\n        return self._released\n\n    @_pre_call_cache\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        self._emitter.on(str(event.value), callback)\n\n    @_pre_call_cache\n    async def get(self, key: K) -> Optional[V]:\n        g = self._request_factory.get_request(key)\n        v = await self._client_stub.get(g)\n        if v.present:\n            return self._request_factory.get_serializer().deserialize(v.value)\n        else:\n            return None\n\n    @_pre_call_cache\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        v: Optional[V] = await self.get(key)\n        if v is not None:\n            return v\n        else:\n            return default_value\n\n    @_pre_call_cache\n    def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        r = self._request_factory.get_all_request(keys)\n        stream = self._client_stub.getAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def put(self, key: K, value: V, ttl: int = -1) -> V:\n        p = self._request_factory.put_request(key, value, ttl)\n        v = await self._client_stub.put(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_if_absent(self, key: K, value: V, ttl: int = -1) -> V:\n        p = self._request_factory.put_if_absent_request(key, value, ttl)\n        v = await self._client_stub.putIfAbsent(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_all(self, map: dict[K, V]) -> None:\n        p = self._request_factory.put_all_request(map)\n        await self._client_stub.putAll(p)\n\n    @_pre_call_cache\n    async def clear(self) -> None:\n        r = self._request_factory.clear_request()\n        await self._client_stub.clear(r)\n\n    async def destroy(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.DESTROYED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.DESTROYED.value, self.name)\n        r = self._request_factory.destroy_request()\n        await self._client_stub.destroy(r)\n\n    @_pre_call_cache\n    def release(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.RELEASED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.RELEASED.value, self.name)\n\n    @_pre_call_cache\n    async def truncate(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.TRUNCATED.value)\n        r = self._request_factory.truncate_request()\n        await self._client_stub.truncate(r)\n\n    @_pre_call_cache\n    async def remove(self, key: K) -> V:\n        r = self._request_factory.remove_request(key)\n        v = await self._client_stub.remove(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        r = self._request_factory.remove_mapping_request(key, value)\n        v = await self._client_stub.removeMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace(self, key: K, value: V) -> V:\n        r = self._request_factory.replace_request(key, value)\n        v = await self._client_stub.replace(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        r = self._request_factory.replace_mapping_request(key, old_value, new_value)\n        v = await self._client_stub.replaceMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_key(self, key: K) -> bool:\n        r = self._request_factory.contains_key_request(key)\n        v = await self._client_stub.containsKey(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_value(self, value: V) -> bool:\n        r = self._request_factory.contains_value_request(value)\n        v = await self._client_stub.containsValue(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def is_empty(self) -> bool:\n        r = self._request_factory.is_empty_request()\n        v = await self._client_stub.isEmpty(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def size(self) -> int:\n        r = self._request_factory.size_request()\n        v = await self._client_stub.size(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> R:\n        r = self._request_factory.invoke_request(key, processor)\n        v = await self._client_stub.invoke(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        r = self._request_factory.invoke_all_request(processor, keys, filter)\n        stream = self._client_stub.invokeAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> R:\n        r = self._request_factory.aggregate_request(aggregator, keys, filter)\n        results = await self._client_stub.aggregate(r)\n        value: Any = self._request_factory.get_serializer().deserialize(results.value)\n        # for compatibility with 22.06\n        if isinstance(aggregator, SumAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, AverageAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, PriorityAggregator):\n            pri_agg: PriorityAggregator[R] = aggregator\n            if isinstance(pri_agg.aggregator, SumAggregator) and isinstance(value, str):\n                return cast(R, float(value))\n            elif isinstance(pri_agg.aggregator, AverageAggregator) and isinstance(value, str):\n                return cast(R, float(value))\n        # end compatibility with 22.06\n\n        return cast(R, value)\n\n    @_pre_call_cache\n    def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _scalar_deserializer)\n        else:\n            r = self._request_factory.values_request(filter)\n            stream = self._client_stub.values(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        if by_page and filter is None:\n            return _PagedStream(self, _scalar_deserializer, True)\n        else:\n            r = self._request_factory.keys_request(filter)\n            stream = self._client_stub.keySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _entry_deserializer)\n        else:\n            r = self._request_factory.entries_request(filter, comparator)\n            stream = self._client_stub.entrySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    from .event import MapListener\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._register_filter_listener(listener, listener_for, lite)\n        else:\n            await self._events_manager._register_key_listener(listener, listener_for, lite)\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._remove_filter_listener(listener, listener_for)\n        else:\n            await self._events_manager._remove_key_listener(listener, listener_for)\n\n    def _setup_event_handlers(self) -> None:\n        \"\"\"\n        Setup handlers to notify cache-level handlers of events.\n        \"\"\"\n        emitter: EventEmitter = self._emitter\n        internal_emitter: EventEmitter = self._internal_emitter\n        this: NamedCacheClient[K, V] = self\n        cache_name = self._cache_name\n\n        # noinspection PyProtectedMember\n        def on_destroyed(name: str) -> None:\n            if name == cache_name:\n                if not this.destroyed:\n                    this._events_manager._close()\n                    this._destroyed = True\n                    emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        # noinspection PyProtectedMember\n        def on_released(name: str) -> None:\n            if name == cache_name:\n                if not this.released:\n                    this._events_manager._close()\n                    this._released = True\n                    emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        def on_truncated(name: str) -> None:\n            if name == cache_name:\n                emitter.emit(MapLifecycleEvent.TRUNCATED.value, name)\n\n        internal_emitter.on(MapLifecycleEvent.DESTROYED.value, on_destroyed)\n        internal_emitter.on(MapLifecycleEvent.RELEASED.value, on_released)\n        internal_emitter.on(MapLifecycleEvent.TRUNCATED.value, on_truncated)\n\n\nclass TlsOptions:\n    \"\"\"\n    Options specific to the configuration of TLS.\n    \"\"\"\n\n    ENV_CA_CERT = \"COHERENCE_TLS_CERTS_PATH\"\n    \"\"\"\n    Environment variable to configure the path to CA certificates\n    \"\"\"\n    ENV_CLIENT_CERT = \"COHERENCE_TLS_CLIENT_CERT\"\n    \"\"\"\n    Environment variable to configure the path to client certificates\n    \"\"\"\n    ENV_CLIENT_KEY = \"COHERENCE_TLS_CLIENT_KEY\"\n    \"\"\"\n    Environment variable to configure the path to client key\n    \"\"\"\n\n    def __init__(\n        self,\n        locked: bool = False,\n        enabled: bool = False,\n        ca_cert_path: str | None = None,\n        client_cert_path: str | None = None,\n        client_key_path: str | None = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.TlsOptions`\n\n        :param locked: If `true`, prevents further mutations to the options.\n        :param enabled: Enable/disable TLS support.\n        :param ca_cert_path: the path to the CA certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CERTS_PATH\n        :param client_cert_path: the path to the client certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_CERT\n        :param client_key_path: the path to the client certificate key. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_KEY\n        \"\"\"\n        self._locked = locked\n        self._enabled = enabled\n\n        self._ca_cert_path = ca_cert_path if ca_cert_path is not None else os.getenv(TlsOptions.ENV_CA_CERT)\n        self._client_cert_path = (\n            client_cert_path if client_cert_path is not None else os.getenv(TlsOptions.ENV_CLIENT_CERT)\n        )\n        self._client_key_path = client_key_path if client_key_path is not None else os.getenv(TlsOptions.ENV_CLIENT_KEY)\n\n    @property\n    def enabled(self) -> bool:\n        \"\"\"\n        Property to set/get the boolean state if TLS is enabled(true) or disabled(false)\n        \"\"\"\n        return self._enabled\n\n    @enabled.setter\n    def enabled(self, enabled: bool) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._enabled = enabled\n\n    @property\n    def ca_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the CA certificate\n        \"\"\"\n        return self._ca_cert_path\n\n    @ca_cert_path.setter\n    def ca_cert_path(self, ca_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._ca_cert_path = ca_cert_path\n\n    @property\n    def client_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate.\n        \"\"\"\n        return self._client_cert_path\n\n    @client_cert_path.setter\n    def client_cert_path(self, client_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_cert_path = client_cert_path\n\n    @property\n    def client_key_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate key.\n        \"\"\"\n        return self._client_key_path\n\n    @client_key_path.setter\n    def client_key_path(self, client_key_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_key_path = client_key_path\n\n    def locked(self) -> None:\n        \"\"\"\n        Once called, no further mutations can be made.\n        \"\"\"\n        self._locked = True\n\n    def is_locked(self) -> bool:\n        return self._locked\n\n\nclass Options:\n    \"\"\"\n    Supported :func:`coherence.client.Session` options.\n    \"\"\"\n\n    ENV_SERVER_ADDRESS = \"COHERENCE_SERVER_ADDRESS\"\n    \"\"\"\n    Environment variable to specify the Coherence gRPC server address for the client to connect to. The\n    environment variable is used if address is not passed as an argument in the constructor. If the environment\n    variable is not set and address is not passed as an argument then `DEFAULT_ADDRESS` is used\n    \"\"\"\n    ENV_REQUEST_TIMEOUT = \"COHERENCE_CLIENT_REQUEST_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the request timeout for each remote call. The environment variable is used if\n    request timeout is not passed as an argument in the constructor. If the environment variable is not set and\n    request timeout is not passed as an argument then `DEFAULT_REQUEST_TIMEOUT` of 30 seconds is used\n    \"\"\"\n\n    DEFAULT_ADDRESS: Final[str] = \"localhost:1408\"\n    \"\"\"The default target address to connect to Coherence gRPC server.\"\"\"\n    DEFAULT_SCOPE: Final[str] = \"\"\n    \"\"\"The default scope.\"\"\"\n    DEFAULT_REQUEST_TIMEOUT: Final[float] = 30.0\n    \"\"\"The default request timeout.\"\"\"\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    def __init__(\n        self,\n        address: str = DEFAULT_ADDRESS,\n        scope: str = DEFAULT_SCOPE,\n        request_timeout_seconds: float = DEFAULT_REQUEST_TIMEOUT,\n        ser_format: str = DEFAULT_FORMAT,\n        channel_options: Optional[Sequence[Tuple[str, Any]]] = None,\n        tls_options: Optional[TlsOptions] = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.Options`\n\n        :param address: Address of the target Coherence cluster.  If not explicitly set, this defaults\n          to :func:`coherence.client.Options.DEFAULT_ADDRESS`. See\n          also :func:`coherence.client.Options.ENV_SERVER_ADDRESS`\n        :param scope: scope name used to link this :func:`coherence.client.Options` to the\n          corresponding `ConfigurableCacheFactory` on the server.\n        :param request_timeout_seconds: Defines the request timeout, in `seconds`, that will be applied to each\n          remote call. If not explicitly set, this defaults to :func:`coherence.client.Options.DEFAULT_REQUEST_TIMEOUT`.\n          See also :func:`coherence.client.Options.ENV_REQUEST_TIMEOUT`\n        :param ser_format: The serialization format.  Currently, this is always `json`\n        :param channel_options: The `gRPC` `ChannelOptions`. See\n            https://grpc.github.io/grpc/python/glossary.html#term-channel_arguments and\n            https://github.com/grpc/grpc/blob/master/include/grpc/impl/grpc_types.h\n        :param tls_options: Optional TLS configuration.\n        \"\"\"\n        addr = os.getenv(Options.ENV_SERVER_ADDRESS)\n        if addr is not None:\n            self._address = addr\n        else:\n            self._address = address\n\n        timeout = os.getenv(Options.ENV_REQUEST_TIMEOUT)\n        if timeout is not None:\n            time_out: float\n            try:\n                time_out = float(timeout)\n            except ValueError:\n                COH_LOG.warning(\"The timeout value of [%s] cannot be converted to a float\", Options.ENV_REQUEST_TIMEOUT)\n\n            self._request_timeout_seconds = time_out\n        else:\n            self._request_timeout_seconds = request_timeout_seconds\n\n        self._scope = scope\n        self._ser_format = ser_format\n\n        if channel_options is not None:\n            self._channel_options = channel_options\n\n        if tls_options is not None:\n            self._tls_options = tls_options\n\n    @property\n    def tls_options(self) -> Optional[TlsOptions]:\n        \"\"\"\n        Returns the TLS-specific configuration options.\n\n        :return: the TLS-specific configuration options.\n        \"\"\"\n        return getattr(self, \"_tls_options\", None)\n\n    @tls_options.setter\n    def tls_options(self, tls_options: TlsOptions) -> None:\n        \"\"\"\n        Sets the TLS-specific configuration options.\n\n        :param tls_options: the TLS-specific configuration options.\n        \"\"\"\n        self._tls_options = tls_options\n\n    @property\n    def address(self) -> str:\n        \"\"\"\n        Return the IPv4 host address and port in the format of ``[host]:[port]``.\n\n        :return: the IPv4 host address and port in the format of ``[host]:[port]``.\n        \"\"\"\n        return self._address\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n         server.\n        \"\"\"\n        return self._scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        The serialization format used by this session.  This library currently supports JSON serialization only,\n        thus this always returns 'json'.\n\n        :return: the serialization format used by this session.\n        \"\"\"\n        return self._ser_format\n\n    @property\n    def request_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the request timeout in `seconds`\n\n        :return: the request timeout in `seconds`\n        \"\"\"\n        return self._request_timeout_seconds\n\n    @property\n    def channel_options(self) -> Optional[Sequence[Tuple[str, Any]]]:\n        \"\"\"\n        Return the `gRPC` `ChannelOptions`.\n\n        :return: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        return getattr(self, \"_channel_options\", None)\n\n    @channel_options.setter\n    def channel_options(self, channel_options: Sequence[Tuple[str, Any]]) -> None:\n        \"\"\"\n        Set the `gRPC` `ChannelOptions`.\n\n        :param channel_options: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        self._channel_options = channel_options\n\n\ndef _get_channel_creds(tls_options: TlsOptions) -> grpc.ChannelCredentials:\n    client_cert: bytes | None = None\n    client_key: bytes | None = None\n    ca_cert: bytes | None = None\n\n    if tls_options.client_cert_path is not None:\n        with open(tls_options.client_cert_path, \"rb\") as f:\n            client_cert = f.read()\n    if tls_options.client_key_path is not None:\n        with open(tls_options.client_key_path, \"rb\") as f:\n            client_key = f.read()\n    if tls_options.ca_cert_path is not None:\n        with open(tls_options.ca_cert_path, \"rb\") as f:\n            ca_cert = f.read()\n\n    credentials = grpc.ssl_channel_credentials(ca_cert, client_key, client_cert)\n\n    return credentials\n\n\nclass Session:\n    \"\"\"\n    Session represents a logical connection to an endpoint. It also acts as a factory for creating caches.\n\n    This class emits the following events:\n\n        1. :class:`coherence.event.MapLifecycleEvent.DESTROYED`: when the underlying cache is destroyed\n        2. :class:`coherence.event.MapLifecycleEvent.TRUNCATED`: When the underlying cache is truncated\n        3. :class:`coherence.event.MapLifecycleEvent.RELEASED`: When the underlying cache is released\n        4. :class:`coherence.event.SessionLifecycleEvent.CONNECT`: when the Session detects the underlying `gRPC`\n            channel has connected.\n        5. :class:`coherence.event.SessionLifecycleEvent.DISCONNECT`: when the Session detects the underlying `gRPC`\n            channel has disconnected\n        6. :class:`coherence.event.SessionLifecycleEvent.RECONNECTED`: when the Session detects the underlying `gRPC`\n            channel has re-connected\n        7. :class:`coherence.event.SessionLifecycleEvent.CLOSED`: when the Session has been closed\n\n    \"\"\"\n\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    def __init__(self, session_options: Optional[Options] = None):\n        \"\"\"\n        Construct a new `Session` based on the provided :func:`coherence.client.Options`\n\n        :param session_options: the provided :func:`coherence.client.Options`\n        \"\"\"\n        self._closed: bool = False\n        self._active = False\n        self._active_condition: Condition = Condition()\n        self._caches: dict[str, NamedCache[Any, Any]] = dict()\n        self._lock: Lock = Lock()\n        if session_options is not None:\n            self._session_options = session_options\n        else:\n            self._session_options = Options()\n\n        self._tasks: Set[Task[None]] = set()\n\n        if self._session_options.tls_options is None:\n            self._channel: grpc.aio.Channel = grpc.aio.insecure_channel(\n                self._session_options.address,\n                options=None\n                if self._session_options.channel_options is None\n                else self._session_options.channel_options,\n                interceptors=[\n                    _InterceptorUnaryUnary(self),\n                    _InterceptorUnaryStream(self),\n                    _InterceptorStreamUnary(self),\n                    _InterceptorStreamStream(self),\n                ],\n            )\n        else:\n            creds: grpc.ChannelCredentials = _get_channel_creds(self._session_options.tls_options)\n            self._channel = grpc.aio.secure_channel(\n                self._session_options.address,\n                creds,\n                options=None\n                if self._session_options.channel_options is None\n                else self._session_options.channel_options,\n                interceptors=[\n                    _InterceptorUnaryUnary(self),\n                    _InterceptorUnaryStream(self),\n                    _InterceptorStreamUnary(self),\n                    _InterceptorStreamStream(self),\n                ],\n            )\n\n        watch_task: Task[None] = asyncio.create_task(watch_channel_state(self))\n        self._tasks.add(watch_task)\n        self._emitter: EventEmitter = EventEmitter()\n        self._channel.get_state(True)  # trigger connect\n\n    @staticmethod\n    async def create(session_options: Optional[Options] = None) -> Session:\n        session: Session = Session(session_options)\n        await session._set_active(False)\n        return session\n\n    # noinspection PyTypeHints\n    @_pre_call_session\n    def on(\n        self,\n        event: Literal[MapLifecycleEvent.DESTROYED] | Literal[MapLifecycleEvent.RELEASED] | SessionLifecycleEvent,\n        callback: Callable[[str], None] | Callable[[], None],\n    ) -> None:\n        \"\"\"\n        Register a callback to be invoked when the following events are raised:\n\n        * MapLifecycleEvent.DESTROYED\n        * MapLifecycleEvent.RELEASED\n        * Any SessionLifecycleEvent\n\n        The callbacks defined for MapLifecycleEvent DESTROYED and RELEASED should accept a single string\n        argument representing the cache name that the event was raised for.\n\n        The SessionLifecycleEvent callbacks should not accept call arguments.\n        :param event:     the event to listener for\n        :param callback:  the callback to invoke when the event is raised\n        \"\"\"\n        self._emitter.on(str(event.value), callback)\n\n    @property\n    def channel(self) -> grpc.aio.Channel:\n        \"\"\"\n        Return the underlying `gRPC` Channel used by this session.\n\n        :return: the underlying `gRPC` Channel used by this session.\n        \"\"\"\n        return self._channel\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n          server.\n        \"\"\"\n        return self._session_options.scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        Returns the default serialization format used by the `Session`\n\n        :return: the default serialization format used by the `Session`\n        \"\"\"\n        return self._session_options.format\n\n    @property\n    def options(self) -> Options:\n        \"\"\"\n        Return the :func:`coherence.client.Options` (read-only) used to configure this session.\n\n        :return: the :func:`coherence.client.Options` (read-only) used to configure this session.\n        \"\"\"\n        return self._session_options\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"\n        Returns `True` if Session is closed else `False`\n\n        :return: `True` if Session is closed else `False`\n        \"\"\"\n        return self._closed\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_cache(self, name: str, ser_format: str = DEFAULT_FORMAT) -> \"NamedCache[K, V]\":\n        \"\"\"\n        Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n\n        :param name: the cache name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n        \"\"\"\n        serializer = SerializerRegistry.serializer(ser_format)\n        with self._lock:\n            c = self._caches.get(name)\n            if c is None:\n                c = NamedCacheClient(name, self, serializer)\n                # initialize the event stream now to ensure lifecycle listeners will work as expected\n                await c._events_manager._ensure_stream()\n                self._setup_event_handlers(c)\n                self._caches.update({name: c})\n            return c\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_map(self, name: str, ser_format: str = DEFAULT_FORMAT) -> \"NamedMap[K, V]\":\n        \"\"\"\n        Returns a :func:`coherence.client.NameMap` for the specified cache name.\n\n        :param name: the map name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedMap` for the specified cache name.\n        \"\"\"\n        serializer = SerializerRegistry.serializer(ser_format)\n        with self._lock:\n            c = self._caches.get(name)\n            if c is None:\n                c = NamedCacheClient(name, self, serializer)\n                # initialize the event stream now to ensure lifecycle listeners will work as expected\n                await c._events_manager._ensure_stream()\n                self._setup_event_handlers(c)\n                self._caches.update({name: c})\n            return c\n\n    def is_active(self) -> bool:\n        \"\"\"\n        Returns\n        :return:\n        \"\"\"\n        return self._active\n\n    async def _set_active(self, active: bool) -> None:\n        self._active = active\n        if self._active:\n            if not self._active_condition.locked():\n                await self._active_condition.acquire()\n            self._active_condition.notify_all()\n            self._active_condition.release()\n        else:\n            await self._active_condition.acquire()\n\n    async def _wait_for_active(self) -> None:\n        if not self.is_active():\n            timeout: float = self._session_options.request_timeout_seconds\n            COH_LOG.debug(\"Waiting for session to become active; timeout=[%s seconds]\", timeout)\n            async with asyncio.timeout(timeout):\n                await self._active_condition.wait()\n\n    # noinspection PyUnresolvedReferences\n    async def close(self) -> None:\n        \"\"\"\n        Close the `Session`\n        \"\"\"\n        if not self._closed:\n            self._closed = True\n            self._emitter.emit(SessionLifecycleEvent.CLOSED.value)\n            for task in self._tasks:\n                task.cancel()\n            self._tasks.clear()\n\n            caches_copy: dict[str, NamedCache[Any, Any]] = self._caches.copy()\n            for cache in caches_copy.values():\n                cache.release()\n\n            self._caches.clear()\n\n            await self._channel.close()  # TODO: consider grace period?\n\n    def _setup_event_handlers(self, client: NamedCacheClient[K, V]) -> None:\n        this: Session = self\n\n        def on_destroyed(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        def on_released(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        client.on(MapLifecycleEvent.DESTROYED, on_destroyed)\n        client.on(MapLifecycleEvent.RELEASED, on_released)\n\n\n# noinspection PyArgumentList\nclass _BaseInterceptor:\n    \"\"\"Base client interceptor to enable waiting for channel connectivity and\n    set call timeouts.\n    Having this base class and four concrete implementations is due to\n    https://github.com/grpc/grpc/issues/31442\"\"\"\n\n    def __init__(self, session: Session):\n        self._session: Session = session\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def _do_intercept(self, continuation, client_call_details, request):\n        \"\"\"\n        Intercepts a gRPC call setting our specific options for the call.\n        :param continuation:         the gRPC call continuation\n        :param client_call_details:  the call details\n        :param request:              the gRPC request (if any)\n        :return:                     the result of the call\n        \"\"\"\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            self._session.options.request_timeout_seconds,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True,\n        )\n        return await continuation(new_details, request)\n\n\nclass _InterceptorUnaryUnary(_BaseInterceptor, grpc.aio.UnaryUnaryClientInterceptor):\n    \"\"\"Interceptor for Unary/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorUnaryStream(_BaseInterceptor, grpc.aio.UnaryStreamClientInterceptor):\n    \"\"\"Interceptor for Unary/Stream calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_stream(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamUnary(_BaseInterceptor, grpc.aio.StreamUnaryClientInterceptor):\n    \"\"\"Interceptor for Stream/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamStream(_BaseInterceptor, grpc.aio.StreamStreamClientInterceptor):\n    \"\"\"Interceptor for Stream/Stream calls.\"\"\"\n\n    # noinspection PyArgumentList,PyUnresolvedReferences\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_stream(self, continuation, client_call_details, request):\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            client_call_details.timeout,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True,\n        )\n\n        return await continuation(new_details, request)\n\n\n# noinspection PyProtectedMember\nasync def watch_channel_state(session: Session) -> None:\n    emitter: EventEmitter = session._emitter\n    channel: grpc.aio.Channel = session.channel\n    first_connect: bool = True\n    last_state: grpc.ChannelConnectivity = grpc.ChannelConnectivity.IDLE\n\n    try:\n        while True:\n            state: grpc.ChannelConnectivity = channel.get_state(False)\n            COH_LOG.debug(\"New Channel State: transitioning from [%s] to [%s]\", last_state, state)\n            match state:\n                case grpc.ChannelConnectivity.SHUTDOWN:\n                    COH_LOG.info(\"Session to [%s] terminated\", session.options.address)\n                    await session._set_active(False)\n                case grpc.ChannelConnectivity.READY:\n                    if not first_connect and not session.is_active():\n                        COH_LOG.info(\"Session re-established to [%s]\", session.options.address)\n\n                        await emitter.emit_async(SessionLifecycleEvent.RECONNECTED.value)\n                        await session._set_active(True)\n                    elif first_connect and not session.is_active():\n                        COH_LOG.info(\"Session established to [%s]\", session.options.address)\n\n                        first_connect = False\n                        await emitter.emit_async(SessionLifecycleEvent.CONNECTED.value)\n                        await session._set_active(True)\n                case _:\n                    if session.is_active():\n                        COH_LOG.warning(\"Session to [%s] disconnected; will attempt reconnect\", session.options.address)\n\n                        await emitter.emit_async(SessionLifecycleEvent.DISCONNECTED.value)\n                        await session._set_active(False)\n\n            COH_LOG.debug(\"Waiting for state change from [%s]\", state)\n            await channel.wait_for_state_change(channel.get_state(True))\n    except asyncio.CancelledError:\n        return\n\n\nclass _Stream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    A simple AsyncIterator that wraps a Callable that produces iteration\n    elements.\n    \"\"\"\n\n    def __init__(\n        self,\n        serializer: Serializer,\n        stream: grpc.Channel.unary_stream,\n        next_producer: Callable[[Serializer, grpc.Channel.unary_stream], Awaitable[T]],\n    ) -> None:\n        super().__init__()\n        # A function that may be called to produce a series of results\n        self._next_producer = next_producer\n\n        # the Serializer that should be used to deserialize results\n        self._serializer = serializer\n\n        # the gRPC stream providing results\n        self._stream = stream\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    def __anext__(self) -> Awaitable[T]:\n        return self._next_producer(self._serializer, self._stream)\n\n\n# noinspection PyProtectedMember\nclass _PagedStream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    An AsyncIterator that will stream results in pages.\n    \"\"\"\n\n    def __init__(\n        self, client: NamedCacheClient[K, V], result_handler: Callable[[Serializer, Any], Any], keys: bool = False\n    ) -> None:\n        super().__init__()\n        # flag indicating that all pages have been processed\n        self._exhausted: bool = False\n\n        # the gRPC client\n        self._client: NamedCacheClient[K, V] = client\n\n        # the handler responsible for deserializing the result\n        self._result_handler: Callable[[Serializer, Any], Any] = result_handler\n\n        # the serializer to be used when deserializing streamed results\n        self._serializer: Serializer = client._request_factory.get_serializer()\n\n        # cookie that tracks page streaming; used for each new page request\n        self._cookie: bytes = bytes()\n\n        # the gRPC stream providing the results\n        self._stream: grpc.Channel.unary_stream = None\n\n        # flag indicating a new page has been loaded\n        self._new_page: bool = True\n\n        # flag indicating that pages will be keys only\n        self._keys: bool = keys\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    async def __anext__(self) -> T:\n        # keep the loop running to ensure we don't exit\n        # prematurely which would result in a None value\n        # being returned incorrectly between pages\n        while True:\n            if self._stream is None and not self._exhausted:\n                await self.__load_next_page()\n\n            if self._stream is None and self._exhausted:\n                raise StopAsyncIteration\n\n            async for item in self._stream:\n                if self._new_page:  # a new page has been loaded; the cookie will be the first result\n                    self._new_page = False\n                    self._cookie = item.value if self._keys else item.cookie\n                    if self._cookie == b\"\":\n                        self._exhausted = True  # processing the last page\n                    continue\n                else:\n                    return self._result_handler(self._serializer, item)\n\n            self._stream = None\n            if self._exhausted:\n                raise StopAsyncIteration\n\n    # noinspection PyProtectedMember\n    async def __load_next_page(self) -> None:\n        \"\"\"\n        Requests the next page of results to be streamed.\n\n        :return: None\n        \"\"\"\n        request: PageRequest = self._client._request_factory.page_request(self._cookie)\n        self._stream = self._get_stream(request)\n        self._new_page = True\n\n    def _get_stream(self, request: PageRequest) -> grpc.Channel.unary_stream:\n        \"\"\"\n        Obtain the gRPC unary_stream for the provided PageRequest.\n\n        :param request: the PageRequest\n        :return: the gRPC unary_stream for the given request\n        \"\"\"\n        client_stub: NamedCacheServiceStub = self._client._client_stub\n        return client_stub.nextKeySetPage(request) if self._keys else client_stub.nextEntrySetPage(request)\n\n\ndef _scalar_deserializer(serializer: Serializer, item: Any) -> Any:\n    \"\"\"\n    Helper method to deserialize a key or value returned in a stream.\n\n    :param serializer: the serializer that should be used\n    :param item: the key or value to deserialize\n    :return: the deserialized key or value\n    \"\"\"\n    return serializer.deserialize(item.value)\n\n\ndef _entry_deserializer(serializer: Serializer, item: Any) -> MapEntry[Any, Any]:\n    \"\"\"\n    Helper method to deserialize entries returned in a stream.\n\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param item: the entry\n    :return: the deserialized entry\n    \"\"\"\n    return MapEntry(serializer.deserialize(item.key), serializer.deserialize(item.value))\n\n\nasync def _scalar_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> T:\n    \"\"\"\n    Helper method to iterate over a stream and produce scalar results.\n\n    :param serializer: the serializer that should be used to deserialize the scalar value\n    :param stream: the gRPC stream\n    :return: one or more deserialized scalar values\n    \"\"\"\n    async for item in stream:\n        return _scalar_deserializer(serializer, item)\n    raise StopAsyncIteration\n\n\nasync def _entry_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> MapEntry[K, V]:\n    \"\"\"\n    Helper method to iterate over a stream and produce MapEntry instances\n    .\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param stream: the gRPC stream\n    :return: one or more deserialized MapEntry instances\n    \"\"\"\n    async for item in stream:\n        return _entry_deserializer(serializer, item)\n    raise StopAsyncIteration\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/client.py b/src/coherence/client.py
--- a/src/coherence/client.py	(revision ae8cfc70745b9fa053c689c7fb50c40923c73a0f)
+++ b/src/coherence/client.py	(date 1687466238455)
@@ -62,7 +62,7 @@
             raise Exception("Cache [{}] has been {}.".format(self.name, "released" if self.released else "destroyed"))
 
         # noinspection PyProtectedMember
-        await self._session._wait_for_active()
+        await self._session._wait_for_ready()
 
         return await func(self, *args, **kwargs)
 
@@ -902,6 +902,12 @@
     request timeout is not passed as an argument in the constructor. If the environment variable is not set and
     request timeout is not passed as an argument then `DEFAULT_REQUEST_TIMEOUT` of 30 seconds is used
     """
+    ENV_READY_TIMEOUT = "COHERENCE_READY_TIMEOUT"
+    """
+    Environment variable to specify the maximum amount of time an NamedMap or NamedCache operations may wait for the
+    underlying gRPC channel to be ready.  This is independent of the request timeout which sets a deadline on how
+    long the call may take after being dispatched.
+    """
 
     DEFAULT_ADDRESS: Final[str] = "localhost:1408"
     """The default target address to connect to Coherence gRPC server."""
@@ -909,6 +915,12 @@
     """The default scope."""
     DEFAULT_REQUEST_TIMEOUT: Final[float] = 30.0
     """The default request timeout."""
+    DEFAULT_READY_TIMEOUT: Final[float] = -1.0
+    """
+    The default ready timeout is -1.0 which disables the feature by default.  Explicit configure the ready timeout
+    session option or use the environment variable to specify a positive value indicating how many seconds an RPC will
+    wait for the underlying channel to be ready before failing.
+    """
     DEFAULT_FORMAT: Final[str] = "json"
     """The default serialization format"""
 
@@ -917,6 +929,7 @@
         address: str = DEFAULT_ADDRESS,
         scope: str = DEFAULT_SCOPE,
         request_timeout_seconds: float = DEFAULT_REQUEST_TIMEOUT,
+        ready_timeout_seconds: float = DEFAULT_READY_TIMEOUT,
         ser_format: str = DEFAULT_FORMAT,
         channel_options: Optional[Sequence[Tuple[str, Any]]] = None,
         tls_options: Optional[TlsOptions] = None,
@@ -932,6 +945,11 @@
         :param request_timeout_seconds: Defines the request timeout, in `seconds`, that will be applied to each
           remote call. If not explicitly set, this defaults to :func:`coherence.client.Options.DEFAULT_REQUEST_TIMEOUT`.
           See also :func:`coherence.client.Options.ENV_REQUEST_TIMEOUT`
+        :param ready_timeout_seconds: Defines the ready timeout, in `seconds`.  If this is a positive
+          float value, remote calls will not fail immediately if no connection is available.  If this is a value of zero
+          or less, then remote calls will fail-fast.  If not explicitly configured, the default of -1 is assumed.
+
+          See also :class:`coherence.client.Options.ENV_READY_TIMEOUT`
         :param ser_format: The serialization format.  Currently, this is always `json`
         :param channel_options: The `gRPC` `ChannelOptions`. See
             https://grpc.github.io/grpc/python/glossary.html#term-channel_arguments and
@@ -956,6 +974,20 @@
         else:
             self._request_timeout_seconds = request_timeout_seconds
 
+        ready_timeout = os.getenv(Options.ENV_READY_TIMEOUT)
+        if ready_timeout is not None:
+            ready_time_out: float
+            try:
+                ready_time_out = float(ready_timeout)
+            except ValueError:
+                COH_LOG.warning(
+                    "The ready timeout value of [%s] cannot be converted to a float", Options.ENV_READY_TIMEOUT
+                )
+
+            self._ready_timeout_seconds = ready_time_out
+        else:
+            self._ready_timeout_seconds = ready_timeout_seconds
+
         self._scope = scope
         self._ser_format = ser_format
 
@@ -1022,6 +1054,15 @@
         """
         return self._request_timeout_seconds
 
+    @property
+    def ready_timeout_seconds(self) -> float:
+        """
+        Returns the ready timeout in `seconds`.
+
+        :return: the ready timeout in `seconds`
+        """
+        return self._ready_timeout_seconds
+
     @property
     def channel_options(self) -> Optional[Sequence[Tuple[str, Any]]]:
         """
@@ -1090,8 +1131,8 @@
         :param session_options: the provided :func:`coherence.client.Options`
         """
         self._closed: bool = False
-        self._active = False
-        self._active_condition: Condition = Condition()
+        self._ready = False
+        self._ready_condition: Condition = Condition()
         self._caches: dict[str, NamedCache[Any, Any]] = dict()
         self._lock: Lock = Lock()
         if session_options is not None:
@@ -1099,6 +1140,20 @@
         else:
             self._session_options = Options()
 
+        self._ready_timeout_seconds: float = self._session_options.ready_timeout_seconds
+        self._ready_enabled: bool = self._ready_timeout_seconds > 0
+
+        interceptors = [
+            _InterceptorUnaryUnary(self),
+            _InterceptorUnaryStream(self),
+            _InterceptorStreamUnary(self),
+        ]
+
+        # only add the StreamStream interceptor if ready support is enabled as
+        # when added in the non-ready case, the call will not fail-fast
+        if self._ready_enabled:
+            interceptors.append(_InterceptorStreamStream(self))
+
         self._tasks: Set[Task[None]] = set()
 
         if self._session_options.tls_options is None:
@@ -1107,12 +1162,7 @@
                 options=None
                 if self._session_options.channel_options is None
                 else self._session_options.channel_options,
-                interceptors=[
-                    _InterceptorUnaryUnary(self),
-                    _InterceptorUnaryStream(self),
-                    _InterceptorStreamUnary(self),
-                    _InterceptorStreamStream(self),
-                ],
+                interceptors=interceptors,
             )
         else:
             creds: grpc.ChannelCredentials = _get_channel_creds(self._session_options.tls_options)
@@ -1122,12 +1172,7 @@
                 options=None
                 if self._session_options.channel_options is None
                 else self._session_options.channel_options,
-                interceptors=[
-                    _InterceptorUnaryUnary(self),
-                    _InterceptorUnaryStream(self),
-                    _InterceptorStreamUnary(self),
-                    _InterceptorStreamStream(self),
-                ],
+                interceptors=interceptors,
             )
 
         watch_task: Task[None] = asyncio.create_task(watch_channel_state(self))
@@ -1138,7 +1183,7 @@
     @staticmethod
     async def create(session_options: Optional[Options] = None) -> Session:
         session: Session = Session(session_options)
-        await session._set_active(False)
+        await session._set_ready(False)
         return session
 
     # noinspection PyTypeHints
@@ -1255,29 +1300,29 @@
                 self._caches.update({name: c})
             return c
 
-    def is_active(self) -> bool:
+    def is_ready(self) -> bool:
         """
         Returns
         :return:
         """
-        return self._active
+        return True if not self._ready_enabled else self._ready
 
-    async def _set_active(self, active: bool) -> None:
-        self._active = active
-        if self._active:
-            if not self._active_condition.locked():
-                await self._active_condition.acquire()
-            self._active_condition.notify_all()
-            self._active_condition.release()
+    async def _set_ready(self, ready: bool) -> None:
+        self._ready = ready
+        if self._ready:
+            if not self._ready_condition.locked():
+                await self._ready_condition.acquire()
+            self._ready_condition.notify_all()
+            self._ready_condition.release()
         else:
-            await self._active_condition.acquire()
+            await self._ready_condition.acquire()
 
-    async def _wait_for_active(self) -> None:
-        if not self.is_active():
-            timeout: float = self._session_options.request_timeout_seconds
+    async def _wait_for_ready(self) -> None:
+        if self._ready_enabled and not self.is_ready():
+            timeout: float = self._ready_timeout_seconds
             COH_LOG.debug("Waiting for session to become active; timeout=[%s seconds]", timeout)
             async with asyncio.timeout(timeout):
-                await self._active_condition.wait()
+                await self._ready_condition.wait()
 
     # noinspection PyUnresolvedReferences
     async def close(self) -> None:
@@ -1340,7 +1385,7 @@
             self._session.options.request_timeout_seconds,
             client_call_details.metadata,
             client_call_details.credentials,
-            True,
+            True if self._session._ready_enabled else None,
         )
         return await continuation(new_details, request)
 
@@ -1391,37 +1436,43 @@
     emitter: EventEmitter = session._emitter
     channel: grpc.aio.Channel = session.channel
     first_connect: bool = True
+    connected: bool = False
     last_state: grpc.ChannelConnectivity = grpc.ChannelConnectivity.IDLE
 
     try:
         while True:
-            state: grpc.ChannelConnectivity = channel.get_state(False)
+            state: grpc.ChannelConnectivity = channel.get_state(True)
             COH_LOG.debug("New Channel State: transitioning from [%s] to [%s]", last_state, state)
             match state:
                 case grpc.ChannelConnectivity.SHUTDOWN:
+                    connected = False
                     COH_LOG.info("Session to [%s] terminated", session.options.address)
-                    await session._set_active(False)
+                    await session._set_ready(False)
                 case grpc.ChannelConnectivity.READY:
-                    if not first_connect and not session.is_active():
+                    if not first_connect and not connected:
+                        connected = True
                         COH_LOG.info("Session re-established to [%s]", session.options.address)
-
                         await emitter.emit_async(SessionLifecycleEvent.RECONNECTED.value)
-                        await session._set_active(True)
-                    elif first_connect and not session.is_active():
+                        await session._set_ready(True)
+                    elif first_connect and not connected:
+                        connected = True
                         COH_LOG.info("Session established to [%s]", session.options.address)
 
                         first_connect = False
                         await emitter.emit_async(SessionLifecycleEvent.CONNECTED.value)
-                        await session._set_active(True)
+                        await session._set_ready(True)
                 case _:
-                    if session.is_active():
+                    if connected:
+                        connected = False
                         COH_LOG.warning("Session to [%s] disconnected; will attempt reconnect", session.options.address)
 
                         await emitter.emit_async(SessionLifecycleEvent.DISCONNECTED.value)
-                        await session._set_active(False)
+                        await session._set_ready(False)
 
             COH_LOG.debug("Waiting for state change from [%s]", state)
-            await channel.wait_for_state_change(channel.get_state(True))
+            await channel.wait_for_state_change(state)
+    except Exception as e:
+        COH_LOG.error(str(e))
     except asyncio.CancelledError:
         return
 
