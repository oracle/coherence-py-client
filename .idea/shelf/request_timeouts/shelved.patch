Index: tests/e2e/test_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom asyncio import Event\nfrom time import sleep, time\nfrom typing import Dict, Final, List, Optional, Set, TypeVar, Union\n\nimport pytest\n\nimport tests\nfrom coherence import Aggregators, Filters, MapEntry, NamedCache, Session\nfrom coherence.event import MapLifecycleEvent\nfrom coherence.extractor import ChainedExtractor, Extractors, UniversalExtractor\nfrom coherence.processor import ExtractorProcessor\nfrom tests.address import Address\nfrom tests.person import Person\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\nR = TypeVar(\"R\")\n\n\nasync def _insert_large_number_of_entries(cache: NamedCache[str, str]) -> int:\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_bulk_ops: int = 10\n    num_entries: int = 40000\n    bulk_ops: int = int(num_entries / num_bulk_ops)\n    to_send: Dict[str, str] = {}\n    for i in range(num_bulk_ops):\n        offset: int = i * bulk_ops\n        for n in range(bulk_ops):\n            to_insert: str = str(offset + n)\n            to_send[to_insert] = to_insert\n\n        await cache.put_all(to_send)\n\n    return num_entries\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_and_put(cache: NamedCache[str, Union[str, int, Person]]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    # c.put(k, v, 60000)\n    await cache.put(k, v)\n    r = await cache.get(k)\n    assert r == v\n\n    k1: str = \"two\"\n    v1: int = 2\n    await cache.put(k1, v1)\n    r = await cache.get(k1)\n    assert r == v1\n\n    k2: str = Person.andy().name\n    v2: Person = Person.andy()\n    await cache.put(k2, v2)\n    r = await cache.get(k2)\n    assert isinstance(r, Person)\n    assert r.name == k2\n    assert r.address.city == Person.andy().address.city\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_put_with_ttl(cache: NamedCache[str, Union[str, int]]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v, 5000)  # TTL of 5 seconds\n    r = await cache.get(k)\n    assert r == v\n\n    sleep(5)  # sleep for 5 seconds\n    r = await cache.get(k)\n    assert r is None\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_put_if_absent(cache: NamedCache[str, str]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    r = await cache.put_if_absent(k1, v1)\n    assert r is None\n\n    r = await cache.put_if_absent(k, v)\n    assert r == v\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_keys_filtered(cache: NamedCache[str, str]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_set: Set[str] = set()\n    async for e in await cache.keys(Filters.equals(\"length()\", 8)):\n        local_set.add(e)\n\n    assert len(local_set) == 2\n    assert \"one\" in local_set\n    assert \"two\" in local_set\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_keys_paged(cache: NamedCache[str, str]) -> None:\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries: int = await _insert_large_number_of_entries(cache)\n\n    # Stream the keys and locally cache the results\n    local_set: Set[str] = set()\n    async for e in await cache.keys(by_page=True):\n        local_set.add(e)\n\n    assert len(local_set) == num_entries\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_entries_filtered(cache: NamedCache[str, str]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_dict: Dict[str, str] = {}\n    async for e in await cache.entries(Filters.equals(\"length()\", 8)):\n        local_dict[e.key] = e.value\n\n    assert len(local_dict) == 2\n    assert local_dict[\"one\"] == \"only-one\"\n    assert local_dict[\"two\"] == \"only-two\"\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_entries_paged(cache: NamedCache[str, str]) -> None:\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries = await _insert_large_number_of_entries(cache)\n\n    assert await cache.size() == num_entries\n\n    # Stream the keys and locally cache the results\n    local_dict: Dict[str, str] = {}\n    async for e in await cache.entries(by_page=True):\n        local_dict[e.key] = e.value\n\n    assert len(local_dict) == num_entries\n\n\n@pytest.mark.asyncio\nasync def test_values_filtered(cache: NamedCache[str, str]) -> None:\n    k: str = \"one\"\n    v: str = \"only-one\"\n    await cache.put(k, v)\n    k1: str = \"two\"\n    v1: str = \"only-two\"\n    await cache.put(k1, v1)\n    k2: str = \"three\"\n    v2: str = \"only-three\"\n    await cache.put(k2, v2)\n\n    local_list: List[str] = []\n    async for e in await cache.values(Filters.equals(\"length()\", 8)):\n        local_list.append(e)\n\n    assert len(local_list) == 2\n    assert \"only-one\" in local_list\n    assert \"only-two\" in local_list\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_values_paged(cache: NamedCache[str, str]) -> None:\n    # insert enough data into the cache to ensure results will be paged\n    # by the proxy.\n    num_entries: int = await _insert_large_number_of_entries(cache)\n\n    # Stream the keys and locally cache the results\n    local_list: List[str] = []\n    async for e in await cache.values(by_page=True):\n        local_list.append(e)\n\n    assert len(local_list) == num_entries\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_put_all(cache: NamedCache[str, str]) -> None:\n    k1: str = \"three\"\n    v1: str = \"only-three\"\n    k2: str = \"four\"\n    v2: str = \"only-four\"\n    my_map: Dict[str, str] = {k1: v1, k2: v2}\n    await cache.put_all(my_map)\n    r1 = await cache.get(k1)\n    r2 = await cache.get(k2)\n    assert r1 == v1\n    assert r2 == v2\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_or_default(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    k: str = \"five\"\n    default_v: str = \"five-only\"\n    r: Optional[str] = await cache.get_or_default(k1, default_v)\n    assert r == v1\n    r2: Optional[str] = await cache.get_or_default(k, default_v)\n    assert r2 == default_v\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_all(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    k3: str = \"three\"\n    v3: str = \"only-three\"\n    await cache.put(k3, v3)\n\n    r: Dict[str, str] = {}\n    # result = await cache.get_all({k1, k3})\n    async for e in await cache.get_all({k1, k3}):\n        r[e.key] = e.value\n\n    assert r == {k1: v1, k3: v3}\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_get_all_no_keys_raises_error(cache: NamedCache[str, str]) -> None:\n    with pytest.raises(ValueError):\n        # noinspection PyTypeChecker\n        await cache.get_all(None)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_remove(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: str = await cache.remove(k1)\n    assert r == v1\n\n    r = await cache.remove(\"some-key\")\n    assert r is None\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_remove_mapping(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.remove_mapping(k1, v1)\n    assert r is True\n\n    r = await cache.remove_mapping(\"some-key\", \"some-value\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_replace(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    v2: str = \"only-one-one\"\n    r: str = await cache.replace(k1, v2)\n    assert r == v1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_replace_mapping(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    v2: str = \"only-one-one\"\n    r: bool = await cache.replace_mapping(k1, v1, v2)\n    assert r is True\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_key(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.contains_key(k1)\n    assert r is True\n\n    r = await cache.contains_key(\"two\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_contains_value(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.contains_value(v1)\n    assert r is True\n\n    r = await cache.contains_key(\"two-only\")\n    assert r is False\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_is_empty(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    r: bool = await cache.is_empty()\n    assert r is False\n\n    await cache.clear()\n    r = await cache.is_empty()\n    assert r is True\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_size(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    r: int = await cache.size()\n    assert r == 1\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n    r = await cache.size()\n    assert r == 2\n\n    await cache.clear()\n    r = await cache.size()\n    assert r == 0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_invoke(cache: NamedCache[str, Union[str, Person]]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    r: int = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"length()\")))\n    assert r == len(v2)\n\n    r2: bool = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"isEmpty()\")))\n    assert r2 is False\n\n    r3: str = await cache.invoke(k2, ExtractorProcessor(UniversalExtractor(\"toUpperCase()\")))\n    assert r3 == v2.upper()\n\n    k3: str = Person.andy().name\n    v3: Person = Person.andy()\n    await cache.put(k3, v3)\n    r4: str = await cache.invoke(k3, ExtractorProcessor(UniversalExtractor(\"name\")))\n    assert r4 == k3\n    r5: Address = await cache.invoke(k3, ExtractorProcessor(UniversalExtractor(\"address\")))\n    assert isinstance(r5, Address)\n    assert r5.zipcode == v3.address.zipcode\n    r6: int = await cache.invoke(k3, ExtractorProcessor(ChainedExtractor(\"address.zipcode\")))\n    assert r6 == v3.address.zipcode\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_invoke_all_keys(cache: NamedCache[str, str]) -> None:\n    k1: str = \"one\"\n    v1: str = \"only-one\"\n    await cache.put(k1, v1)\n\n    k2: str = \"two\"\n    v2: str = \"only-two\"\n    await cache.put(k2, v2)\n\n    k3: str = \"three\"\n    v3: str = \"only-three\"\n    await cache.put(k3, v3)\n\n    r: Dict[str, int] = {}\n    e: MapEntry[str, int]\n    async for e in await cache.invoke_all(ExtractorProcessor(UniversalExtractor(\"length()\")), keys={k1, k3}):\n        r[e.key] = e.value\n\n    assert r == {k1: 8, k3: 10}\n\n\nEVENT_TIMEOUT: Final[float] = 20.0\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio(loop_scope=\"function\")\nasync def test_cache_truncate_event(cache: NamedCache[str, str]) -> None:\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    cache.on(MapLifecycleEvent.TRUNCATED, callback)\n\n    await cache.put(\"A\", \"B\")\n    await cache.put(\"C\", \"D\")\n    assert await cache.size() == 2\n\n    await cache.truncate()\n    await tests.wait_for(event, EVENT_TIMEOUT)\n\n    assert name == cache.name\n    assert await cache.size() == 0\n\n\n# noinspection PyShadowingNames,DuplicatedCode\n@pytest.mark.asyncio(loop_scope=\"function\")\nasync def test_cache_release_event() -> None:\n    session: Session = await tests.get_session()\n    cache: NamedCache[str, str] = await session.get_cache(\"test-\" + str(int(time() * 1000)))\n    name: str = \"UNSET\"\n    event: Event = Event()\n\n    def callback(n: str) -> None:\n        nonlocal name\n        name = n\n        event.set()\n\n    cache.on(MapLifecycleEvent.RELEASED, callback)\n\n    try:\n        await cache.put(\"A\", \"B\")\n        await cache.put(\"C\", \"D\")\n        assert await cache.size() == 2\n\n        await cache.release()\n        await tests.wait_for(event, EVENT_TIMEOUT)\n\n        assert name == cache.name\n        assert cache.released\n        assert not cache.destroyed\n        assert not cache.active\n    finally:\n        await session.close()\n\n\n# noinspection PyShadowingNames,DuplicatedCode,PyUnresolvedReferences\n@pytest.mark.asyncio\nasync def test_add_remove_index(person_cache: NamedCache[str, Person]) -> None:\n    await person_cache.add_index(Extractors.extract(\"age\"))\n    result = await person_cache.aggregate(Aggregators.record(), None, Filters.greater(\"age\", 25))\n    # print(result)\n    # {'@class': 'util.SimpleQueryRecord', 'results': [{'@class': 'util.SimpleQueryRecord.PartialResult',\n    # 'partitionSet': {'@class': 'net.partition.PartitionSet', 'bits': [2147483647], 'markedCount': -1,\n    # 'partitionCount': 31, 'tailMask': 2147483647}, 'steps': [{'@class': 'util.SimpleQueryRecord.PartialResult.Step',\n    # 'efficiency': 5, 'filter': 'GreaterFilter(.age, 25)',\n    # 'indexLookupRecords': [{'@class': 'util.SimpleQueryRecord.PartialResult.IndexLookupRecord',\n    # 'bytes': 6839, 'distinctValues': 5, 'extractor': '.age', 'index': 'Partitioned: Footprint=6.67KB, Size=5',\n    # 'indexDesc': 'Partitioned: ', 'ordered': False}], 'keySetSizePost': 0, 'keySetSizePre': 7, 'millis': 0,\n    # 'subSteps': []}]}], 'type': {'@class': 'aggregator.QueryRecorder.RecordType', 'enum': 'EXPLAIN'}}\n\n    idx_rec = result[\"results\"][0].get(\"steps\")[0].get(\"indexLookupRecords\")[0]\n    # print(idx_rec)\n    # {'@class': 'util.SimpleQueryRecord.PartialResult.IndexLookupRecord', 'bytes': 6839, 'distinctValues': 5,\n    # 'extractor': '.age', 'index': 'Partitioned: Footprint=6.67KB, Size=5', 'indexDesc': 'Partitioned: ',\n    # 'ordered': False}\n    assert \"index\" in idx_rec\n\n    await person_cache.remove_index(Extractors.extract(\"age\"))\n    result2 = await person_cache.aggregate(Aggregators.record(), None, Filters.greater(\"age\", 25))\n    print(result2)\n    # {'@class': 'util.SimpleQueryRecord', 'results': [{'@class': 'util.SimpleQueryRecord.PartialResult',\n    # 'partitionSet': {'@class': 'net.partition.PartitionSet', 'bits': [2147483647], 'markedCount': -1,\n    # 'partitionCount': 31, 'tailMask': 2147483647}, 'steps': [{'@class': 'util.SimpleQueryRecord.PartialResult.Step',\n    # 'efficiency': 7000, 'filter': 'GreaterFilter(.age, 25)',\n    # 'indexLookupRecords': [{'@class': 'util.SimpleQueryRecord.PartialResult.IndexLookupRecord', 'bytes': -1,\n    # 'distinctValues': -1, 'extractor': '.age', 'ordered': False}], 'keySetSizePost': 0, 'keySetSizePre': 7,\n    # 'millis': 0, 'subSteps': []}]}], 'type': {'@class': 'aggregator.QueryRecorder.RecordType', 'enum': 'EXPLAIN'}}\n    idx_rec = result2[\"results\"][0].get(\"steps\")[0].get(\"indexLookupRecords\")[0]\n    # print(idx_rec)\n    # {'@class': 'util.SimpleQueryRecord.PartialResult.IndexLookupRecord', 'bytes': -1, 'distinctValues': -1,\n    # 'extractor': '.age', 'ordered': False}\n    assert \"index\" not in idx_rec\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/e2e/test_client.py b/tests/e2e/test_client.py
--- a/tests/e2e/test_client.py	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/tests/e2e/test_client.py	(date 1728945051583)
@@ -4,12 +4,13 @@
 
 from asyncio import Event
 from time import sleep, time
-from typing import Dict, Final, List, Optional, Set, TypeVar, Union
+from typing import Dict, Final, List, Optional, Set, TypeVar, Union, final
 
 import pytest
 
 import tests
-from coherence import Aggregators, Filters, MapEntry, NamedCache, Session
+from coherence import Aggregators, Filters, MapEntry, NamedCache, Session, \
+    Options
 from coherence.event import MapLifecycleEvent
 from coherence.extractor import ChainedExtractor, Extractors, UniversalExtractor
 from coherence.processor import ExtractorProcessor
@@ -529,3 +530,15 @@
     # {'@class': 'util.SimpleQueryRecord.PartialResult.IndexLookupRecord', 'bytes': -1, 'distinctValues': -1,
     # 'extractor': '.age', 'ordered': False}
     assert "index" not in idx_rec
+
+@pytest.mark.asyncio
+async def test_request_timeout(monkeypatch: pytest.MonkeyPatch) -> None:
+        monkeypatch.setenv(Options.ENV_REQUEST_TIMEOUT, "5.0")
+        session: Session = await tests.get_session()
+        cache: NamedCache[any, any] = await session.get_cache("timeout-cache")
+        start = time()
+        try:
+            await cache.invoke("key", tests.LongRunningProcessor())
+        except TimeoutError:
+            end = time()
+            assert pytest.approx((end - start), 0.5) == 5.0
Index: tests/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\nimport asyncio\nimport logging.config\nimport os\nfrom asyncio import Event\nfrom typing import Final, List, TypeVar\n\nimport pytest\n\nfrom coherence import Options, Session, TlsOptions\nfrom coherence.event import MapEvent, MapListener\n\nK = TypeVar(\"K\")\n\"\"\"Generic type for cache keys\"\"\"\n\nV = TypeVar(\"V\")\n\"\"\"Generic type for cache values\"\"\"\n\n# logging configuration for tests\nlogging_config: str = os.path.dirname(__file__) + \"/logging.conf\"  # executing from project root\nif not os.path.exists(logging_config):\n    logging_config = \"logging.conf\"  # executing from tests directory (most likely IntelliJ)\n\nlogging.config.fileConfig(fname=logging_config, disable_existing_loggers=False)\nCOH_TEST_LOG = logging.getLogger(\"coherence-test\")\n\n\nclass CountingMapListener(MapListener[K, V]):\n    \"\"\"Listener for capturing and storing events for test evaluation.\"\"\"\n\n    _name: str\n    \"\"\"The logical name for this listener.\"\"\"\n\n    _counter: int\n    \"\"\"The number of events captured between resets.\"\"\"\n\n    _inserted: List[MapEvent[K, V]]\n    \"\"\"The captured insert events.\"\"\"\n\n    _updated: List[MapEvent[K, V]]\n    \"\"\"The captured update events.\"\"\"\n\n    _deleted: List[MapEvent[K, V]]\n    \"\"\"The captured delete events.\"\"\"\n\n    _order: List[MapEvent[K, V]]\n    \"\"\"The expected order of events.\"\"\"\n\n    def __init__(self, name: str):\n        \"\"\"\n        Constructs a new CountingMapListener.\n        This listener will record the number of insert, update, and delete events\n        as well as maintaining the order of received events.\n        :param name:  the logical name of this listener (used for debug display purposes)\n        \"\"\"\n        super().__init__()\n        self._name = name\n        self._inserted = []\n        self._updated = []\n        self._deleted = []\n        self._order = []\n        self._debug = bool(os.getenv(\"DEBUG\", True))\n        self._counter = 0\n\n        self.on_inserted(self._handle_inserted)\n        self.on_updated(self._handle_updated)\n        self.on_deleted(self._handle_deleted)\n\n    async def wait_for(self, event_count: int, timeout: float = 10.0) -> None:\n        \"\"\"\n        Wait for the specified number of events to occur.\n        :param event_count:  the expected number of events\n        :param timeout:      the maximum time to wait for all events (defaults to 10.0)\n        \"\"\"\n        await asyncio.wait_for(asyncio.create_task(self._wait_counter(event_count)), timeout)\n\n    def reset(self) -> None:\n        \"\"\"Resets the listener to its initial state.\"\"\"\n        self._counter = 0\n        self._inserted = []\n        self._updated = []\n        self._deleted = []\n        self._order = []\n\n    @property\n    def inserted(self) -> List[MapEvent[K, V]]:\n        \"\"\"\n        Returns the list of captured insert MapEvents.\n        :return: the list of captured insert MapEvents\n        \"\"\"\n        return self._inserted\n\n    @property\n    def updated(self) -> List[MapEvent[K, V]]:\n        \"\"\"\n        Returns the list of captured update MapEvents.\n        :return: the list of captured update MapEvents\n        \"\"\"\n        return self._updated\n\n    @property\n    def deleted(self) -> List[MapEvent[K, V]]:\n        \"\"\"\n        Returns the list of captured delete MapEvents.\n        :return: the list of captured delete MapEvents\n        \"\"\"\n        return self._deleted\n\n    @property\n    def order(self) -> List[MapEvent[K, V]]:\n        \"\"\"\n        Returns the list of all captured MapEvents in the order received.\n        :return: the list of all captured MapEvents in the order received\n        \"\"\"\n        return self._order\n\n    @property\n    def count(self) -> int:\n        \"\"\"\n        Returns the total number of events captured.\n        :return: the total number of events captured\n        \"\"\"\n        return self._counter\n\n    @property\n    def name(self) -> str:\n        \"\"\"\n        Returns the logical name of this listener.\n        :return:  the logical name of this listener\n        \"\"\"\n        return self._name\n\n    def _handle_inserted(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Records the insert event.\n        :param event:  the insert event\n        \"\"\"\n        self._handle_common(event)\n        self.inserted.append(event)\n\n    def _handle_updated(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Records the update event.\n        :param event:  the update event\n        \"\"\"\n        self._handle_common(event)\n        self.updated.append(event)\n\n    def _handle_deleted(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Records the delete event.\n        :param event:  the delete event\n        \"\"\"\n        self._handle_common(event)\n        self.deleted.append(event)\n\n    def _handle_common(self, event: MapEvent[K, V]) -> None:\n        \"\"\"\n        Common logic for all events.\n        :param event:  the event\n        \"\"\"\n        self.order.append(event)\n        self._counter += 1\n        COH_TEST_LOG.debug(\"[%s] Received event [%s]\", self.name, event)\n\n    async def _wait_counter(self, event_count: int) -> None:\n        \"\"\"\n        Loops waiting for the internal counter to equal `event_count`.\n        :param event_count:  the number of expected events\n        \"\"\"\n        while True:\n            print(\"### DEBUG : COUNT -> \" + str(self.count))\n            if self.count == event_count:\n                return\n            await asyncio.sleep(0)\n\n\nasync def get_session(wait_for_ready: float = 0) -> Session:\n    default_address: Final[str] = \"localhost:1408\"\n    default_scope: Final[str] = \"\"\n    default_request_timeout: Final[float] = 30.0\n    default_format: Final[str] = \"json\"\n\n    run_secure: Final[str] = \"RUN_SECURE\"\n    session: Session\n\n    if run_secure in os.environ:\n        # Default TlsOptions constructor will pick up the SSL Certs and\n        # Key values from these environment variables:\n        # COHERENCE_TLS_CERTS_PATH\n        # COHERENCE_TLS_CLIENT_CERT\n        # COHERENCE_TLS_CLIENT_KEY\n        tls_options: TlsOptions = TlsOptions()\n        tls_options.enabled = True\n        tls_options.locked()\n\n        options: Options = Options(\n            default_address, default_scope, default_request_timeout, wait_for_ready, ser_format=default_format\n        )\n        options.tls_options = tls_options\n        options.channel_options = ((\"grpc.ssl_target_name_override\", \"Star-Lord\"),)\n        session = await Session.create(options)\n    else:\n        session = await Session.create(Options(ready_timeout_seconds=wait_for_ready))\n\n    return session\n\n\nasync def wait_for(event: Event, timeout: float) -> None:\n    await asyncio.wait_for(event.wait(), timeout)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/__init__.py b/tests/__init__.py
--- a/tests/__init__.py	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/tests/__init__.py	(date 1728941993403)
@@ -5,12 +5,15 @@
 import logging.config
 import os
 from asyncio import Event
-from typing import Final, List, TypeVar
+from typing import Final, List, TypeVar, Any
 
 import pytest
 
 from coherence import Options, Session, TlsOptions
 from coherence.event import MapEvent, MapListener
+from coherence.processor import EntryProcessor
+from coherence.serialization import proxy
+
 
 K = TypeVar("K")
 """Generic type for cache keys"""
@@ -210,3 +213,7 @@
 
 async def wait_for(event: Event, timeout: float) -> None:
     await asyncio.wait_for(event.wait(), timeout)
+
+@proxy("test.longrunning")
+class LongRunningProcessor(EntryProcessor[Any]):
+    ...
Index: src/coherence/util.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2023 Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport sys\nimport threading\nimport time\nfrom abc import ABC, abstractmethod\nfrom asyncio import Event\nfrom typing import Any, AsyncIterator, Callable, Generic, Optional, Tuple, TypeVar\n\nfrom google.protobuf.any_pb2 import Any as GrpcAny  # type: ignore\nfrom google.protobuf.wrappers_pb2 import BoolValue, BytesValue, Int32Value  # type: ignore\n\nfrom .aggregator import EntryAggregator\nfrom .cache_service_messages_v1_pb2 import EnsureCacheRequest, ExecuteRequest, IndexRequest, KeyOrFilter, KeysOrFilter\nfrom .cache_service_messages_v1_pb2 import MapListenerRequest as V1MapListenerRequest\nfrom .cache_service_messages_v1_pb2 import NamedCacheRequest, NamedCacheRequestType, NamedCacheResponse\nfrom .cache_service_messages_v1_pb2 import PutAllRequest as V1PutAllRequest\nfrom .cache_service_messages_v1_pb2 import PutRequest as V1PutRequest\nfrom .cache_service_messages_v1_pb2 import QueryRequest\nfrom .cache_service_messages_v1_pb2 import ReplaceMappingRequest as V1ReplaceMappingRequest\nfrom .common_messages_v1_pb2 import BinaryKeyAndValue, CollectionOfBytesValues, OptionalValue\nfrom .comparator import Comparator\nfrom .entry import MapEntry\nfrom .extractor import ValueExtractor\nfrom .filter import Filter, Filters, MapEventFilter\nfrom .messages_pb2 import (\n    AddIndexRequest,\n    AggregateRequest,\n    ClearRequest,\n    ContainsKeyRequest,\n    ContainsValueRequest,\n    DestroyRequest,\n    Entry,\n    EntrySetRequest,\n    GetAllRequest,\n    GetRequest,\n    InvokeAllRequest,\n    InvokeRequest,\n    IsEmptyRequest,\n    KeySetRequest,\n    MapListenerRequest,\n    PageRequest,\n    PutAllRequest,\n    PutIfAbsentRequest,\n    PutRequest,\n    RemoveIndexRequest,\n    RemoveMappingRequest,\n    RemoveRequest,\n    ReplaceMappingRequest,\n    ReplaceRequest,\n    SizeRequest,\n    TruncateRequest,\n    ValuesRequest,\n)\nfrom .processor import EntryProcessor\nfrom .proxy_service_messages_v1_pb2 import InitRequest, ProxyRequest\nfrom .serialization import Serializer\n\nE = TypeVar(\"E\")\nK = TypeVar(\"K\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\nV = TypeVar(\"V\")\n\n\nclass Error:\n\n    def __init__(self, message: str):\n        super().__init__()\n        self._message: str = message\n\n    @property\n    def message(self) -> str:\n        return self._message\n\n\nclass Dispatcher(ABC):\n    @abstractmethod\n    async def dispatch(self, stream_handler: Any) -> None:\n        pass\n\n\nclass ResponseTransformer(ABC, Generic[T]):\n    def __init__(self, serializer: Serializer):\n        self._serializer = serializer\n\n    @abstractmethod\n    def transform(self, response: NamedCacheResponse) -> T:\n        pass\n\n    @property\n    def serializer(self) -> Serializer:\n        return self._serializer\n\n\nclass ScalarResultProducer(ABC, Generic[T]):\n    @abstractmethod\n    def result(self) -> T:\n        pass\n\n\nclass KeyValueTransformer(ResponseTransformer[MapEntry[K, V]]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> MapEntry[K, V]:\n        from coherence import MapEntry\n\n        binary_key_value = BinaryKeyAndValue()\n        response.message.Unpack(binary_key_value)\n        return MapEntry(\n            self.serializer.deserialize(binary_key_value.key), self._serializer.deserialize(binary_key_value.value)\n        )\n\n\nclass ValueTransformer(ResponseTransformer[V]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> V:\n        binary_key_value = BinaryKeyAndValue()\n        response.message.Unpack(binary_key_value)\n        return self.serializer.deserialize(binary_key_value.value)\n\n\nclass OptionalValueTransformer(ResponseTransformer[Optional[T]]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> Optional[T]:\n        optional_value = OptionalValue()\n        response.message.Unpack(optional_value)\n        if optional_value.present:\n            return self.serializer.deserialize(optional_value.value)\n        else:\n            return None\n\n\nclass IntValueTransformer(ResponseTransformer[int]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> int:\n        value = Int32Value()\n        response.message.Unpack(value)\n        return value.value\n\n\nclass BoolValueTransformer(ResponseTransformer[bool]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> bool:\n        bool_value = BoolValue()\n        response.message.Unpack(bool_value)\n        return bool_value.value\n\n\nclass BytesValueTransformer(ResponseTransformer[Optional[T]]):\n    def __init__(self, serializer: Serializer):\n        super().__init__(serializer)\n\n    def transform(self, response: NamedCacheResponse) -> Optional[T]:\n        bytes_value = BytesValue()\n        response.message.Unpack(bytes_value)\n        result: T = self.serializer.deserialize(bytes_value.value)\n        return result\n\n\nclass CookieTransformer(ResponseTransformer[bytes]):\n    def transform(self, response: NamedCacheResponse) -> bytes:\n        bytes_value = BytesValue()\n        response.message.Unpack(bytes_value)\n        return bytes_value.value\n\n\nclass CacheIdTransformer(ResponseTransformer[int]):\n\n    def transform(self, response: NamedCacheResponse) -> int:\n        return response.cacheId\n\n\nclass ResponseObserver(ABC):\n    def __init__(self, request: ProxyRequest):\n        if request is None:\n            raise ValueError(\"Request cannot be None\")\n\n        self._request: ProxyRequest = request\n        self._waiter: Event = Event()\n        self._complete: bool = False\n        self._error: Optional[Error] = None\n\n    @abstractmethod\n    def _next(self, response: NamedCacheResponse) -> None:\n        pass\n\n    def _err(self, error: Error) -> None:\n        self._error = error\n        self._done()\n\n    def _done(self) -> None:\n        self._complete = True\n        self._waiter.set()\n\n    @property\n    def id(self) -> int:\n        return self._request.id\n\n\nclass UnaryDispatcher(ResponseObserver, Dispatcher, ScalarResultProducer[T]):\n    def __init__(self, request: ProxyRequest, transformer: Optional[ResponseTransformer[T]] = None):\n        super().__init__(request)\n        self._waiter = Event()\n        self._transformer = transformer\n        self._result: T\n        self._complete: bool = False\n\n    def _next(self, response: NamedCacheResponse) -> None:\n        if self._complete is True:\n            return\n\n        if self._transformer is not None:\n            self._result = self._transformer.transform(response)\n\n    async def dispatch(self, stream_handler: Any) -> None:\n        assert self._complete is False\n\n        stream_handler.register_observer(self)\n        await stream_handler.send_proxy_request(self._request)\n\n        await asyncio.wait_for(self._waiter.wait(), 10.0)\n\n        if self._error is not None:\n            raise RuntimeError(self._error.message)\n\n    def result(self) -> T:\n        return self._result\n\n\nclass StreamingDispatcher(ResponseObserver, Dispatcher, AsyncIterator[T]):\n    def __init__(self, request: ProxyRequest, transformer: ResponseTransformer[T]):\n        super().__init__(request)\n        self._transformer = transformer\n\n    def _next(self, response: NamedCacheResponse) -> None:\n        if self._complete is True:\n            return\n\n        self._result: T = self._transformer.transform(response)\n        self._waiter.set()\n\n    async def dispatch(self, stream_handler: Any) -> None:\n        assert self._complete is False\n\n        stream_handler.register_observer(self)\n        await stream_handler.send_proxy_request(self._request)\n\n        if self._error is not None:\n            raise RuntimeError(self._error.message)\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    async def __anext__(self) -> T:\n        await self._waiter.wait()\n        if self._error is not None:\n            raise RuntimeError(self._error.message)\n        elif self._complete is True:\n            raise StopAsyncIteration\n        else:\n            try:\n                return self._result\n            finally:\n                self._waiter.clear()\n\n\nclass PagingDispatcher(ResponseObserver, Dispatcher, AsyncIterator[T]):\n    def __init__(\n        self,\n        request: ProxyRequest,\n        request_creator: Callable[[bytes], ProxyRequest],\n        transformer: ResponseTransformer[T],\n    ):\n        super().__init__(request)\n        self._cookie_transformer: ResponseTransformer[Any] = CookieTransformer(transformer.serializer)\n        self._transformer: ResponseTransformer[T] = transformer\n        self._request_creator: Callable[[bytes], ProxyRequest] = request_creator\n        self._first: bool = True\n        self._cookie: bytes = bytes()\n        self._exhausted: bool = False\n        self._stream_handler: Any\n\n    def _next(self, response: NamedCacheResponse) -> None:\n        if self._complete is True:\n            return\n\n        if self._first:\n            # first response will have the cookie\n            self._first = False\n            self._cookie = self._cookie_transformer.transform(response)\n            self._exhausted = self._cookie == b\"\"\n        else:\n            self._result: T = self._transformer.transform(response)\n            self._waiter.set()\n\n    def _done(self) -> None:\n        if self._exhausted:\n            self._complete = True\n            self._waiter.set()\n        else:\n            self._first = True\n            self._request = self._request_creator(self._cookie)\n            asyncio.create_task(self.dispatch(self._stream_handler))\n\n    async def dispatch(self, stream_handler: Any) -> None:\n        # noinspection PyAttributeOutsideInit\n        self._stream_handler = stream_handler\n\n        stream_handler.register_observer(self)\n        await stream_handler.send_proxy_request(self._request)\n\n        if self._error is not None:\n            raise RuntimeError(self._error.message)\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    async def __anext__(self) -> T:\n        await self._waiter.wait()\n        if self._error is not None:\n            raise RuntimeError(self._error.message)\n        elif self._complete is True:\n            raise StopAsyncIteration\n        else:\n            try:\n                return self._result\n            finally:\n                self._waiter.clear()\n\n\nclass RequestFactory:\n    def __init__(self, cache_name: str, scope: str, serializer: Serializer) -> None:\n        self._cache_name: str = cache_name\n        self._scope: str = scope\n        self._serializer: Serializer = serializer\n        self.__uidPrefix: str = \"-\" + cache_name + \"-\" + str(time.time_ns())\n        self.__next_request_id: int = 0\n        self.__next_filter_id: int = 0\n\n    def get_serializer(self) -> Serializer:\n        return self._serializer\n\n    def put_request(self, key: K, value: V, ttl: int = -1) -> PutRequest:\n        p = PutRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n            ttl=ttl,\n        )\n        return p\n\n    def get_request(self, key: K) -> GetRequest:\n        g = GetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return g\n\n    def get_all_request(self, keys: set[K]) -> GetAllRequest:\n        if keys is None:\n            raise ValueError(\"Must specify a set of keys\")\n\n        get_all: GetAllRequest = GetAllRequest(\n            scope=self._scope, cache=self._cache_name, format=self._serializer.format\n        )\n\n        for key in keys:\n            get_all.key.append(self._serializer.serialize(key))\n\n        return get_all\n\n    def put_if_absent_request(self, key: K, value: V, ttl: int = -1) -> PutIfAbsentRequest:\n        p = PutIfAbsentRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n            ttl=ttl,\n        )\n        return p\n\n    def put_all_request(self, map: dict[K, V]) -> PutAllRequest:\n        entry_list = list()\n        for key, value in map.items():\n            k = self._serializer.serialize(key)\n            v = self._serializer.serialize(value)\n            e = Entry(key=k, value=v)\n            entry_list.append(e)\n        p = PutAllRequest(scope=self._scope, cache=self._cache_name, format=self._serializer.format, entry=entry_list)\n        return p\n\n    def clear_request(self) -> ClearRequest:\n        r = ClearRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def destroy_request(self) -> DestroyRequest:\n        r = DestroyRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def truncate_request(self) -> TruncateRequest:\n        r = TruncateRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def remove_request(self, key: K) -> RemoveRequest:\n        r = RemoveRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def remove_mapping_request(self, key: K, value: V) -> RemoveMappingRequest:\n        r = RemoveMappingRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def replace_request(self, key: K, value: V) -> ReplaceRequest:\n        r = ReplaceRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> ReplaceMappingRequest:\n        r = ReplaceMappingRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n            previousValue=self._serializer.serialize(old_value),\n            newValue=self._serializer.serialize(new_value),\n        )\n        return r\n\n    def contains_key_request(self, key: K) -> ContainsKeyRequest:\n        r = ContainsKeyRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def contains_value_request(self, value: V) -> ContainsValueRequest:\n        r = ContainsValueRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            value=self._serializer.serialize(value),\n        )\n        return r\n\n    def is_empty_request(self) -> IsEmptyRequest:\n        r = IsEmptyRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def size_request(self) -> SizeRequest:\n        r = SizeRequest(scope=self._scope, cache=self._cache_name)\n        return r\n\n    def invoke_request(self, key: K, processor: EntryProcessor[R]) -> InvokeRequest:\n        r = InvokeRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            processor=self._serializer.serialize(processor),\n            key=self._serializer.serialize(key),\n        )\n        return r\n\n    def invoke_all_request(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> InvokeAllRequest:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        r = InvokeAllRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            processor=self._serializer.serialize(processor),\n        )\n\n        if keys is not None:\n            for key in keys:\n                r.keys.append(self._serializer.serialize(key))\n        else:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def aggregate_request(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AggregateRequest:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        r: AggregateRequest = AggregateRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            aggregator=self._serializer.serialize(aggregator),\n        )\n\n        if keys is not None:\n            for key in keys:\n                r.keys.append(self._serializer.serialize(key))\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def values_request(self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None) -> ValuesRequest:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        r: ValuesRequest = ValuesRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def keys_request(self, filter: Optional[Filter] = None) -> KeySetRequest:\n        r: KeySetRequest = KeySetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        return r\n\n    def entries_request(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None\n    ) -> EntrySetRequest:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        r: EntrySetRequest = EntrySetRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n        )\n\n        if filter is not None:\n            r.filter = self._serializer.serialize(filter)\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def page_request(self, cookie: bytes) -> PageRequest:\n        \"\"\"\n        Creates a gRPC PageRequest.\n\n        :param cookie: the cookie used for paging\n        :return: a new PageRequest\n        \"\"\"\n\n        r: PageRequest = PageRequest(\n            scope=self._scope, cache=self._cache_name, format=self._serializer.format, cookie=cookie\n        )\n\n        return r\n\n    def map_listener_request(\n        self, subscribe: bool, lite: bool = False, *, key: Optional[K] = None, filter: Optional[Filter] = None\n    ) -> MapListenerRequest:\n        \"\"\"Creates a gRPC generated MapListenerRequest\"\"\"\n\n        if key is None and filter is None:\n            raise AssertionError(\"Must specify a key or a filter\")\n\n        request: MapListenerRequest = MapListenerRequest(\n            cache=self._cache_name, scope=self._scope, format=self._serializer.format\n        )\n\n        request.lite = lite\n        request.subscribe = subscribe\n        request.uid = self.__generate_next_request_id(\"key\" if key is not None else \"filter\")\n        request.trigger = bytes()\n        request.priming = False\n\n        if key is not None:  # registering a key listener\n            # noinspection PyUnresolvedReferences\n            request.type = MapListenerRequest.RequestType.KEY\n            request.key = self._serializer.serialize(key)\n        else:  # registering a Filter listener\n            # noinspection PyUnresolvedReferences\n            request.type = MapListenerRequest.RequestType.FILTER\n            self.__next_filter_id += 1\n            request.filterId = self.__next_filter_id\n            filter_local: Filter = filter if filter is not None else Filters.always()\n            if not isinstance(filter_local, MapEventFilter):\n                # noinspection PyUnresolvedReferences\n                filter_local = MapEventFilter.from_filter(filter_local)\n\n            request.filter = self._serializer.serialize(filter_local)\n\n        return request\n\n    def map_event_subscribe(self) -> MapListenerRequest:\n        request: MapListenerRequest = MapListenerRequest(\n            cache=self._cache_name, scope=self._scope, format=self._serializer.format\n        )\n        request.uid = self.__generate_next_request_id(\"init\")\n        request.subscribe = True\n        # noinspection PyUnresolvedReferences\n        request.type = MapListenerRequest.RequestType.INIT\n\n        return request\n\n    def __generate_next_request_id(self, prefix: str) -> str:\n        \"\"\"Generates a prefix map-specific prefix when starting a MapEvent gRPC stream.\"\"\"\n        self.__next_request_id += 1\n        return prefix + self.__uidPrefix + str(self.__next_request_id)\n\n    def add_index_request(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> AddIndexRequest:\n        r = AddIndexRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            extractor=self._serializer.serialize(extractor),\n        )\n        r.sorted = ordered\n\n        if comparator is not None:\n            r.comparator = self._serializer.serialize(comparator)\n\n        return r\n\n    def remove_index_request(self, extractor: ValueExtractor[T, E]) -> RemoveIndexRequest:\n        r = RemoveIndexRequest(\n            scope=self._scope,\n            cache=self._cache_name,\n            format=self._serializer.format,\n            extractor=self._serializer.serialize(extractor),\n        )\n\n        return r\n\n\nclass RequestIdGenerator:\n    _generator = None\n\n    def __init__(self) -> None:\n        self._lock = threading.Lock()\n        self._counter = 0\n\n    @classmethod\n    def generator(cls) -> RequestIdGenerator:\n        if RequestIdGenerator._generator is None:\n            RequestIdGenerator._generator = RequestIdGenerator()\n        return RequestIdGenerator._generator\n\n    @classmethod\n    def next(cls) -> int:\n        generator = cls.generator()\n        with generator._lock:\n            if generator._counter == sys.maxsize:\n                generator._counter = 0\n            else:\n                generator._counter += 1\n            return generator._counter\n\n\nclass RequestFactoryV1:\n\n    def __init__(self, cache_name: str, cache_id: int, scope: str, serializer: Serializer) -> None:\n        self._cache_name: str = cache_name\n        self._cache_id: int = cache_id\n        self._scope: str = scope\n        self._serializer: Serializer = serializer\n\n    @property\n    def cache_id(self) -> int:\n        return self._cache_id\n\n    @cache_id.setter\n    def cache_id(self, value: int) -> None:\n        self._cache_id = value\n\n    def get_serializer(self) -> Serializer:\n        return self._serializer\n\n    def _create_named_cache_request(self, request: Any, request_type: NamedCacheRequestType) -> NamedCacheRequest:\n        any_cache_request = GrpcAny()\n        any_cache_request.Pack(request)\n\n        return NamedCacheRequest(\n            type=request_type,\n            cacheId=self.cache_id,\n            message=any_cache_request,\n        )\n\n    def create_proxy_request(self, named_cache_request: NamedCacheRequest) -> ProxyRequest:\n        any_named_cache_request = GrpcAny()\n        any_named_cache_request.Pack(named_cache_request)\n        req_id = RequestIdGenerator.next()\n        proxy_request = ProxyRequest(\n            id=req_id,\n            message=any_named_cache_request,\n        )\n        return proxy_request\n\n    @staticmethod\n    def init_sub_channel(\n        scope: str = \"\",\n        serialization_format: str = \"json\",\n        protocol: str = \"CacheService\",\n        protocol_version: int = 1,\n        supported_protocol_version: int = 1,\n        heartbeat: int = 0,\n    ) -> ProxyRequest:\n        init_request = InitRequest(\n            scope=scope,\n            format=serialization_format,\n            protocol=protocol,\n            protocolVersion=protocol_version,\n            supportedProtocolVersion=supported_protocol_version,\n            heartbeat=heartbeat,\n        )\n\n        return ProxyRequest(id=2, init=init_request)\n\n    def ensure_request(self, cache_name: str) -> UnaryDispatcher[int]:\n        cache_request = EnsureCacheRequest(cache=cache_name)\n\n        any_cache_request = GrpcAny()\n        any_cache_request.Pack(cache_request)\n\n        named_cache_request = NamedCacheRequest(\n            type=NamedCacheRequestType.EnsureCache,\n            message=any_cache_request,\n        )\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), CacheIdTransformer(self._serializer))\n\n    def put_request(self, key: K, value: V, ttl: int = 0) -> UnaryDispatcher[Optional[V]]:\n        request: NamedCacheRequest = self._create_named_cache_request(\n            V1PutRequest(\n                key=self._serializer.serialize(key),  # Serialized key\n                value=self._serializer.serialize(value),  # Serialized value\n                ttl=ttl,\n            ),\n            NamedCacheRequestType.Put,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(request), OptionalValueTransformer(self._serializer))\n\n    def get_request(self, key: K) -> UnaryDispatcher[Optional[V]]:\n        request: NamedCacheRequest = self._create_named_cache_request(\n            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Get\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(request), OptionalValueTransformer(self._serializer))\n\n    def get_all_request(self, keys: set[K]) -> StreamingDispatcher[MapEntry[K, V]]:\n        if keys is None:\n            raise ValueError(\"Must specify a set of keys\")\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            CollectionOfBytesValues(\n                values=list(self._serializer.serialize(k) for k in keys),\n            ),\n            NamedCacheRequestType.GetAll,\n        )\n\n        return StreamingDispatcher(\n            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)\n        )\n\n    def put_if_absent_request(self, key: K, value: V, ttl: int = 0) -> UnaryDispatcher[Optional[V]]:\n        request: NamedCacheRequest = self._create_named_cache_request(\n            V1PutRequest(\n                key=self._serializer.serialize(key),  # Serialized key\n                value=self._serializer.serialize(value),  # Serialized value\n                ttl=ttl,\n            ),\n            NamedCacheRequestType.PutIfAbsent,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(request), BytesValueTransformer(self._serializer))\n\n    def put_all_request(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> Dispatcher:\n        request: NamedCacheRequest = self._create_named_cache_request(\n            V1PutAllRequest(\n                entries=list(\n                    BinaryKeyAndValue(key=self._serializer.serialize(k), value=self._serializer.serialize(v))\n                    for k, v in kv_map.items()\n                ),\n                ttl=ttl,\n            ),\n            NamedCacheRequestType.PutAll,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(request))\n\n    def clear_request(self) -> Dispatcher:\n        named_cache_request = NamedCacheRequest(\n            type=NamedCacheRequestType.Clear,\n            cacheId=self.cache_id,\n        )\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request))\n\n    def destroy_request(self) -> Dispatcher:\n        named_cache_request: NamedCacheRequest = NamedCacheRequest(\n            type=NamedCacheRequestType.Destroy,\n            cacheId=self.cache_id,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request))\n\n    def truncate_request(self) -> Dispatcher:\n        named_cache_request: NamedCacheRequest = NamedCacheRequest(\n            type=NamedCacheRequestType.Truncate,\n            cacheId=self.cache_id,\n        )\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request))\n\n    def remove_request(self, key: K) -> UnaryDispatcher[Optional[V]]:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Remove\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))\n\n    def remove_mapping_request(self, key: K, value: V) -> UnaryDispatcher[bool]:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),\n            NamedCacheRequestType.RemoveMapping,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))\n\n    def replace_request(self, key: K, value: V) -> UnaryDispatcher[Optional[V]]:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            BinaryKeyAndValue(key=self._serializer.serialize(key), value=self._serializer.serialize(value)),\n            NamedCacheRequestType.Replace,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))\n\n    def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> UnaryDispatcher[bool]:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            V1ReplaceMappingRequest(\n                key=self._serializer.serialize(key),\n                previousValue=self._serializer.serialize(old_value),\n                newValue=self._serializer.serialize(new_value),\n            ),\n            NamedCacheRequestType.ReplaceMapping,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))\n\n    def contains_key_request(self, key: K) -> UnaryDispatcher[bool]:\n        named_cache_request = self._create_named_cache_request(\n            BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.ContainsKey\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))\n\n    def contains_value_request(self, value: V) -> UnaryDispatcher[bool]:\n        named_cache_request = self._create_named_cache_request(\n            BytesValue(value=self._serializer.serialize(value)), NamedCacheRequestType.ContainsValue\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))\n\n    def is_empty_request(self) -> UnaryDispatcher[bool]:\n        named_cache_request = NamedCacheRequest(\n            type=NamedCacheRequestType.IsEmpty,\n            cacheId=self.cache_id,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))\n\n    def size_request(self) -> UnaryDispatcher[int]:\n        named_cache_request = NamedCacheRequest(\n            type=NamedCacheRequestType.Size,\n            cacheId=self.cache_id,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), IntValueTransformer(self._serializer))\n\n    def invoke_request(self, key: K, processor: EntryProcessor[R]) -> UnaryDispatcher[Optional[R]]:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            ExecuteRequest(\n                agent=self._serializer.serialize(processor),\n                keys=KeysOrFilter(\n                    key=self._serializer.serialize(key),\n                ),\n            ),\n            NamedCacheRequestType.Invoke,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), ValueTransformer(self._serializer))\n\n    def invoke_all_request(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> StreamingDispatcher[MapEntry[K, R]]:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        if keys is not None:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(processor),\n                keys=KeysOrFilter(\n                    keys=CollectionOfBytesValues(\n                        values=list(self._serializer.serialize(key) for key in keys),\n                    ),\n                ),\n            )\n        elif filter is not None:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(processor),\n                keys=KeysOrFilter(\n                    filter=self._serializer.serialize(filter),\n                ),\n            )\n        else:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(processor),\n            )\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            cache_request, NamedCacheRequestType.Invoke\n        )\n\n        return StreamingDispatcher(\n            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)\n        )\n\n    def aggregate_request(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> UnaryDispatcher[Optional[R]]:\n        if keys is not None and filter is not None:\n            raise ValueError(\"keys and filter are mutually exclusive\")\n\n        if keys is not None:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(aggregator),\n                keys=KeysOrFilter(\n                    keys=CollectionOfBytesValues(\n                        values=list(self._serializer.serialize(key) for key in keys),\n                    ),\n                ),\n            )\n        elif filter is not None:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(aggregator),\n                keys=KeysOrFilter(\n                    filter=self._serializer.serialize(filter),\n                ),\n            )\n        else:\n            cache_request = ExecuteRequest(\n                agent=self._serializer.serialize(aggregator),\n            )\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            cache_request, NamedCacheRequestType.Aggregate\n        )\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))\n\n    def values_request(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None\n    ) -> StreamingDispatcher[V]:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        if filter is not None:\n            query_request = QueryRequest(filter=self._serializer.serialize(filter))\n        elif comparator is not None:\n            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))\n        else:\n            query_request = QueryRequest()\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            query_request, NamedCacheRequestType.QueryValues\n        )\n\n        return StreamingDispatcher(\n            self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore\n        )\n\n    def keys_request(self, filter: Optional[Filter] = None) -> StreamingDispatcher[K]:\n\n        if filter is not None:\n            query_request = QueryRequest(filter=self._serializer.serialize(filter))\n        else:\n            query_request = QueryRequest()\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            query_request, NamedCacheRequestType.QueryKeys\n        )\n\n        return StreamingDispatcher(\n            self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore\n        )\n\n    def entries_request(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None\n    ) -> StreamingDispatcher[MapEntry[K, V]]:\n        if filter is None and comparator is not None:\n            raise ValueError(\"Filter cannot be None\")\n\n        if filter is not None:\n            query_request = QueryRequest(filter=self._serializer.serialize(filter))\n        elif comparator is not None:\n            query_request = QueryRequest(comparator=self._serializer.serialize(comparator))\n        else:\n            query_request = QueryRequest()\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            query_request, NamedCacheRequestType.QueryEntries\n        )\n\n        return StreamingDispatcher(\n            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)\n        )\n\n    def page_request(self, keys_only: bool = False, values_only: bool = False) -> PagingDispatcher[T]:\n        \"\"\"\n        Creates a gRPC PageRequest.\n\n        :param keys_only: flag indicating interest in only keys\n        :param values_only: flag indicating interest in only values\n        :return: a new PageRequest\n        \"\"\"\n        if keys_only and values_only:\n            raise ValueError(\"keys_only and values_only cannot be True at the same time\")\n\n        if keys_only:\n            return PagingDispatcher(\n                self._page_of_keys_creator(None),\n                self._page_of_keys_creator,\n                BytesValueTransformer(self._serializer),  # type: ignore\n            )\n        elif values_only:\n            return PagingDispatcher(\n                self._page_of_entries_creator(None), self._page_of_entries_creator, ValueTransformer(self._serializer)\n            )\n        else:\n            return PagingDispatcher(\n                self._page_of_entries_creator(None),\n                self._page_of_entries_creator,\n                KeyValueTransformer(self._serializer),  # type: ignore\n            )\n\n    def _page_of_keys_creator(self, cookie: Optional[bytes]) -> ProxyRequest:\n        if cookie is None:\n            cookie_bytes = BytesValue()\n        else:\n            cookie_bytes = BytesValue(value=cookie)\n\n        return self.create_proxy_request(\n            self._create_named_cache_request(cookie_bytes, NamedCacheRequestType.PageOfKeys)\n        )\n\n    def _page_of_entries_creator(self, cookie: Optional[bytes]) -> ProxyRequest:\n        if cookie is None:\n            cookie_bytes = BytesValue()\n        else:\n            cookie_bytes = BytesValue(value=cookie)\n\n        return self.create_proxy_request(\n            self._create_named_cache_request(cookie_bytes, NamedCacheRequestType.PageOfEntries)\n        )\n\n    def map_listener_request(\n        self,\n        subscribe: bool,\n        lite: bool = False,\n        *,\n        key: Optional[K] = None,\n        filter: Optional[Filter] = None,\n        filter_id: int = -1,\n    ) -> Tuple[UnaryDispatcher[Any], ProxyRequest, int]:\n        \"\"\"Creates a gRPC generated MapListenerRequest\"\"\"\n\n        if key is None and filter is None:\n            raise AssertionError(\"Must specify a key or a filter\")\n\n        if key is None:  # registering a Filter listener\n            filter_local: Filter = filter if filter is not None else Filters.always()\n            if not isinstance(filter_local, MapEventFilter):\n                # noinspection PyUnresolvedReferences\n                filter_local = MapEventFilter.from_filter(filter_local)\n            listener_request: V1MapListenerRequest = V1MapListenerRequest(\n                subscribe=subscribe,\n                lite=lite,\n                priming=False,\n                filterId=RequestIdGenerator.next() if filter_id == -1 else filter_id,\n                keyOrFilter=KeyOrFilter(filter=self._serializer.serialize(filter_local)),\n            )\n        else:  # registering a key listener\n            listener_request = V1MapListenerRequest(\n                subscribe=subscribe,\n                lite=lite,\n                priming=False,\n                keyOrFilter=KeyOrFilter(key=self._serializer.serialize(key)),\n            )\n\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            listener_request, NamedCacheRequestType.MapListener\n        )\n        proxy_request: ProxyRequest = self.create_proxy_request(named_cache_request)\n\n        return (\n            UnaryDispatcher(proxy_request),\n            proxy_request,\n            listener_request.filterId,\n        )\n\n    def add_index_request(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> Dispatcher:\n        if comparator is None:\n            named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n                IndexRequest(add=True, extractor=self._serializer.serialize(extractor), sorted=ordered),\n                NamedCacheRequestType.Index,\n            )\n        else:\n            named_cache_request = self._create_named_cache_request(\n                IndexRequest(\n                    add=True,\n                    extractor=self._serializer.serialize(extractor),\n                    sorted=ordered,\n                    comparator=self._serializer.serialize(extractor),\n                ),\n                NamedCacheRequestType.Index,\n            )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request))\n\n    def remove_index_request(self, extractor: ValueExtractor[T, E]) -> Dispatcher:\n        named_cache_request: NamedCacheRequest = self._create_named_cache_request(\n            IndexRequest(\n                add=False,\n                extractor=self._serializer.serialize(extractor),\n            ),\n            NamedCacheRequestType.Index,\n        )\n\n        return UnaryDispatcher(self.create_proxy_request(named_cache_request))\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/util.py b/src/coherence/util.py
--- a/src/coherence/util.py	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/src/coherence/util.py	(date 1729005829598)
@@ -80,6 +80,11 @@
 
 
 class Dispatcher(ABC):
+
+    def __init__(self, timeout: float):
+        super().__init__()
+        self._timeout: float = timeout
+
     @abstractmethod
     async def dispatch(self, stream_handler: Any) -> None:
         pass
@@ -213,8 +218,9 @@
 
 
 class UnaryDispatcher(ResponseObserver, Dispatcher, ScalarResultProducer[T]):
-    def __init__(self, request: ProxyRequest, transformer: Optional[ResponseTransformer[T]] = None):
-        super().__init__(request)
+    def __init__(self, timeout: float, request: ProxyRequest, transformer: Optional[ResponseTransformer[T]] = None):
+        ResponseObserver.__init__(self, request)
+        Dispatcher.__init__(self, timeout)
         self._waiter = Event()
         self._transformer = transformer
         self._result: T
@@ -243,7 +249,7 @@
 
 
 class StreamingDispatcher(ResponseObserver, Dispatcher, AsyncIterator[T]):
-    def __init__(self, request: ProxyRequest, transformer: ResponseTransformer[T]):
+    def __init__(self, timeout: float, request: ProxyRequest, transformer: ResponseTransformer[T]):
         super().__init__(request)
         self._transformer = transformer
 
@@ -282,6 +288,7 @@
 class PagingDispatcher(ResponseObserver, Dispatcher, AsyncIterator[T]):
     def __init__(
         self,
+        timeout: float,
         request: ProxyRequest,
         request_creator: Callable[[bytes], ProxyRequest],
         transformer: ResponseTransformer[T],
@@ -708,10 +715,11 @@
 
 class RequestFactoryV1:
 
-    def __init__(self, cache_name: str, cache_id: int, scope: str, serializer: Serializer) -> None:
+    def __init__(self, cache_name: str, cache_id: int, scope: str, serializer: Serializer, timeout: Callable[[], float]) -> None:
         self._cache_name: str = cache_name
         self._cache_id: int = cache_id
         self._scope: str = scope
+        self._timeout: Callable[[], float] = timeout
         self._serializer: Serializer = serializer
 
     @property
@@ -722,6 +730,10 @@
     def cache_id(self, value: int) -> None:
         self._cache_id = value
 
+    @property
+    def request_timeout(self) -> float:
+        return self._timeout()
+
     def get_serializer(self) -> Serializer:
         return self._serializer
 
@@ -775,7 +787,7 @@
             type=NamedCacheRequestType.EnsureCache,
             message=any_cache_request,
         )
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), CacheIdTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), CacheIdTransformer(self._serializer))
 
     def put_request(self, key: K, value: V, ttl: int = 0) -> UnaryDispatcher[Optional[V]]:
         request: NamedCacheRequest = self._create_named_cache_request(
@@ -787,14 +799,14 @@
             NamedCacheRequestType.Put,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(request), OptionalValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(request), OptionalValueTransformer(self._serializer))
 
     def get_request(self, key: K) -> UnaryDispatcher[Optional[V]]:
         request: NamedCacheRequest = self._create_named_cache_request(
             BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Get
         )
 
-        return UnaryDispatcher(self.create_proxy_request(request), OptionalValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(request), OptionalValueTransformer(self._serializer))
 
     def get_all_request(self, keys: set[K]) -> StreamingDispatcher[MapEntry[K, V]]:
         if keys is None:
@@ -808,7 +820,7 @@
         )
 
         return StreamingDispatcher(
-            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
+            self.request_timeout, self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
         )
 
     def put_if_absent_request(self, key: K, value: V, ttl: int = 0) -> UnaryDispatcher[Optional[V]]:
@@ -821,7 +833,7 @@
             NamedCacheRequestType.PutIfAbsent,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(request), BytesValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(request), BytesValueTransformer(self._serializer))
 
     def put_all_request(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> Dispatcher:
         request: NamedCacheRequest = self._create_named_cache_request(
@@ -835,14 +847,14 @@
             NamedCacheRequestType.PutAll,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(request))
 
     def clear_request(self) -> Dispatcher:
         named_cache_request = NamedCacheRequest(
             type=NamedCacheRequestType.Clear,
             cacheId=self.cache_id,
         )
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request))
 
     def destroy_request(self) -> Dispatcher:
         named_cache_request: NamedCacheRequest = NamedCacheRequest(
@@ -850,21 +862,21 @@
             cacheId=self.cache_id,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request))
 
     def truncate_request(self) -> Dispatcher:
         named_cache_request: NamedCacheRequest = NamedCacheRequest(
             type=NamedCacheRequestType.Truncate,
             cacheId=self.cache_id,
         )
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request))
 
     def remove_request(self, key: K) -> UnaryDispatcher[Optional[V]]:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
             BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.Remove
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
 
     def remove_mapping_request(self, key: K, value: V) -> UnaryDispatcher[bool]:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
@@ -872,7 +884,7 @@
             NamedCacheRequestType.RemoveMapping,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
 
     def replace_request(self, key: K, value: V) -> UnaryDispatcher[Optional[V]]:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
@@ -880,7 +892,7 @@
             NamedCacheRequestType.Replace,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
 
     def replace_mapping_request(self, key: K, old_value: V, new_value: V) -> UnaryDispatcher[bool]:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
@@ -892,21 +904,21 @@
             NamedCacheRequestType.ReplaceMapping,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
 
     def contains_key_request(self, key: K) -> UnaryDispatcher[bool]:
         named_cache_request = self._create_named_cache_request(
             BytesValue(value=self._serializer.serialize(key)), NamedCacheRequestType.ContainsKey
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
 
     def contains_value_request(self, value: V) -> UnaryDispatcher[bool]:
         named_cache_request = self._create_named_cache_request(
             BytesValue(value=self._serializer.serialize(value)), NamedCacheRequestType.ContainsValue
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
 
     def is_empty_request(self) -> UnaryDispatcher[bool]:
         named_cache_request = NamedCacheRequest(
@@ -914,7 +926,7 @@
             cacheId=self.cache_id,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BoolValueTransformer(self._serializer))
 
     def size_request(self) -> UnaryDispatcher[int]:
         named_cache_request = NamedCacheRequest(
@@ -922,7 +934,7 @@
             cacheId=self.cache_id,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), IntValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), IntValueTransformer(self._serializer))
 
     def invoke_request(self, key: K, processor: EntryProcessor[R]) -> UnaryDispatcher[Optional[R]]:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
@@ -935,7 +947,7 @@
             NamedCacheRequestType.Invoke,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), ValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), ValueTransformer(self._serializer))
 
     def invoke_all_request(
         self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None
@@ -969,7 +981,7 @@
         )
 
         return StreamingDispatcher(
-            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
+            self.request_timeout, self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
         )
 
     def aggregate_request(
@@ -1002,7 +1014,7 @@
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
             cache_request, NamedCacheRequestType.Aggregate
         )
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer))
 
     def values_request(
         self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None
@@ -1022,7 +1034,7 @@
         )
 
         return StreamingDispatcher(
-            self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore
+            self.request_timeout, self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore
         )
 
     def keys_request(self, filter: Optional[Filter] = None) -> StreamingDispatcher[K]:
@@ -1037,7 +1049,7 @@
         )
 
         return StreamingDispatcher(
-            self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore
+            self.request_timeout, self.create_proxy_request(named_cache_request), BytesValueTransformer(self._serializer)  # type: ignore
         )
 
     def entries_request(
@@ -1058,7 +1070,7 @@
         )
 
         return StreamingDispatcher(
-            self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
+            self.request_timeout, self.create_proxy_request(named_cache_request), KeyValueTransformer(self._serializer)
         )
 
     def page_request(self, keys_only: bool = False, values_only: bool = False) -> PagingDispatcher[T]:
@@ -1074,16 +1086,18 @@
 
         if keys_only:
             return PagingDispatcher(
+                self.request_timeout,
                 self._page_of_keys_creator(None),
                 self._page_of_keys_creator,
                 BytesValueTransformer(self._serializer),  # type: ignore
             )
         elif values_only:
             return PagingDispatcher(
-                self._page_of_entries_creator(None), self._page_of_entries_creator, ValueTransformer(self._serializer)
+                self.request_timeout, self._page_of_entries_creator(None), self._page_of_entries_creator, ValueTransformer(self._serializer)
             )
         else:
             return PagingDispatcher(
+                self.request_timeout,
                 self._page_of_entries_creator(None),
                 self._page_of_entries_creator,
                 KeyValueTransformer(self._serializer),  # type: ignore
@@ -1149,7 +1163,7 @@
         proxy_request: ProxyRequest = self.create_proxy_request(named_cache_request)
 
         return (
-            UnaryDispatcher(proxy_request),
+            UnaryDispatcher(self.request_timeout, proxy_request),
             proxy_request,
             listener_request.filterId,
         )
@@ -1173,7 +1187,7 @@
                 NamedCacheRequestType.Index,
             )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request))
 
     def remove_index_request(self, extractor: ValueExtractor[T, E]) -> Dispatcher:
         named_cache_request: NamedCacheRequest = self._create_named_cache_request(
@@ -1184,4 +1198,4 @@
             NamedCacheRequestType.Index,
         )
 
-        return UnaryDispatcher(self.create_proxy_request(named_cache_request))
+        return UnaryDispatcher(self.request_timeout, self.create_proxy_request(named_cache_request))
Index: src/coherence/client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022, 2024, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n\nfrom __future__ import annotations\n\nimport abc\nimport asyncio\nimport logging\nimport os\nimport time\nimport uuid\nfrom asyncio import Condition, Event, Task\nfrom threading import Lock\nfrom typing import (\n    Any,\n    AsyncIterator,\n    Awaitable,\n    Callable,\n    Final,\n    Generic,\n    Literal,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    TypeVar,\n    cast,\n    no_type_check,\n)\n\n# noinspection PyPackageRequirements\nimport grpc\nfrom grpc.aio import Channel, StreamStreamMultiCallable\nfrom pymitter import EventEmitter\n\nfrom .aggregator import AverageAggregator, EntryAggregator, PriorityAggregator, SumAggregator\nfrom .cache_service_messages_v1_pb2 import MapEventMessage, NamedCacheResponse, ResponseType\nfrom .comparator import Comparator\nfrom .entry import MapEntry\nfrom .event import (\n    MapEvent,\n    MapLifecycleEvent,\n    MapListener,\n    SessionLifecycleEvent,\n    _ListenerGroup,\n    _MapEventsManagerV0,\n    _MapEventsManagerV1,\n)\nfrom .extractor import ValueExtractor\nfrom .filter import Filter\nfrom .messages_pb2 import PageRequest\nfrom .processor import EntryProcessor\nfrom .proxy_service_messages_v1_pb2 import ProxyRequest, ProxyResponse\nfrom .proxy_service_v1_pb2_grpc import ProxyServiceStub\nfrom .serialization import Serializer, SerializerRegistry\nfrom .services_pb2_grpc import NamedCacheServiceStub\nfrom .util import (\n    Dispatcher,\n    Error,\n    PagingDispatcher,\n    RequestFactory,\n    RequestFactoryV1,\n    ResponseObserver,\n    StreamingDispatcher,\n    UnaryDispatcher,\n)\n\nE = TypeVar(\"E\")\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\nR = TypeVar(\"R\")\nT = TypeVar(\"T\")\n\nCOH_LOG = logging.getLogger(\"coherence\")\n\n\n# noinspection PyUnresolvedReferences,PyProtectedMember\nclass _Handshake:\n    def __init__(self, session: Session):\n        self._protocol_version: int = 0\n        self._proxy_version: str = \"unknown\"\n        self._proxy_member_id: int = 0\n        self._session = session\n        self._channel: Channel = session.channel\n        self._stream: Optional[StreamStreamMultiCallable] = None\n\n    async def handshake(self) -> None:\n        stub: ProxyServiceStub = ProxyServiceStub(self._channel)\n        stream: StreamStreamMultiCallable = stub.subChannel()\n        try:\n            await stream.write(RequestFactoryV1.init_sub_channel())\n            response = await stream.read()\n            stream.cancel()  # cancel the stream; no longer needed\n            self._proxy_version = response.init.version\n            self._protocol_version = response.init.protocolVersion\n            self._proxy_member_id = response.init.proxyMemberId\n        except grpc.aio._call.AioRpcError as e:\n            error_code: int = e.code().value[0]\n            if (\n                error_code == grpc.StatusCode.UNIMPLEMENTED.value[0]\n                or error_code\n                == grpc.StatusCode.INTERNAL.value[0]  # work around for grpc https://github.com/grpc/grpc/issues/36066\n            ):\n                pass\n            else:\n                raise RuntimeError(\"Unknown error attempting to handshake with proxy: \" + str(e))\n\n    @property\n    def protocol_version(self) -> int:\n        return self._protocol_version\n\n    @property\n    def proxy_version(self) -> str:\n        return self._proxy_version\n\n    @property\n    def proxy_member_id(self) -> int:\n        return self._proxy_member_id\n\n\n@no_type_check\ndef _pre_call_cache(func):\n    def inner(self, *args, **kwargs):\n        if not self.active:\n            raise RuntimeError(\"Cache [] has been \" + \"released\" if self.released else \"destroyed\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if not self.active:\n            raise RuntimeError(\n                \"Cache [{}] has been {}.\".format(self.name, \"released\" if self.released else \"destroyed\")\n            )\n\n        # noinspection PyProtectedMember\n        await self._session._wait_for_ready()\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\n@no_type_check\ndef _pre_call_session(func):\n    def inner(self, *args, **kwargs):\n        if self._closed:\n            raise RuntimeError(\"Session has been closed.\")\n\n        return func(self, *args, **kwargs)\n\n    async def inner_async(self, *args, **kwargs):\n        if self._closed:\n            raise RuntimeError(\"Session has been closed.\")\n\n        return await func(self, *args, **kwargs)\n\n    if asyncio.iscoroutinefunction(func):\n        return inner_async\n    return inner\n\n\nclass NamedMap(abc.ABC, Generic[K, V]):\n    # noinspection PyUnresolvedReferences\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored persistently, on disk.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"documentation\"\"\"\n\n    @abc.abstractmethod\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        \"\"\"\n        Add a callback that will be invoked when the specified MapLifecycleEvent is raised.\n        :param event:     the MapLifecycleEvent to listen for\n        :param callback:  the callback that will be invoked when the event occurs\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def destroyed(self) -> bool:\n        pass\n\n    @property\n    @abc.abstractmethod\n    def released(self) -> bool:\n        pass\n\n    @property\n    def active(self) -> bool:\n        return not self.released and not self.destroyed\n\n    @abc.abstractmethod\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        \"\"\"\n        Add a MapListener that will receive events (inserts, updates, deletes) that occur\n        against the map, with the key, old-value and new-value included.\n\n        :param listener:      the MapListener to register\n        :param listener_for:  the optional key that identifies the entry for which to raise events or a Filter\n         that will be passed MapEvent objects to select from; a MapEvent will be delivered to the listener only if the\n         filter evaluates to `True` for that MapEvent. `None` is equivalent to a Filter that always returns `True`\n        :param lite:          optionally pass `True` to indicate that the MapEvent objects do not have to include the\n         old or new values in order to allow optimizations\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        \"\"\"\n        Remove a standard map listener that previously registered to receive events.\n        :param listener:      the MapListener to be removed\n        :param listener_for:  the key or filter, if any, passed to a previous addMapListener invocation\n        :raises ValueError: if `listener` is `None`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get(self, key: K) -> Optional[V]:\n        \"\"\"\n        Returns the value to which this cache maps the specified key.\n\n        :param key: the key whose associated value is to be returned\n\n        :Example:\n\n         >>> import asyncio\n         >>> from typing import Any, AsyncGenerator, Optional, TypeVar\n         >>> from coherence import NamedCache, Session\n         >>> K = TypeVar(\"K\")\n         >>> V = TypeVar(\"V\")\n         >>> R = TypeVar(\"R\")\n         >>> session: Session = Session(None)\n         >>> cache: NamedCache[Any, Any] = await session.get_cache(\"test\")\n         >>> k: str = \"one\"\n         >>> v: str = \"only-one\"\n         >>> await cache.put(k, v)\n         >>> r = await cache.get(k)\n         >>> print(r)\n         only-one\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        \"\"\"\n        Returns the value to which the specified key is mapped, or the specified `defaultValue`\n        if this map contains no mapping for the key.\n\n        :param key: the key whose associated value is to be returned\n        :param default_value: defaultValue if this map contains no mapping for the key.\n        :return: value for the key in the map or the `defaultValue`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Get all the specified keys if they are in the map. For each key that is in the map,\n        that key and its corresponding value will be placed in the map that is returned by\n        this method. The absence of a key in the returned map indicates that it was not in the cache,\n        which may imply (for caches that can load behind the scenes) that the requested data\n        could not be loaded.\n\n        :param keys: an Iterable of keys that may be in this map\n        :return: an AsyncIterator of MapEntry instances for the specified keys passed in `keys`\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V) -> Optional[V]:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the\n        map previously contained a mapping for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None`\n         if there was no mapping for key. A `None` return can also indicate\n         that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V) -> Optional[V]:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to `None`) associates\n        it with the given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :return: the previous value associated with the specified key, or `None` if there was no mapping for key. A\n         `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_all(self, map: dict[K, V], ttl: Optional[int] = 0) -> None:\n        \"\"\"\n        Copies all mappings from the specified map to this map\n\n        :param map: the map to copy from\n        :param ttl: the time to live for the map entries\n        \"\"\"\n\n    @abc.abstractmethod\n    async def clear(self) -> None:\n        \"\"\"\n        Clears all the mappings in the 'NamedMap'.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def destroy(self) -> None:\n        \"\"\"\n        Release and destroy this cache.\n\n        Warning: This method is used to completely destroy the specified cache\n        across the cluster. All references in the entire cluster to this cache\n        will be invalidated, the cached data will be cleared, and all resources\n        will be released.\n        \"\"\"\n\n    @abc.abstractmethod\n    async def release(self) -> None:\n        \"\"\"\n        Release local resources associated with instance.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def truncate(self) -> None:\n        \"\"\"\n        Truncates the cache.  Unlike :func:`coherence.client.NamedMap.clear()`, this function does not generate an\n        event for each removed entry.\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove(self, key: K) -> Optional[V]:\n        \"\"\"\n        Removes the mapping for a key from this map if it is present.\n\n        :param key: key whose mapping is to be removed from the map\n        :return: the previous value associated with key, or `None` if there was no mapping for key\n        \"\"\"\n\n    @abc.abstractmethod\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        \"\"\"\n        Removes the entry for the specified key only if it is currently mapped to the specified value.\n\n        :param key: key with which the specified value is associated\n        :param value: expected to be associated with the specified key\n        :return: resolving to true if the value was removed\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace(self, key: K, value: V) -> Optional[V]:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key: key whose associated value is to be replaced\n        :param value: value expected to be associated with the specified key\n        :return: resolving to the previous value associated with the specified key, or `None` if there was no mapping\n         for the key. (A `None` return can also indicate that the map previously associated `None` with the key\n         if the implementation supports `None` values.)\n        \"\"\"\n\n    @abc.abstractmethod\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        \"\"\"\n        Replaces the entry for the specified key only if currently mapped to the specified value.\n\n        :param key:         key whose associated value is to be removed\n        :param old_value:   value expected to be associated with the specified key\n        :param new_value:   value to be associated with the specified key\n        :return: resolving to `true` if the value was replaced\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_key(self, key: K) -> bool:\n        \"\"\"\n        Returns `true` if the specified key is mapped a value within the cache.\n\n        :param key: the key whose presence in this cache is to be tested\n        :return: resolving to `true` if the key is mapped to a value, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def contains_value(self, value: V) -> bool:\n        \"\"\"\n        Returns `true` if the specified value is mapped to some key.\n\n        :param value: the value expected to be associated with some key\n        :return: resolving to `true` if a mapping exists, or `false` if it does not\n        \"\"\"\n\n    @abc.abstractmethod\n    async def is_empty(self) -> bool:\n        \"\"\"\n        Returns `true` if this map contains no key-value mappings.\n\n        :return: `true` if this map contains no key-value mappings.\n        \"\"\"\n\n    @abc.abstractmethod\n    async def size(self) -> int:\n        \"\"\"\n        Signifies the number of key-value mappings in this map.\n\n        :return: the number of key-value mappings in this map\n        \"\"\"\n\n    @abc.abstractmethod\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:\n        \"\"\"\n        Invoke the passed EntryProcessor against the Entry specified by the\n        passed key, returning the result of the invocation.\n\n        :param key: the key to process - it is not required to exist within the Map\n        :param processor: the EntryProcessor to use to process the specified key\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        \"\"\"\n        Invoke the passed EntryProcessor against the set of entries that are selected by the given Filter,\n        returning the result of the invocation for each.\n\n        Unless specified otherwise, implementations will perform this operation in two steps:\n            1. use the filter to retrieve a matching entry set\n            2. apply the agent to every filtered entry.\n\n        This algorithm assumes that the agent's processing does not affect the result of the specified filter\n        evaluation, since the filtering and processing could be performed in parallel on different threads. If this\n        assumption does not hold, the processor logic has to be idempotent, or at least re-evaluate the filter. This\n        could be easily accomplished by wrapping the processor with the ConditionalProcessor.\n\n        :param processor: the EntryProcessor to use to process the specified keys\n        :param keys: the keys to process these keys are not required to exist within the Map\n        :param filter: a Filter that results in the set of keys to be processed\n        :return: an AsyncIterator of MapEntry instances containing the results of invoking the EntryProcessor against\n         each of the specified keys\n        \"\"\"\n\n    @abc.abstractmethod\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Perform an aggregating operation against the entries specified by the passed keys.\n\n        :param aggregator: the EntryAggregator that is used to aggregate across the specified entries of this Map\n        :param keys: the Iterable of keys that specify the entries within this Map to aggregate across\n        :param filter: the Filter that is used to select entries within this Map to aggregate across\n        :return: the result of the invocation as returned from the EntryProcessor\n        \"\"\"\n\n    @abc.abstractmethod\n    async def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        \"\"\"\n        Return a Set of the values contained in this map that satisfy the criteria expressed by the filter.\n        If no filter or comparator is specified, it returns a Set view of the values contained in this map.The\n        collection is backed by the map, so changes to the map are reflected in the collection, and vice versa. If\n        the map is modified while an iteration over the collection is in progress (except through the iterator's own\n        `remove` operation), the results of the iteration are undefined.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator:  the Comparator object which imposes an ordering on entries in the resulting set; or null\n         if the entries' natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances resolving to the values that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    async def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        \"\"\"\n        Return a set view of the keys contained in this map for entries that satisfy the criteria expressed by the\n        filter.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter is provided.\n        :return: an AsyncIterator of keys for entries that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    async def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        \"\"\"\n        Return a set view of the entries contained in this map that satisfy the criteria expressed by the filter.\n        Each element in the returned set is a :class:`coherence.client.MapEntry`.\n\n        :param filter: the Filter object representing the criteria that the entries of this map should satisfy\n        :param comparator: the Comparator object which imposes an ordering on entries in the resulting set; or `None`\n         if the entries' values natural ordering should be used\n        :param by_page: returns the keys in pages (transparently to the caller).  This option is only valid\n         if no filter or comparator is provided.\n        :return: an AsyncIterator of MapEntry instances that satisfy the specified criteria\n        \"\"\"\n\n    @abc.abstractmethod\n    def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        \"\"\"\n        Add an index to this map.\n\n        :param extractor: The :class:`coherence.extractor.ValueExtractor` object that is used to extract\n                   an indexable Object from a value stored in the\n                   indexed Map. Must not be 'None'.\n        :param ordered: true if the contents of the indexed information\n                   should be ordered false otherwise.\n        :param comparator: The :class:`coherence.comparator.Comparator` object which imposes an ordering\n                   on entries in the indexed map or None if the\n                   entries' values natural ordering should be used.\n        \"\"\"\n\n    @abc.abstractmethod\n    def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        \"\"\"\n        Removes an index on this `NamedMap`.\n\n        :param extractor: The :class:`coherence.extractor.ValueExtractor` object that is used to extract\n                  an indexable Object from a value stored in the\n                  indexed Map. Must not be 'None'.\n\n        \"\"\"\n\n\nclass NamedCache(NamedMap[K, V]):\n    # noinspection PyUnresolvedReferences\n    \"\"\"\n    A Map-based data-structure that manages entries across one or more processes. Entries are typically managed in\n    memory, and are often comprised of data that is also stored in an external system, for example, a database,\n    or data that has been assembled or calculated at some significant cost.  Such entries are referred to as being\n    `cached`.\n\n    :param K:  the type of the map entry keys\n    :param V:  the type of the map entry values\n    \"\"\"\n\n    @abc.abstractmethod\n    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        \"\"\"\n        Associates the specified value with the specified key in this map. If the map previously contained a mapping\n        for this key, the old value is replaced.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n    @abc.abstractmethod\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        \"\"\"\n        If the specified key is not already associated with a value (or is mapped to null) associates it with the\n        given value and returns `None`, else returns the current value.\n\n        :param key: the key with which the specified value is to be associated\n        :param value: the value to be associated with the specified key\n        :param ttl: the expiry time in millis (optional)\n        :return: resolving to the previous value associated with specified key, or `None` if there was no mapping for\n         key. A `None` return can also indicate that the map previously associated `None` with the specified key\n         if the implementation supports `None` values\n\n        \"\"\"\n\n\nclass NamedCacheClient(NamedCache[K, V]):\n    def __init__(self, cache_name: str, session: Session, serializer: Serializer):\n        self._cache_name: str = cache_name\n        self._serializer: Serializer = serializer\n        self._client_stub: NamedCacheServiceStub = NamedCacheServiceStub(session.channel)\n        self._request_factory: RequestFactory = RequestFactory(cache_name, session.scope, serializer)\n        self._emitter: EventEmitter = EventEmitter()\n        self._internal_emitter: EventEmitter = EventEmitter()\n        self._destroyed: bool = False\n        self._released: bool = False\n        self._session: Session = session\n\n        self._setup_event_handlers()\n\n        self._events_manager: _MapEventsManagerV0[K, V] = _MapEventsManagerV0(\n            self, session, self._client_stub, serializer, self._internal_emitter\n        )\n\n    @property\n    def name(self) -> str:\n        return self._cache_name\n\n    @property\n    def destroyed(self) -> bool:\n        return self._destroyed\n\n    @property\n    def released(self) -> bool:\n        return self._released\n\n    @_pre_call_cache\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        self._emitter.on(str(event.value), callback)\n\n    @_pre_call_cache\n    async def get(self, key: K) -> Optional[V]:\n        g = self._request_factory.get_request(key)\n        v = await self._client_stub.get(g)\n        if v.present:\n            return self._request_factory.get_serializer().deserialize(v.value)\n        else:\n            return None\n\n    @_pre_call_cache\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        v: Optional[V] = await self.get(key)\n        if v is not None:\n            return v\n        else:\n            return default_value\n\n    @_pre_call_cache\n    async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        r = self._request_factory.get_all_request(keys)\n        stream = self._client_stub.getAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        p = self._request_factory.put_request(key, value, ttl)\n        v = await self._client_stub.put(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        p = self._request_factory.put_if_absent_request(key, value, ttl)\n        v = await self._client_stub.putIfAbsent(p)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def put_all(self, map: dict[K, V]) -> None:\n        p = self._request_factory.put_all_request(map)\n        await self._client_stub.putAll(p)\n\n    @_pre_call_cache\n    async def clear(self) -> None:\n        r = self._request_factory.clear_request()\n        await self._client_stub.clear(r)\n\n    async def destroy(self) -> None:\n        await self.release()\n        self._internal_emitter.once(MapLifecycleEvent.DESTROYED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.DESTROYED.value, self.name)\n        r = self._request_factory.destroy_request()\n        await self._client_stub.destroy(r)\n\n    async def release(self) -> None:\n        if self.active:\n            self._internal_emitter.once(MapLifecycleEvent.RELEASED.value)\n            self._internal_emitter.emit(MapLifecycleEvent.RELEASED.value, self.name)\n\n    @_pre_call_cache\n    async def truncate(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.TRUNCATED.value)\n        r = self._request_factory.truncate_request()\n        await self._client_stub.truncate(r)\n\n    @_pre_call_cache\n    async def remove(self, key: K) -> Optional[V]:\n        r = self._request_factory.remove_request(key)\n        v = await self._client_stub.remove(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        r = self._request_factory.remove_mapping_request(key, value)\n        v = await self._client_stub.removeMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace(self, key: K, value: V) -> Optional[V]:\n        r = self._request_factory.replace_request(key, value)\n        v = await self._client_stub.replace(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        r = self._request_factory.replace_mapping_request(key, old_value, new_value)\n        v = await self._client_stub.replaceMapping(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_key(self, key: K) -> bool:\n        r = self._request_factory.contains_key_request(key)\n        v = await self._client_stub.containsKey(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def contains_value(self, value: V) -> bool:\n        r = self._request_factory.contains_value_request(value)\n        v = await self._client_stub.containsValue(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def is_empty(self) -> bool:\n        r = self._request_factory.is_empty_request()\n        v = await self._client_stub.isEmpty(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def size(self) -> int:\n        r = self._request_factory.size_request()\n        v = await self._client_stub.size(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:\n        r = self._request_factory.invoke_request(key, processor)\n        v = await self._client_stub.invoke(r)\n        return self._request_factory.get_serializer().deserialize(v.value)\n\n    @_pre_call_cache\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        r = self._request_factory.invoke_all_request(processor, keys, filter)\n        stream = self._client_stub.invokeAll(r)\n\n        return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    @_pre_call_cache\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> Optional[R]:\n        r = self._request_factory.aggregate_request(aggregator, keys, filter)\n        results = await self._client_stub.aggregate(r)\n        value: Any = self._request_factory.get_serializer().deserialize(results.value)\n        # for compatibility with 22.06\n        if isinstance(aggregator, SumAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, AverageAggregator) and isinstance(value, str):\n            return cast(R, float(value))\n        elif isinstance(aggregator, PriorityAggregator):\n            # noinspection PyTypeChecker,PyUnresolvedReferences\n            pri_agg: PriorityAggregator[R] = aggregator\n            if (\n                isinstance(pri_agg.aggregator, AverageAggregator) or isinstance(pri_agg.aggregator, SumAggregator)\n            ) and isinstance(value, str):\n                return cast(R, float(value))\n        # end compatibility with 22.06\n\n        return cast(R, value)\n\n    @_pre_call_cache\n    async def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _scalar_deserializer)\n        else:\n            r = self._request_factory.values_request(filter)\n            stream = self._client_stub.values(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    async def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        if by_page and filter is None:\n            return _PagedStream(self, _scalar_deserializer, True)\n        else:\n            r = self._request_factory.keys_request(filter)\n            stream = self._client_stub.keySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _scalar_producer)\n\n    @_pre_call_cache\n    async def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        if by_page and comparator is None and filter is None:\n            return _PagedStream(self, _entry_deserializer)\n        else:\n            r = self._request_factory.entries_request(filter, comparator)\n            stream = self._client_stub.entrySet(r)\n\n            return _Stream(self._request_factory.get_serializer(), stream, _entry_producer)\n\n    from .event import MapListener\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._register_filter_listener(listener, listener_for, lite)\n        else:\n            await self._events_manager._register_key_listener(listener, listener_for, lite)\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._remove_filter_listener(listener, listener_for)\n        else:\n            await self._events_manager._remove_key_listener(listener, listener_for)\n\n    @_pre_call_cache\n    async def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n        r = self._request_factory.add_index_request(extractor, ordered, comparator)\n        await self._client_stub.addIndex(r)\n\n    @_pre_call_cache\n    async def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n        r = self._request_factory.remove_index_request(extractor)\n        await self._client_stub.removeIndex(r)\n\n    def _setup_event_handlers(self) -> None:\n        \"\"\"\n        Setup handlers to notify cache-level handlers of events.\n        \"\"\"\n        emitter: EventEmitter = self._emitter\n        internal_emitter: EventEmitter = self._internal_emitter\n        this: NamedCacheClient[K, V] = self\n        cache_name = self._cache_name\n\n        # noinspection PyProtectedMember\n        def on_destroyed(name: str) -> None:\n            if name == cache_name and not this.destroyed:\n                this._events_manager._close()\n                this._destroyed = True\n                emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        # noinspection PyProtectedMember\n        def on_released(name: str) -> None:\n            if name == cache_name and not this.released:\n                this._events_manager._close()\n                this._released = True\n                emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        def on_truncated(name: str) -> None:\n            if name == cache_name:\n                emitter.emit(MapLifecycleEvent.TRUNCATED.value, name)\n\n        internal_emitter.on(MapLifecycleEvent.DESTROYED.value, on_destroyed)\n        internal_emitter.on(MapLifecycleEvent.RELEASED.value, on_released)\n        internal_emitter.on(MapLifecycleEvent.TRUNCATED.value, on_truncated)\n\n    def __str__(self) -> str:\n        return (\n            f\"NamedCache(name={self.name}, session={self._session.session_id}, serializer={self._serializer},\"\n            f\" released={self.released}, destroyed={self.destroyed})\"\n        )\n\n\nclass NamedCacheClientV1(NamedCache[K, V]):\n\n    def __init__(self, cache_name: str, session: Session, serializer: Serializer):\n        self._cache_name: str = cache_name\n        self._cache_id: int = 0\n        self._serializer: Serializer = serializer\n        self._request_factory: RequestFactoryV1 = RequestFactoryV1(\n            cache_name, self._cache_id, session.scope, serializer\n        )\n        self._emitter: EventEmitter = EventEmitter()\n        self._internal_emitter: EventEmitter = EventEmitter()\n        self._destroyed: bool = False\n        self._released: bool = False\n        self._session: Session = session\n\n        self._events_manager: _MapEventsManagerV1[K, V] = _MapEventsManagerV1(\n            self, session, serializer, self._internal_emitter, self._request_factory\n        )\n\n        self._stream_handler: StreamHandler = StreamHandler(session, self._request_factory, self._events_manager)\n        self._setup_event_handlers()\n\n    def _setup_event_handlers(self) -> None:\n        \"\"\"\n        Setup handlers to notify cache-level handlers of events.\n        \"\"\"\n        emitter: EventEmitter = self._emitter\n        internal_emitter: EventEmitter = self._internal_emitter\n        this: NamedCacheClientV1[K, V] = self\n        cache_name = self._cache_name\n\n        # noinspection PyProtectedMember\n        def on_destroyed(name: str) -> None:\n            if name == cache_name and not this.destroyed:\n                this._events_manager._close()\n                this._destroyed = True\n                this._released = True\n                emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        # noinspection PyProtectedMember\n        def on_released(name: str) -> None:\n            if name == cache_name and not this.released:\n                this._events_manager._close()\n                this._released = True\n                emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        def on_truncated(name: str) -> None:\n            if name == cache_name:\n                emitter.emit(MapLifecycleEvent.TRUNCATED.value, name)\n\n        internal_emitter.on(MapLifecycleEvent.DESTROYED.value, on_destroyed)\n        internal_emitter.on(MapLifecycleEvent.RELEASED.value, on_released)\n        internal_emitter.on(MapLifecycleEvent.TRUNCATED.value, on_truncated)\n\n    @property\n    def cache_id(self) -> int:\n        return self._cache_id\n\n    @cache_id.setter\n    def cache_id(self, cache_id: int) -> None:\n        self._cache_id = cache_id\n\n    @property\n    def name(self) -> str:\n        return self._cache_name\n\n    def on(self, event: MapLifecycleEvent, callback: Callable[[str], None]) -> None:\n        self._emitter.on(str(event.value), callback)\n\n    @property\n    def destroyed(self) -> bool:\n        return self._destroyed\n\n    @property\n    def released(self) -> bool:\n        return self._released\n\n    async def _ensure_cache(self) -> None:\n        dispatcher: UnaryDispatcher[int] = self._request_factory.ensure_request(self._cache_name)\n        await dispatcher.dispatch(self._stream_handler)\n\n        self.cache_id = dispatcher.result()\n        self._request_factory.cache_id = self.cache_id\n\n    @_pre_call_cache\n    async def get(self, key: K) -> Optional[V]:\n        dispatcher: UnaryDispatcher[Optional[V]] = self._request_factory.get_request(key)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def put(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        dispatcher: UnaryDispatcher[Optional[V]] = self._request_factory.put_request(key, value, ttl)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def put_if_absent(self, key: K, value: V, ttl: int = 0) -> Optional[V]:\n        dispatcher: UnaryDispatcher[Optional[V]] = self._request_factory.put_if_absent_request(key, value, ttl)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def add_map_listener(\n        self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None, lite: bool = False\n    ) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._register_filter_listener(listener, listener_for, lite)\n        else:\n            await self._events_manager._register_key_listener(listener, listener_for, lite)\n\n    # noinspection PyProtectedMember\n    @_pre_call_cache\n    async def remove_map_listener(self, listener: MapListener[K, V], listener_for: Optional[K | Filter] = None) -> None:\n        if listener is None:\n            raise ValueError(\"A MapListener must be specified\")\n\n        if listener_for is None or isinstance(listener_for, Filter):\n            await self._events_manager._remove_filter_listener(listener, listener_for)\n        else:\n            await self._events_manager._remove_key_listener(listener, listener_for)\n\n    @_pre_call_cache\n    async def get_or_default(self, key: K, default_value: Optional[V] = None) -> Optional[V]:\n        v: Optional[V] = await self.get(key)\n        if v is not None:\n            return v\n        else:\n            return default_value\n\n    @_pre_call_cache\n    async def get_all(self, keys: set[K]) -> AsyncIterator[MapEntry[K, V]]:\n        dispatcher: StreamingDispatcher[MapEntry[K, V]] = self._request_factory.get_all_request(keys)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher\n\n    @_pre_call_cache\n    async def put_all(self, kv_map: dict[K, V], ttl: Optional[int] = 0) -> None:\n        dispatcher: Dispatcher = self._request_factory.put_all_request(kv_map, ttl)\n        await dispatcher.dispatch(self._stream_handler)\n\n    @_pre_call_cache\n    async def clear(self) -> None:\n        dispatcher: Dispatcher = self._request_factory.clear_request()\n        await dispatcher.dispatch(self._stream_handler)\n\n    async def destroy(self) -> None:\n        self._internal_emitter.once(MapLifecycleEvent.DESTROYED.value)\n        self._internal_emitter.emit(MapLifecycleEvent.DESTROYED.value, self.name)\n        dispatcher: Dispatcher = self._request_factory.destroy_request()\n        await dispatcher.dispatch(self._stream_handler)\n\n    async def release(self) -> None:\n        if self.active:\n            await self._stream_handler.close()\n            self._internal_emitter.once(MapLifecycleEvent.RELEASED.value)\n            self._internal_emitter.emit(MapLifecycleEvent.RELEASED.value, self.name)\n\n    @_pre_call_cache\n    async def truncate(self) -> None:\n        dispatcher: Dispatcher = self._request_factory.truncate_request()\n        await dispatcher.dispatch(self._stream_handler)\n\n    @_pre_call_cache\n    async def remove(self, key: K) -> Optional[V]:\n        dispatcher: UnaryDispatcher[Optional[V]] = self._request_factory.remove_request(key)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def remove_mapping(self, key: K, value: V) -> bool:\n        dispatcher: UnaryDispatcher[bool] = self._request_factory.remove_mapping_request(key, value)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def replace(self, key: K, value: V) -> Optional[V]:\n        dispatcher: UnaryDispatcher[Optional[V]] = self._request_factory.replace_request(key, value)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def replace_mapping(self, key: K, old_value: V, new_value: V) -> bool:\n        dispatcher: UnaryDispatcher[bool] = self._request_factory.replace_mapping_request(key, old_value, new_value)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def contains_key(self, key: K) -> bool:\n        dispatcher: UnaryDispatcher[bool] = self._request_factory.contains_key_request(key)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def contains_value(self, value: V) -> bool:\n        dispatcher: UnaryDispatcher[bool] = self._request_factory.contains_value_request(value)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def is_empty(self) -> bool:\n        dispatcher: UnaryDispatcher[bool] = self._request_factory.is_empty_request()\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def size(self) -> int:\n        dispatcher: UnaryDispatcher[int] = self._request_factory.size_request()\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def invoke(self, key: K, processor: EntryProcessor[R]) -> Optional[R]:\n        dispatcher: UnaryDispatcher[Optional[R]] = self._request_factory.invoke_request(key, processor)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    @_pre_call_cache\n    async def invoke_all(\n        self, processor: EntryProcessor[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> AsyncIterator[MapEntry[K, R]]:\n        dispatcher: StreamingDispatcher[MapEntry[K, R]] = self._request_factory.invoke_all_request(\n            processor, keys, filter\n        )\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher\n\n    @_pre_call_cache\n    async def aggregate(\n        self, aggregator: EntryAggregator[R], keys: Optional[set[K]] = None, filter: Optional[Filter] = None\n    ) -> Optional[R]:\n        dispatcher: UnaryDispatcher[Optional[R]] = self._request_factory.aggregate_request(aggregator, keys, filter)\n        await dispatcher.dispatch(self._stream_handler)\n        return dispatcher.result()\n\n    # TODO\n    @_pre_call_cache\n    async def values(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[V]:\n        if by_page and comparator is None and filter is None:\n            page_dispatcher: PagingDispatcher[V] = self._request_factory.page_request(values_only=True)\n            await page_dispatcher.dispatch(self._stream_handler)\n            return page_dispatcher\n        else:\n            dispatcher: StreamingDispatcher[V] = self._request_factory.values_request(filter, comparator)\n            await dispatcher.dispatch(self._stream_handler)\n            return dispatcher\n\n    # TODO\n    @_pre_call_cache\n    async def keys(self, filter: Optional[Filter] = None, by_page: bool = False) -> AsyncIterator[K]:\n        if by_page and filter is None:\n            page_dispatcher: PagingDispatcher[K] = self._request_factory.page_request(keys_only=True)\n            await page_dispatcher.dispatch(self._stream_handler)\n            return page_dispatcher\n        else:\n            dispatcher: StreamingDispatcher[K] = self._request_factory.keys_request(filter)\n            await dispatcher.dispatch(self._stream_handler)\n            return dispatcher\n\n    # TODO\n    @_pre_call_cache\n    async def entries(\n        self, filter: Optional[Filter] = None, comparator: Optional[Comparator] = None, by_page: bool = False\n    ) -> AsyncIterator[MapEntry[K, V]]:\n        if by_page and comparator is None and filter is None:\n            page_dispatcher: PagingDispatcher[MapEntry[K, V]] = self._request_factory.page_request()\n            await page_dispatcher.dispatch(self._stream_handler)\n            return page_dispatcher\n        else:\n            dispatcher: StreamingDispatcher[MapEntry[K, V]] = self._request_factory.entries_request(filter, comparator)\n            await dispatcher.dispatch(self._stream_handler)\n            return dispatcher\n\n    @_pre_call_cache\n    async def add_index(\n        self, extractor: ValueExtractor[T, E], ordered: bool = False, comparator: Optional[Comparator] = None\n    ) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n\n        dispatcher: Dispatcher = self._request_factory.add_index_request(extractor, ordered, comparator)\n        await dispatcher.dispatch(self._stream_handler)\n\n    @_pre_call_cache\n    async def remove_index(self, extractor: ValueExtractor[T, E]) -> None:\n        if extractor is None:\n            raise ValueError(\"A ValueExtractor must be specified\")\n\n        dispatcher: Dispatcher = self._request_factory.remove_index_request(extractor)\n        await dispatcher.dispatch(self._stream_handler)\n\n\nclass TlsOptions:\n    \"\"\"\n    Options specific to the configuration of TLS.\n    \"\"\"\n\n    ENV_CA_CERT = \"COHERENCE_TLS_CERTS_PATH\"\n    \"\"\"\n    Environment variable to configure the path to CA certificates\n    \"\"\"\n    ENV_CLIENT_CERT = \"COHERENCE_TLS_CLIENT_CERT\"\n    \"\"\"\n    Environment variable to configure the path to client certificates\n    \"\"\"\n    ENV_CLIENT_KEY = \"COHERENCE_TLS_CLIENT_KEY\"\n    \"\"\"\n    Environment variable to configure the path to client key\n    \"\"\"\n\n    def __init__(\n        self,\n        locked: bool = False,\n        enabled: bool = False,\n        ca_cert_path: str | None = None,\n        client_cert_path: str | None = None,\n        client_key_path: str | None = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.TlsOptions`\n\n        :param locked: If `true`, prevents further mutations to the options.\n        :param enabled: Enable/disable TLS support.\n        :param ca_cert_path: the path to the CA certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CERTS_PATH\n        :param client_cert_path: the path to the client certificate. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_CERT\n        :param client_key_path: the path to the client certificate key. If not specified then its configured using the\n            environment variable COHERENCE_TLS_CLIENT_KEY\n        \"\"\"\n        self._locked = locked\n        self._enabled = enabled\n\n        self._ca_cert_path = os.getenv(TlsOptions.ENV_CA_CERT, ca_cert_path)\n        self._client_cert_path = os.getenv(TlsOptions.ENV_CLIENT_CERT, client_cert_path)\n        self._client_key_path = os.getenv(TlsOptions.ENV_CLIENT_KEY, client_key_path)\n\n    @property\n    def enabled(self) -> bool:\n        \"\"\"\n        Property to set/get the boolean state if TLS is enabled(true) or disabled(false)\n        \"\"\"\n        return self._enabled\n\n    @enabled.setter\n    def enabled(self, enabled: bool) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._enabled = enabled\n\n    @property\n    def ca_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the CA certificate\n        \"\"\"\n        return self._ca_cert_path\n\n    @ca_cert_path.setter\n    def ca_cert_path(self, ca_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._ca_cert_path = ca_cert_path\n\n    @property\n    def client_cert_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate.\n        \"\"\"\n        return self._client_cert_path\n\n    @client_cert_path.setter\n    def client_cert_path(self, client_cert_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_cert_path = client_cert_path\n\n    @property\n    def client_key_path(self) -> Optional[str]:\n        \"\"\"\n        Property to set/get the path to the client certificate key.\n        \"\"\"\n        return self._client_key_path\n\n    @client_key_path.setter\n    def client_key_path(self, client_key_path: str) -> None:\n        if self.is_locked():\n            return\n        else:\n            self._client_key_path = client_key_path\n\n    def locked(self) -> None:\n        \"\"\"\n        Once called, no further mutations can be made.\n        \"\"\"\n        self._locked = True\n\n    def is_locked(self) -> bool:\n        return self._locked\n\n    def __str__(self) -> str:\n        return (\n            f\"TlsOptions(enabled={self.enabled}, ca-cert-path={self.ca_cert_path}, \"\n            f\"client-cert-path={self.client_cert_path}, client-key-path={self.client_key_path})\"\n        )\n\n\nclass Options:\n    \"\"\"\n    Supported :func:`coherence.client.Session` options.\n    \"\"\"\n\n    ENV_SERVER_ADDRESS = \"COHERENCE_SERVER_ADDRESS\"\n    \"\"\"\n    Environment variable to specify the Coherence gRPC server address for the client to connect to. The\n    environment variable is used if address is not passed as an argument in the constructor. If the environment\n    variable is not set and address is not passed as an argument then `DEFAULT_ADDRESS` is used\n    \"\"\"\n    ENV_REQUEST_TIMEOUT = \"COHERENCE_CLIENT_REQUEST_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the request timeout for each remote call. The environment variable is used if\n    request timeout is not passed as an argument in the constructor. If the environment variable is not set and\n    request timeout is not passed as an argument then `DEFAULT_REQUEST_TIMEOUT` of 30 seconds is used\n    \"\"\"\n    ENV_READY_TIMEOUT = \"COHERENCE_READY_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the maximum amount of time an NamedMap or NamedCache operations may wait for the\n    underlying gRPC channel to be ready.  This is independent of the request timeout which sets a deadline on how\n    long the call may take after being dispatched.\n    \"\"\"\n    ENV_SESSION_DISCONNECT_TIMEOUT = \"COHERENCE_SESSION_DISCONNECT_TIMEOUT\"\n    \"\"\"\n    Environment variable to specify the maximum amount of time, in seconds, a Session may remain in a disconnected\n    state without successfully reconnecting.\n    \"\"\"\n\n    DEFAULT_ADDRESS: Final[str] = \"localhost:1408\"\n    \"\"\"The default target address to connect to Coherence gRPC server.\"\"\"\n    DEFAULT_SCOPE: Final[str] = \"\"\n    \"\"\"The default scope.\"\"\"\n    DEFAULT_REQUEST_TIMEOUT: Final[float] = 30.0\n    \"\"\"The default request timeout.\"\"\"\n    DEFAULT_READY_TIMEOUT: Final[float] = 0\n    \"\"\"\n    The default ready timeout is 0 which disables the feature by default.  Explicitly configure the ready timeout\n    session option or use the environment variable to specify a positive value indicating how many seconds an RPC will\n    wait for the underlying channel to be ready before failing.\n    \"\"\"\n    DEFAULT_SESSION_DISCONNECT_TIMEOUT: Final[float] = 30.0\n    \"\"\"\n    The default maximum time a session may be in a disconnected state without having successfully reconnected.\n    \"\"\"\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    def __init__(\n        self,\n        address: str = DEFAULT_ADDRESS,\n        scope: str = DEFAULT_SCOPE,\n        request_timeout_seconds: float = DEFAULT_REQUEST_TIMEOUT,\n        ready_timeout_seconds: float = DEFAULT_READY_TIMEOUT,\n        session_disconnect_seconds: float = DEFAULT_SESSION_DISCONNECT_TIMEOUT,\n        ser_format: str = DEFAULT_FORMAT,\n        channel_options: Optional[Sequence[Tuple[str, Any]]] = None,\n        tls_options: Optional[TlsOptions] = None,\n    ) -> None:\n        \"\"\"\n        Construct a new :func:`coherence.client.Options`\n\n        :param address: Address of the target Coherence cluster.  If not explicitly set, this defaults\n          to :func:`coherence.client.Options.DEFAULT_ADDRESS`. See\n          also :func:`coherence.client.Options.ENV_SERVER_ADDRESS`\n        :param scope: scope name used to link this :func:`coherence.client.Options` to the\n          corresponding `ConfigurableCacheFactory` on the server.\n        :param request_timeout_seconds: Defines the request timeout, in `seconds`, that will be applied to each\n          remote call. If not explicitly set, this defaults to :func:`coherence.client.Options.DEFAULT_REQUEST_TIMEOUT`.\n          See also :func:`coherence.client.Options.ENV_REQUEST_TIMEOUT`\n        :param ready_timeout_seconds: Defines the ready timeout, in `seconds`.  If this is a positive\n          float value, remote calls will not fail immediately if no connection is available.  If this is a value of zero\n          or less, then remote calls will fail-fast.  If not explicitly configured, the default of 0 is assumed.\n\n          See also :class:`coherence.client.Options.ENV_READY_TIMEOUT`\n        :param session_disconnect_seconds: Defines the maximum time, in `seconds`, that a session may remain in\n          a disconnected state without successfully reconnecting.\n        :param ser_format: The serialization format.  Currently, this is always `json`\n        :param channel_options: The `gRPC` `ChannelOptions`. See\n            https://grpc.github.io/grpc/python/glossary.html#term-channel_arguments and\n            https://github.com/grpc/grpc/blob/master/include/grpc/impl/grpc_types.h\n        :param tls_options: Optional TLS configuration.\n        \"\"\"\n        self._address = os.getenv(Options.ENV_SERVER_ADDRESS, address)\n\n        self._request_timeout_seconds = Options._get_float_from_env(\n            Options.ENV_REQUEST_TIMEOUT, request_timeout_seconds\n        )\n        self._ready_timeout_seconds = Options._get_float_from_env(Options.ENV_READY_TIMEOUT, ready_timeout_seconds)\n        self._session_disconnect_timeout_seconds = Options._get_float_from_env(\n            Options.ENV_SESSION_DISCONNECT_TIMEOUT, session_disconnect_seconds\n        )\n\n        self._scope = scope\n        self._ser_format = ser_format\n\n        if channel_options is not None:\n            self._channel_options = channel_options\n\n        if tls_options is not None:\n            self._tls_options = tls_options\n\n    @property\n    def tls_options(self) -> Optional[TlsOptions]:\n        \"\"\"\n        Returns the TLS-specific configuration options.\n\n        :return: the TLS-specific configuration options.\n        \"\"\"\n        return getattr(self, \"_tls_options\", None)\n\n    @tls_options.setter\n    def tls_options(self, tls_options: TlsOptions) -> None:\n        \"\"\"\n        Sets the TLS-specific configuration options.\n\n        :param tls_options: the TLS-specific configuration options.\n        \"\"\"\n        self._tls_options = tls_options\n\n    @property\n    def address(self) -> str:\n        \"\"\"\n        Return the IPv4 host address and port in the format of ``[host]:[port]``.\n\n        :return: the IPv4 host address and port in the format of ``[host]:[port]``.\n        \"\"\"\n        return self._address\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n         server.\n        \"\"\"\n        return self._scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        The serialization format used by this session.  This library currently supports JSON serialization only,\n        thus this always returns 'json'.\n\n        :return: the serialization format used by this session.\n        \"\"\"\n        return self._ser_format\n\n    @property\n    def request_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the request timeout in `seconds`\n\n        :return: the request timeout in `seconds`\n        \"\"\"\n        return self._request_timeout_seconds\n\n    @property\n    def ready_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the ready timeout in `seconds`.\n\n        :return: the ready timeout in `seconds`\n        \"\"\"\n        return self._ready_timeout_seconds\n\n    @property\n    def session_disconnect_timeout_seconds(self) -> float:\n        \"\"\"\n        Returns the ready timeout in `seconds`.\n\n        :return: the ready timeout in `seconds`\n        \"\"\"\n        return self._session_disconnect_timeout_seconds\n\n    @property\n    def channel_options(self) -> Optional[Sequence[Tuple[str, Any]]]:\n        \"\"\"\n        Return the `gRPC` `ChannelOptions`.\n\n        :return: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        return getattr(self, \"_channel_options\", None)\n\n    @channel_options.setter\n    def channel_options(self, channel_options: Sequence[Tuple[str, Any]]) -> None:\n        \"\"\"\n        Set the `gRPC` `ChannelOptions`.\n\n        :param channel_options: the `gRPC` `ChannelOptions`.\n        \"\"\"\n        self._channel_options = channel_options\n\n    @staticmethod\n    def _get_float_from_env(variable_name: str, default_value: float) -> float:\n        \"\"\"\n        Return a float value parsed from the provided environment variable name.\n\n        :param variable_name: the environment variable name\n        :param default_value: the value to use if the environment variable is not set\n\n        :return: the float value from the environment or the default if the value can't be parsed\n          or the environment variable is not set\n        \"\"\"\n        timeout = os.getenv(variable_name)\n        if timeout is not None:\n            time_out: float = default_value\n            try:\n                time_out = float(timeout)\n            except ValueError:\n                COH_LOG.warning(\n                    \"The timeout value of [%s] specified by environment variable [%s] cannot be converted to a float\",\n                    timeout,\n                    variable_name,\n                )\n\n            return time_out\n        else:\n            return default_value\n\n    def __str__(self) -> str:\n        return (\n            f\"Options(address={self.address}, scope={self.scope}, format={self.format},\"\n            f\" request-timeout-seconds={self.request_timeout_seconds}, \"\n            f\"ready-timeout-seconds={self.ready_timeout_seconds}, \"\n            f\"session-disconnect-timeout-seconds={self.session_disconnect_timeout_seconds}, \"\n            f\"tls-options={self.tls_options}, \"\n            f\"channel-options={self.channel_options})\"\n        )\n\n\ndef _get_channel_creds(tls_options: TlsOptions) -> grpc.ChannelCredentials:\n    client_cert: bytes | None = None\n    client_key: bytes | None = None\n    ca_cert: bytes | None = None\n\n    if tls_options.client_cert_path is not None:\n        with open(tls_options.client_cert_path, \"rb\") as f:\n            client_cert = f.read()\n    if tls_options.client_key_path is not None:\n        with open(tls_options.client_key_path, \"rb\") as f:\n            client_key = f.read()\n    if tls_options.ca_cert_path is not None:\n        with open(tls_options.ca_cert_path, \"rb\") as f:\n            ca_cert = f.read()\n\n    credentials = grpc.ssl_channel_credentials(ca_cert, client_key, client_cert)\n\n    return credentials\n\n\nclass Session:\n    \"\"\"\n    Session represents a logical connection to an endpoint. It also acts as a factory for creating caches.\n\n    This class emits the following events:\n\n        1. :class:`coherence.event.MapLifecycleEvent.DESTROYED`: when the underlying cache is destroyed\n        2. :class:`coherence.event.MapLifecycleEvent.TRUNCATED`: When the underlying cache is truncated\n        3. :class:`coherence.event.MapLifecycleEvent.RELEASED`: When the underlying cache is released\n        4. :class:`coherence.event.SessionLifecycleEvent.CONNECT`: when the Session detects the underlying `gRPC`\n            channel has connected.\n        5. :class:`coherence.event.SessionLifecycleEvent.DISCONNECT`: when the Session detects the underlying `gRPC`\n            channel has disconnected\n        6. :class:`coherence.event.SessionLifecycleEvent.RECONNECTED`: when the Session detects the underlying `gRPC`\n            channel has re-connected\n        7. :class:`coherence.event.SessionLifecycleEvent.CLOSED`: when the Session has been closed\n\n    \"\"\"\n\n    DEFAULT_FORMAT: Final[str] = \"json\"\n    \"\"\"The default serialization format\"\"\"\n\n    def __init__(self, session_options: Optional[Options] = None):\n        \"\"\"\n        Construct a new `Session` based on the provided :func:`coherence.client.Options`\n\n        :param session_options: the provided :func:`coherence.client.Options`\n        \"\"\"\n        self._closed: bool = False\n        self._session_id: str = str(uuid.uuid4())\n        self._ready: bool = False\n        self._initialized: bool = False\n        self._ready_condition: Condition = Condition()\n        self._caches: dict[str, NamedCache[Any, Any]] = dict()\n        self._lock: Lock = Lock()\n        if session_options is not None:\n            self._session_options = session_options\n        else:\n            self._session_options = Options()\n\n        self._ready_timeout_seconds: float = self._session_options.ready_timeout_seconds\n        self._ready_enabled: bool = self._ready_timeout_seconds > 0\n\n        interceptors = [\n            _InterceptorUnaryUnary(self),\n            _InterceptorUnaryStream(self),\n            _InterceptorStreamUnary(self),\n        ]\n\n        # only add the StreamStream interceptor if ready support is enabled as\n        # when added in the non-ready case, the call will not fail-fast\n        if self._ready_enabled:\n            interceptors.append(_InterceptorStreamStream(self))\n\n        self._tasks: Set[Task[None]] = set()\n\n        options: Sequence[tuple[str, Any]] = [\n            (\"grpc.min_reconnect_backoff_ms\", 1100),\n            (\"grpc.max_reconnect_backoff_ms\", 3000),\n            (\"grpc.lb_policy_name\", \"round_robin\"),\n        ]\n\n        self._is_server_grpc_v1 = False\n        self._v1_init_response_details: dict[str, Any] = dict()\n\n        if self._session_options.tls_options is None:\n            self._channel: grpc.aio.Channel = grpc.aio.insecure_channel(\n                self._session_options.address,\n                options=(\n                    options if self._session_options.channel_options is None else self._session_options.channel_options\n                ),\n                interceptors=interceptors,\n            )\n        else:\n            creds: grpc.ChannelCredentials = _get_channel_creds(self._session_options.tls_options)\n            self._channel = grpc.aio.secure_channel(\n                self._session_options.address,\n                creds,\n                options=(\n                    options if self._session_options.channel_options is None else self._session_options.channel_options\n                ),\n                interceptors=interceptors,\n            )\n\n        self._handshake = _Handshake(self)\n\n        watch_task: Task[None] = asyncio.create_task(watch_channel_state(self))\n        self._tasks.add(watch_task)\n        self._emitter: EventEmitter = EventEmitter()\n        self._channel.get_state(True)  # trigger connect\n\n    @staticmethod\n    async def create(session_options: Optional[Options] = None) -> Session:\n        session: Session = Session(session_options)\n        await session._set_ready(False)\n        await session._handshake.handshake()\n        return session\n\n    # noinspection PyTypeHints\n    @_pre_call_session\n    def on(\n        self,\n        event: Literal[MapLifecycleEvent.DESTROYED] | Literal[MapLifecycleEvent.RELEASED] | SessionLifecycleEvent,\n        callback: Callable[[str], None] | Callable[[], None],\n    ) -> None:\n        \"\"\"\n        Register a callback to be invoked when the following events are raised:\n\n        * MapLifecycleEvent.DESTROYED\n        * MapLifecycleEvent.RELEASED\n        * Any SessionLifecycleEvent\n\n        The callbacks defined for MapLifecycleEvent DESTROYED and RELEASED should accept a single string\n        argument representing the cache name that the event was raised for.\n\n        The SessionLifecycleEvent callbacks should not accept call arguments.\n        :param event:     the event to listener for\n        :param callback:  the callback to invoke when the event is raised\n        \"\"\"\n        if event == SessionLifecycleEvent.CONNECTED and self.is_ready():\n            callback()  # type: ignore\n            return\n\n        self._emitter.on(str(event.value), callback)\n\n    @property\n    def channel(self) -> grpc.aio.Channel:\n        \"\"\"\n        Return the underlying `gRPC` Channel used by this session.\n\n        :return: the underlying `gRPC` Channel used by this session.\n        \"\"\"\n        return self._channel\n\n    @property\n    def scope(self) -> str:\n        \"\"\"\n        Return the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n        server.\n\n        :return: the scope name used to link this `Session` with to the corresponding `ConfigurableCacheFactory` on the\n          server.\n        \"\"\"\n        return self._session_options.scope\n\n    @property\n    def format(self) -> str:\n        \"\"\"\n        Returns the default serialization format used by the `Session`\n\n        :return: the default serialization format used by the `Session`\n        \"\"\"\n        return self._session_options.format\n\n    @property\n    def options(self) -> Options:\n        \"\"\"\n        Return the :func:`coherence.client.Options` (read-only) used to configure this session.\n\n        :return: the :func:`coherence.client.Options` (read-only) used to configure this session.\n        \"\"\"\n        return self._session_options\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"\n        Returns `True` if Session is closed else `False`.\n\n        :return: `True` if Session is closed else `False`\n        \"\"\"\n        return self._closed\n\n    @property\n    def session_id(self) -> str:\n        \"\"\"\n        Returns this Session's ID.\n\n        :return: this Session's ID\n        \"\"\"\n        return self._session_id\n\n    def __str__(self) -> str:\n        if self._protocol_version > 0:\n            return (\n                f\"Session(id={self.session_id}, closed={self.closed}, state={self._channel.get_state(False)},\"\n                f\" caches/maps={len(self._caches)}, protocol-version={self._protocol_version} options={self.options}\"\n                f\" proxy-version={self._proxy_version}, proxy-member-id={self._proxy_member_id})\"\n            )\n        else:\n            return (\n                f\"Session(id={self.session_id}, closed={self.closed}, state={self._channel.get_state(False)},\"\n                f\" caches/maps={len(self._caches)}, protocol-version={self._protocol_version} options={self.options})\"\n            )\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_cache(self, name: str, ser_format: str = DEFAULT_FORMAT) -> NamedCache[K, V]:\n        \"\"\"\n        Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n\n        :param name: the cache name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedCache` for the specified cache name.\n        \"\"\"\n        serializer = SerializerRegistry.serializer(ser_format)\n\n        if self._protocol_version == 0:\n            with self._lock:\n                c = self._caches.get(name)\n                if c is None:\n                    c = NamedCacheClient(name, self, serializer)\n                    # initialize the event stream now to ensure lifecycle listeners will work as expected\n                    await c._events_manager._ensure_stream()\n                    self._setup_event_handlers(c)\n                    self._caches.update({name: c})\n                return c\n        else:  # Server is running grpc v1\n            with self._lock:\n                c = self._caches.get(name)\n                if c is None:\n                    c = NamedCacheClientV1(name, self, serializer)\n                    await c._ensure_cache()\n                    self._setup_event_handlers(c)\n                    self._caches.update({name: c})\n                return c\n\n    # noinspection PyProtectedMember\n    @_pre_call_session\n    async def get_map(self, name: str, ser_format: str = DEFAULT_FORMAT) -> NamedMap[K, V]:\n        \"\"\"\n        Returns a :func:`coherence.client.NameMap` for the specified cache name.\n\n        :param name: the map name\n        :param ser_format: the serialization format for keys and values stored within the cache\n\n        :return: Returns a :func:`coherence.client.NamedMap` for the specified cache name.\n        \"\"\"\n        return cast(NamedMap[K, V], await self.get_cache(name, ser_format))\n\n    def is_ready(self) -> bool:\n        \"\"\"\n        Returns\n        :return:\n        \"\"\"\n        if self._closed:\n            return False\n\n        return True if not self._ready_enabled else self._ready\n\n    @property\n    def _proxy_version(self) -> str:\n        return self._handshake.proxy_version\n\n    @property\n    def _protocol_version(self) -> int:\n        return self._handshake.protocol_version\n\n    @property\n    def _proxy_member_id(self) -> int:\n        return self._handshake.proxy_member_id\n\n    async def _set_ready(self, ready: bool) -> None:\n        self._ready = ready\n        if self._ready:\n            if not self._ready_condition.locked():\n                await self._ready_condition.acquire()\n            self._ready_condition.notify_all()\n            self._ready_condition.release()\n        else:\n            await self._ready_condition.acquire()\n\n    async def _wait_for_ready(self) -> None:\n        if self._ready_enabled and not self.is_ready():\n            timeout: float = self._ready_timeout_seconds\n            COH_LOG.debug(f\"Waiting for session {self.session_id} to become active; timeout=[{timeout} seconds]\")\n            try:\n                await asyncio.wait_for(self._ready_condition.wait(), timeout)\n            except TimeoutError:\n                s = \"Deadline [{0} seconds] exceeded \" \"waiting for session {1} to become active\".format(\n                    str(timeout), self.session_id\n                )\n                raise TimeoutError(s)\n\n    # noinspection PyUnresolvedReferences\n    async def close(self) -> None:\n        \"\"\"\n        Close the `Session`\n        \"\"\"\n        if not self._closed:\n            self._closed = True\n            self._emitter.emit(SessionLifecycleEvent.CLOSED.value)\n            for task in self._tasks:\n                task.cancel()\n                await task\n            self._tasks.clear()\n\n            caches_copy: dict[str, NamedCache[Any, Any]] = self._caches.copy()\n            for cache in caches_copy.values():\n                await cache.release()\n\n            self._caches.clear()\n\n            await self._channel.close()  # TODO: consider grace period?\n            self._channel = None\n\n    def _setup_event_handlers(self, client: NamedCacheClient[K, V] | NamedCacheClientV1[K, V]) -> None:\n        this: Session = self\n\n        def on_destroyed(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.DESTROYED.value, name)\n\n        def on_released(name: str) -> None:\n            if name in this._caches:\n                del this._caches[name]\n            self._emitter.emit(MapLifecycleEvent.RELEASED.value, name)\n\n        client.on(MapLifecycleEvent.DESTROYED, on_destroyed)\n        client.on(MapLifecycleEvent.RELEASED, on_released)\n\n\n# noinspection PyArgumentList\nclass _BaseInterceptor:\n    \"\"\"Base client interceptor to enable waiting for channel connectivity and\n    set call timeouts.\n    Having this base class and four concrete implementations is due to\n    https://github.com/grpc/grpc/issues/31442\"\"\"\n\n    def __init__(self, session: Session):\n        self._session: Session = session\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def _do_intercept(self, continuation, client_call_details, request):\n        \"\"\"\n        Intercepts a gRPC call setting our specific options for the call.\n        :param continuation:         the gRPC call continuation\n        :param client_call_details:  the call details\n        :param request:              the gRPC request (if any)\n        :return:                     the result of the call\n        \"\"\"\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            self._session.options.request_timeout_seconds,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True if self._session._ready_enabled else None,\n        )\n        return await continuation(new_details, request)\n\n\nclass _InterceptorUnaryUnary(_BaseInterceptor, grpc.aio.UnaryUnaryClientInterceptor):\n    \"\"\"Interceptor for Unary/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorUnaryStream(_BaseInterceptor, grpc.aio.UnaryStreamClientInterceptor):\n    \"\"\"Interceptor for Unary/Stream calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_unary_stream(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamUnary(_BaseInterceptor, grpc.aio.StreamUnaryClientInterceptor):\n    \"\"\"Interceptor for Stream/Unary calls.\"\"\"\n\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_unary(self, continuation, client_call_details, request):\n        return await self._do_intercept(continuation, client_call_details, request)\n\n\nclass _InterceptorStreamStream(_BaseInterceptor, grpc.aio.StreamStreamClientInterceptor):\n    \"\"\"Interceptor for Stream/Stream calls.\"\"\"\n\n    # noinspection PyArgumentList,PyUnresolvedReferences\n    @no_type_check  # disabling as typing info in gRPC is in protected packages\n    async def intercept_stream_stream(self, continuation, client_call_details, request):\n        new_details = grpc.aio.ClientCallDetails(\n            client_call_details.method,\n            client_call_details.timeout,\n            client_call_details.metadata,\n            client_call_details.credentials,\n            True,\n        )\n\n        return await continuation(new_details, request)\n\n\n# noinspection PyProtectedMember\nasync def watch_channel_state(session: Session) -> None:\n    emitter: EventEmitter = session._emitter\n    channel: grpc.aio.Channel = session.channel\n    first_connect: bool = True\n    connected: bool = False\n    last_state: grpc.ChannelConnectivity = grpc.ChannelConnectivity.IDLE\n    disconnect_time: float = 0\n\n    def current_milli_time() -> float:\n        return round(time.time() * 1000)\n\n    try:\n        while True:\n            state: grpc.ChannelConnectivity = channel.get_state(True)\n            if COH_LOG.isEnabledFor(logging.DEBUG):\n                COH_LOG.debug(f\"New Channel State: transitioning from [{last_state}] to [{state}].\")\n            if state == grpc.ChannelConnectivity.SHUTDOWN:\n                COH_LOG.info(f\"Session [{session.session_id}] terminated.\")\n                await session._set_ready(False)\n                await session.close()\n                return\n            elif state == grpc.ChannelConnectivity.READY:\n                if not first_connect and not connected:\n                    connected = True\n                    disconnect_time = 0\n                    COH_LOG.info(f\"Session [{session.session_id} re-connected to [{session.options.address}].\")\n                    await emitter.emit_async(SessionLifecycleEvent.RECONNECTED.value)\n                    await session._set_ready(True)\n                elif first_connect and not connected:\n                    connected = True\n                    COH_LOG.info(f\"Session [{session.session_id}] connected to [{session.options.address}].\")\n\n                    first_connect = False\n                    await emitter.emit_async(SessionLifecycleEvent.CONNECTED.value)\n                    await session._set_ready(True)\n            else:\n                if connected:\n                    connected = False\n                    disconnect_time = -1\n                    COH_LOG.warning(\n                        f\"Session [{session.session_id}] disconnected from [{session.options.address}];\"\n                        f\" will attempt reconnect.\"\n                    )\n\n                    await emitter.emit_async(SessionLifecycleEvent.DISCONNECTED.value)\n                    await session._set_ready(False)\n\n                if disconnect_time != 0:\n                    if disconnect_time == -1:\n                        disconnect_time = current_milli_time()\n                    else:\n                        waited: float = current_milli_time() - disconnect_time\n                        timeout = session.options.session_disconnect_timeout_seconds\n                        if COH_LOG.isEnabledFor(logging.DEBUG):\n                            COH_LOG.debug(\n                                f\"Waited [{waited / 1000} seconds] for session [{session.session_id}] to reconnect.\"\n                                f\" [~{(round(timeout - (waited / 1000)))} seconds] remaining to reconnect.\"\n                            )\n                        if waited >= timeout:\n                            COH_LOG.error(\n                                f\"session [{session.session_id}] unable to reconnect within [{timeout} seconds.\"\n                                f\"  Closing session.\"\n                            )\n                            await session.close()\n                            return\n\n            state = channel.get_state(True)\n            if COH_LOG.isEnabledFor(logging.DEBUG):\n                COH_LOG.debug(f\"Waiting for state change from [{state}]\")\n            await channel.wait_for_state_change(state)\n    except asyncio.CancelledError:\n        return\n\n\nclass _Stream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    A simple AsyncIterator that wraps a Callable that produces iteration\n    elements.\n    \"\"\"\n\n    def __init__(\n        self,\n        serializer: Serializer,\n        stream: grpc.Channel.unary_stream,\n        next_producer: Callable[[Serializer, grpc.Channel.unary_stream], Awaitable[T]],\n    ) -> None:\n        super().__init__()\n        # A function that may be called to produce a series of results\n        self._next_producer = next_producer\n\n        # the Serializer that should be used to deserialize results\n        self._serializer = serializer\n\n        # the gRPC stream providing results\n        self._stream = stream\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    def __anext__(self) -> Awaitable[T]:\n        return self._next_producer(self._serializer, self._stream)\n\n\n# noinspection PyProtectedMember\nclass _PagedStream(abc.ABC, AsyncIterator[T]):\n    \"\"\"\n    An AsyncIterator that will stream results in pages.\n    \"\"\"\n\n    def __init__(\n        self, client: NamedCacheClient[K, V], result_handler: Callable[[Serializer, Any], Any], keys: bool = False\n    ) -> None:\n        super().__init__()\n        # flag indicating that all pages have been processed\n        self._exhausted: bool = False\n\n        # the gRPC client\n        self._client: NamedCacheClient[K, V] = client\n\n        # the handler responsible for deserializing the result\n        self._result_handler: Callable[[Serializer, Any], Any] = result_handler\n\n        # the serializer to be used when deserializing streamed results\n        self._serializer: Serializer = client._request_factory.get_serializer()\n\n        # cookie that tracks page streaming; used for each new page request\n        self._cookie: bytes = bytes()\n\n        # the gRPC stream providing the results\n        self._stream: grpc.Channel.unary_stream = None\n\n        # flag indicating a new page has been loaded\n        self._new_page: bool = True\n\n        # flag indicating that pages will be keys only\n        self._keys: bool = keys\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    async def __anext__(self) -> T:\n        # keep the loop running to ensure we don't exit\n        # prematurely which would result in a None value\n        # being returned incorrectly between pages\n        while True:\n            if self._stream is None and not self._exhausted:\n                await self.__load_next_page()\n\n            if self._stream is None and self._exhausted:\n                raise StopAsyncIteration\n\n            async for item in self._stream:\n                if self._new_page:  # a new page has been loaded; the cookie will be the first result\n                    self._new_page = False\n                    self._cookie = item.value if self._keys else item.cookie\n                    if self._cookie == b\"\":\n                        self._exhausted = True  # processing the last page\n                else:\n                    return self._result_handler(self._serializer, item)\n\n            self._stream = None\n            if self._exhausted:\n                raise StopAsyncIteration\n\n    # noinspection PyProtectedMember\n    async def __load_next_page(self) -> None:\n        \"\"\"\n        Requests the next page of results to be streamed.\n\n        :return: None\n        \"\"\"\n        request: PageRequest = self._client._request_factory.page_request(self._cookie)\n        self._stream = self._get_stream(request)\n        self._new_page = True\n\n    def _get_stream(self, request: PageRequest) -> grpc.Channel.unary_stream:\n        \"\"\"\n        Obtain the gRPC unary_stream for the provided PageRequest.\n\n        :param request: the PageRequest\n        :return: the gRPC unary_stream for the given request\n        \"\"\"\n        client_stub: NamedCacheServiceStub = self._client._client_stub\n        return client_stub.nextKeySetPage(request) if self._keys else client_stub.nextEntrySetPage(request)\n\n\ndef _scalar_deserializer(serializer: Serializer, item: Any) -> Any:\n    \"\"\"\n    Helper method to deserialize a key or value returned in a stream.\n\n    :param serializer: the serializer that should be used\n    :param item: the key or value to deserialize\n    :return: the deserialized key or value\n    \"\"\"\n    return serializer.deserialize(item.value)\n\n\ndef _entry_deserializer(serializer: Serializer, item: Any) -> MapEntry[Any, Any]:\n    \"\"\"\n    Helper method to deserialize entries returned in a stream.\n\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param item: the entry\n    :return: the deserialized entry\n    \"\"\"\n    return MapEntry(serializer.deserialize(item.key), serializer.deserialize(item.value))\n\n\nasync def _scalar_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> T:\n    \"\"\"\n    Helper method to iterate over a stream and produce scalar results.\n\n    :param serializer: the serializer that should be used to deserialize the scalar value\n    :param stream: the gRPC stream\n    :return: one or more deserialized scalar values\n    \"\"\"\n    async for item in stream:\n        return _scalar_deserializer(serializer, item)\n    raise StopAsyncIteration\n\n\nasync def _entry_producer(serializer: Serializer, stream: grpc.Channel.unary_stream) -> MapEntry[K, V]:\n    \"\"\"\n    Helper method to iterate over a stream and produce MapEntry instances\n    .\n    :param serializer: the serializer that should be used to deserialize the entry\n    :param stream: the gRPC stream\n    :return: one or more deserialized MapEntry instances\n    \"\"\"\n    async for item in stream:\n        return _entry_deserializer(serializer, item)\n    raise StopAsyncIteration\n\n\nasync def _entry_producer_from_list(serializer: Serializer, the_list: list[Any]) -> MapEntry[K, V]:  # type: ignore\n    if len(the_list) == 0:\n        raise StopAsyncIteration\n    for item in the_list:\n        the_list.pop(0)\n        return _entry_deserializer(serializer, item)\n\n\nclass _ListAsyncIterator(abc.ABC, AsyncIterator[T]):\n    def __init__(\n        self,\n        serializer: Serializer,\n        the_list: list[T],\n        next_producer: Callable[[Serializer, list[T]], Awaitable[T]],\n    ) -> None:\n        super().__init__()\n        # A function that may be called to produce a series of results\n        self._next_producer = next_producer\n\n        # the Serializer that should be used to deserialize results\n        self._serializer = serializer\n\n        # the gRPC stream providing results\n        self._the_list = the_list\n\n    def __aiter__(self) -> AsyncIterator[T]:\n        return self\n\n    def __anext__(self) -> Awaitable[T]:\n        return self._next_producer(self._serializer, self._the_list)\n\n\n# noinspection PyProtectedMember\nclass StreamHandler:\n    theStreamHandler = None\n\n    def __init__(\n        self,\n        session: Session,\n        request_factory: RequestFactoryV1,\n        events_manager: _MapEventsManagerV1[K, V],\n    ):\n        self._channel = session.channel\n        self._reconnect_timeout: float = session.options.session_disconnect_timeout_seconds\n        self._proxy_stub = ProxyServiceStub(session.channel)\n\n        self._request_factory: RequestFactoryV1 = request_factory\n        self._events_manager: _MapEventsManagerV1[K, V] = events_manager\n        self._stream: Optional[StreamStreamMultiCallable] = None\n        self._observers: dict[int, ResponseObserver] = dict()\n        self.result_available = Event()\n        self.result_available.clear()\n        self._background_tasks: Set[Task[Any]] = set()\n        self._closed: bool = False\n        self._connected = Event()\n        self._connected.clear()\n        self._ensure_lock = asyncio.Lock()\n\n        task = asyncio.create_task(self.handle_response())\n        task.add_done_callback(self._background_tasks.discard)\n        self._background_tasks.add(task)\n\n        def on_disconnect() -> None:\n            self._connected.clear()\n            self._stream = None\n\n        async def on_reconnect() -> None:\n            self._connected.set()\n            await self._events_manager._named_map._ensure_cache()\n            await self._events_manager._reconnect()\n\n        session.on(SessionLifecycleEvent.DISCONNECTED, on_disconnect)\n        session.on(SessionLifecycleEvent.RECONNECTED, on_reconnect)\n\n    @property\n    async def stream(self) -> StreamStreamMultiCallable:\n        await self._ensure_stream()\n\n        return self._stream\n\n    # noinspection PyUnresolvedReferences\n    async def close(self) -> None:\n        tasks: Set[Task[Any]] = set(self._background_tasks)\n        for task in tasks:\n            task.cancel()\n            await task\n\n        if self._stream is not None:\n            self._stream.cancel()\n            self._stream = None\n\n        self._closed = True\n\n    async def _ensure_stream(self) -> StreamStreamMultiCallable:\n        if self._stream is None:\n            async with self._ensure_lock:\n                if self._stream is None:\n                    stream = self._proxy_stub.subChannel()\n\n                    try:\n                        await stream.write(self._request_factory.init_sub_channel())\n                    except grpc.aio._call.AioRpcError as e:\n                        print(e)\n\n                    await stream.read()\n                    self._stream = stream  # we don't care about the result, only that it completes\n                    self._connected.set()\n\n        return self._stream\n\n    # noinspection PyUnresolvedReferences\n    async def send_proxy_request(self, proxy_request: ProxyRequest) -> None:\n        stream: StreamStreamMultiCallable = await self.stream\n        await stream.write(proxy_request)\n\n    def register_observer(self, observer: ResponseObserver) -> None:\n        assert observer.id not in self._observers\n\n        self._observers[observer.id] = observer\n\n    async def handle_response(self) -> None:\n        while not self._closed:\n            try:\n                stream: StreamStreamMultiCallable = await self.stream\n                response = await stream.read()\n                response_id = response.id\n                if response_id == 0:\n                    self.handle_zero_id_response(response)\n                else:\n                    if response.HasField(\"message\"):\n                        observer = self._observers.get(response_id, None)\n                        if observer is not None:\n                            named_cache_response = NamedCacheResponse()\n                            response.message.Unpack(named_cache_response)\n                            observer._next(named_cache_response)\n                            continue\n                    elif response.HasField(\"init\"):\n                        print(\"InitRequest request completed.\")\n                        self.result_available.set()\n                    elif response.HasField(\"error\"):\n                        observer = self._observers.get(response_id, None)\n                        if observer is not None:\n                            self._observers.pop(response_id, None)\n                            observer._err(Error(response.error.message))\n                        continue\n                    elif response.HasField(\"complete\"):\n                        observer = self._observers.get(response_id, None)\n                        if observer is not None:\n                            self._observers.pop(response_id, None)\n                            observer._done()\n            except asyncio.CancelledError:\n                return\n            except grpc.aio._call.AioRpcError as e:\n                if e.code().name == \"CANCELLED\":\n                    continue\n                COH_LOG.error(\"Received unexpected error from proxy: \" + str(e))\n\n    # noinspection PyUnresolvedReferences\n    def handle_zero_id_response(self, response: ProxyResponse) -> None:\n        if response.HasField(\"message\"):\n            named_cache_response = NamedCacheResponse()\n            response.message.Unpack(named_cache_response)\n            response_type = named_cache_response.type\n            if response_type == ResponseType.Message:\n                pass\n            elif response_type == ResponseType.MapEvent:\n                # Handle MapEvent Response\n                event_response = MapEventMessage()\n                named_cache_response.message.Unpack(event_response)\n\n                try:\n                    event: MapEvent[Any, Any] = MapEvent(\n                        self._events_manager._named_map, event_response, self._events_manager._serializer\n                    )\n                    for _id in event_response.filterIds:\n                        filter_group: Optional[_ListenerGroup[Any, Any, Any]] = (\n                            self._events_manager._filter_id_listener_group_map.get(_id, None)\n                        )\n                        if filter_group is not None:\n                            filter_group._notify_listeners(event)\n\n                    key_group = self._events_manager._key_map.get(event.key, None)\n                    if key_group is not None:\n                        key_group._notify_listeners(event)\n                except Exception as e:\n                    COH_LOG.warning(\"Unhandled Event Message: \" + str(e))\n            elif response_type == ResponseType.Destroyed:\n                if self._events_manager._named_map.cache_id == named_cache_response.cacheId:\n                    self._events_manager._emitter.emit(\n                        MapLifecycleEvent.DESTROYED.value, self._events_manager._named_map.name\n                    )\n            elif response_type == ResponseType.Truncated:\n                if self._events_manager._named_map.cache_id == named_cache_response.cacheId:\n                    self._events_manager._emitter.emit(\n                        MapLifecycleEvent.TRUNCATED.value, self._events_manager._named_map.name\n                    )\n            else:\n                pass\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/coherence/client.py b/src/coherence/client.py
--- a/src/coherence/client.py	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/src/coherence/client.py	(date 1729005138653)
@@ -893,7 +893,7 @@
         self._cache_id: int = 0
         self._serializer: Serializer = serializer
         self._request_factory: RequestFactoryV1 = RequestFactoryV1(
-            cache_name, self._cache_id, session.scope, serializer
+            cache_name, self._cache_id, session.scope, serializer, lambda : session.options.request_timeout_seconds
         )
         self._emitter: EventEmitter = EventEmitter()
         self._internal_emitter: EventEmitter = EventEmitter()
Index: Makefile
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># ----------------------------------------------------------------------------------------------------------------------\n# Copyright (c) 2022, 2023, Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n#\n# ----------------------------------------------------------------------------------------------------------------------\n# This is the Makefile to build the Coherence Python Client\n# ----------------------------------------------------------------------------------------------------------------------\n\nSHELL := /bin/bash\nVERSION ?=0.9.0\nCURRDIR := $(shell pwd)\nUSER_ID := $(shell echo \"`id -u`:`id -g`\")\n\noverride BUILD_BIN           := $(CURRDIR)/bin\noverride PROTO_DIR\t\t\t := $(CURRDIR)/etc/proto\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Set the location of various build tools\n# ----------------------------------------------------------------------------------------------------------------------\noverride BUILD_OUTPUT        := $(CURRDIR)/build/_output\noverride BUILD_BIN           := $(CURRDIR)/bin\noverride PROTO_OUT           := $(CURRDIR)/proto\noverride BUILD_TARGETS       := $(BUILD_OUTPUT)/targets\noverride TEST_LOGS_DIR       := $(BUILD_OUTPUT)/test-logs\noverride COVERAGE_DIR        := $(BUILD_OUTPUT)/coverage\noverride COPYRIGHT_JAR       := glassfish-copyright-maven-plugin-2.4.jar\noverride BUILD_CERTS         := $(CURRDIR)/tests/utils/certs\noverride ENV_FILE            := tests/utils/.env\n\n# Maven version is always 1.0.0 as it is only for testing\nMVN_VERSION ?= 1.0.0\n\n# Coherence CE version to run base tests against\nCOHERENCE_VERSION ?= 22.06.7\nCOHERENCE_GROUP_ID ?= com.oracle.coherence.ce\nCOHERENCE_WKA1 ?= server1\nCOHERENCE_WKA2 ?= server1\nCLUSTER_PORT ?= 7574\n# Profiles to include for building\nPROFILES ?= \",-jakarta,javax\"\nCOHERENCE_BASE_IMAGE ?= gcr.io/distroless/java17-debian11\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Set the location of various build tools\n# ----------------------------------------------------------------------------------------------------------------------\nTOOLS_DIRECTORY   = $(CURRDIR)/build/tools\nTOOLS_BIN         = $(TOOLS_DIRECTORY)/bin\n\n# ----------------------------------------------------------------------------------------------------------------------\n# The test application images used in integration tests\n# ----------------------------------------------------------------------------------------------------------------------\nRELEASE_IMAGE_PREFIX     ?= ghcr.io/oracle/\nTEST_APPLICATION_IMAGE_1 := $(RELEASE_IMAGE_PREFIX)coherence-python-test-1:1.0.0\nTEST_APPLICATION_IMAGE_2 := $(RELEASE_IMAGE_PREFIX)coherence-python-test-2:1.0.0\nGO_TEST_FLAGS ?= -timeout 20m\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Options to append to the Maven command\n# ----------------------------------------------------------------------------------------------------------------------\nMAVEN_OPTIONS ?= -Dmaven.wagon.httpconnectionManager.ttlSeconds=25 -Dmaven.wagon.http.retryHandler.count=3\nMAVEN_BUILD_OPTS :=$(USE_MAVEN_SETTINGS) -Drevision=$(MVN_VERSION) -Dcoherence.version=$(COHERENCE_VERSION) -Dcoherence.group.id=$(COHERENCE_GROUP_ID) $(MAVEN_OPTIONS)\n\nCURRDIR := $(shell pwd)\n\nCOMPOSE:=$(shell type -p docker-compose || echo docker compose)\n$(info COMPOSE = $(COMPOSE))\n\n# ----------------------------------------------------------------------------------------------------------------------\n# List of unit tests\n# ----------------------------------------------------------------------------------------------------------------------\nUNIT_TESTS := tests/unit/test_environment.py \\\n\t\t\t\ttests/unit/test_serialization.py \\\n\t\t\t\ttests/unit/test_extractors.py\n\n# ----------------------------------------------------------------------------------------------------------------------\n# List of E2E tests\n# ----------------------------------------------------------------------------------------------------------------------\nE2E_TESTS := tests/e2e/test_session.py \\\n\t\t\t\ttests/e2e/test_client.py \\\n\t\t\t\ttests/e2e/test_events.py \\\n\t\t\t\ttests/e2e/test_filters.py \\\n\t\t\t\ttests/e2e/test_processors.py \\\n\t\t\t\ttests/e2e/test_aggregators.py \\\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Clean-up all of the build artifacts\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: clean\nclean: ## Cleans the build\n\t@echo \"Cleaning Project\"\n\t-rm -rf $(CURRDIR)/build\n#\t-rm -rf $(PROTO_DIR)\n\t-rm -rf $(CURRDIR)/htmlcov\n\t-rm -rf $(CURRDIR)/.pytest_cache\n\t-rm -rf $(BUILD_CERTS)\n\t@mkdir -p $(BUILD_CERTS)\n\tmvn -B -f tests/java/coherence-python-test $(MAVEN_BUILD_OPTS) clean\n\n.PHONY: certs\ncerts: ## Generates certificates for TLS tests\n\t@echo \"Generating certs\"\n\t./tests/scripts/keys.sh $(BUILD_CERTS)\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Configure the build properties\n# ----------------------------------------------------------------------------------------------------------------------\n$(BUILD_PROPS):\n\t@echo \"Creating build directories\"\n\t@mkdir -p $(BUILD_OUTPUT)\n\t@mkdir -p $(BUILD_BIN)\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Build the Coherence Go Client Test Image\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: build-test-images\nbuild-test-images: ## Build the Test images\n\t@echo \"${MAVEN_BUILD_OPTS}\"\n\tmvn -B -f tests/java clean package jib:dockerBuild -DskipTests -P member1$(PROFILES) -Djib.to.image=$(TEST_APPLICATION_IMAGE_1) -Dcoherence.test.base.image=$(COHERENCE_BASE_IMAGE) $(MAVEN_BUILD_OPTS)\n\tmvn -B -f tests/java clean package jib:dockerBuild -DskipTests -P member2$(PROFILES) -Djib.to.image=$(TEST_APPLICATION_IMAGE_2) -Dcoherence.test.base.image=$(COHERENCE_BASE_IMAGE) $(MAVEN_BUILD_OPTS)\n\techo \"CURRENT_UID=$(USER_ID)\" >> $(ENV_FILE)\n\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Download and build proto files\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: generate-proto\ngenerate-proto:  ## Generate Proto Files\n\tmkdir -p $(PROTO_DIR) || true\n\tcurl -o $(PROTO_DIR)/proxy_service_v1.proto \\\n\t\thttps://raw.githubusercontent.com/oracle/coherence/$(COHERENCE_VERSION)/prj/coherence-grpc/src/main/proto/proxy_service_v1.proto\n\tcurl -o $(PROTO_DIR)/proxy_service_messages_v1.proto \\\n\t\thttps://raw.githubusercontent.com/oracle/coherence/$(COHERENCE_VERSION)/prj/coherence-grpc/src/main/proto/proxy_service_messages_v1.proto\n\tcurl -o $(PROTO_DIR)/common_messages_v1.proto \\\n\t\thttps://raw.githubusercontent.com/oracle/coherence/$(COHERENCE_VERSION)/prj/coherence-grpc/src/main/proto/common_messages_v1.proto\n\tcurl -o $(PROTO_DIR)/cache_service_messages_v1.proto \\\n\t\thttps://raw.githubusercontent.com/oracle/coherence/$(COHERENCE_VERSION)/prj/coherence-grpc/src/main/proto/cache_service_messages_v1.proto\n\tpython -m grpc_tools.protoc --proto_path=$(CURRDIR)/etc/proto --pyi_out=$(CURRDIR)/src/coherence --python_out=$(CURRDIR)/src/coherence \\\n\t\t\t--grpc_python_out=$(CURRDIR)/src/coherence \\\n\t\t\t$(CURRDIR)/etc/proto/proxy_service_v1.proto \\\n\t\t\t$(CURRDIR)/etc/proto/proxy_service_messages_v1.proto \\\n\t\t\t$(CURRDIR)/etc/proto/common_messages_v1.proto \\\n\t\t\t$(CURRDIR)/etc/proto/cache_service_messages_v1.proto\n\tsed -e 's/import proxy_service_messages_v1_pb2 as proxy__service__messages__v1__pb2/import coherence.proxy_service_messages_v1_pb2 as proxy__service__messages__v1__pb2/' \\\n\t\t< $(CURRDIR)/src/coherence/proxy_service_v1_pb2.py > $(CURRDIR)/src/coherence/proxy_service_v1_pb2.py.out\n\tmv $(CURRDIR)/src/coherence/proxy_service_v1_pb2.py.out $(CURRDIR)/src/coherence/proxy_service_v1_pb2.py\n\tsed -e 's/import common_messages_v1_pb2 as common__messages__v1__pb2/import coherence.common_messages_v1_pb2 as common__messages__v1__pb2/' \\\n\t\t< $(CURRDIR)/src/coherence/proxy_service_messages_v1_pb2.py > $(CURRDIR)/src/coherence/proxy_service_messages_v1_pb2.py.out\n\tmv $(CURRDIR)/src/coherence/proxy_service_messages_v1_pb2.py.out $(CURRDIR)/src/coherence/proxy_service_messages_v1_pb2.py\n\tsed -e 's/import proxy_service_messages_v1_pb2 as proxy__service__messages__v1__pb2/import coherence.proxy_service_messages_v1_pb2 as proxy__service__messages__v1__pb2/' \\\n\t\t< $(CURRDIR)/src/coherence/proxy_service_v1_pb2_grpc.py > $(CURRDIR)/src/coherence/proxy_service_v1_pb2_grpc.py.out\n\tmv $(CURRDIR)/src/coherence/proxy_service_v1_pb2_grpc.py.out $(CURRDIR)/src/coherence/proxy_service_v1_pb2_grpc.py\n\tsed -e 's/import common_messages_v1_pb2 as common__messages__v1__pb2/import coherence.common_messages_v1_pb2 as common__messages__v1__pb2/' \\\n\t\t< $(CURRDIR)/src/coherence/cache_service_messages_v1_pb2.py > $(CURRDIR)/src/coherence/cache_service_messages_v1_pb2.py.out\n\tmv $(CURRDIR)/src/coherence/cache_service_messages_v1_pb2.py.out $(CURRDIR)/src/coherence/cache_service_messages_v1_pb2.py\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Run tests with code coverage\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test\ntest:  ##\n\tpytest -W error --cov src/coherence --cov-report=term --cov-report=html $(UNIT_TESTS) $(E2E_TESTS)\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Run unit tests with code coverage\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-unit\ntest-unit:  ##\n\tpytest -W error --cov src/coherence --cov-report=term --cov-report=html $(UNIT_TESTS)\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Run e2e tests with code coverage\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-e2e\ntest-e2e:  ##\n\tpytest -W error --cov src/coherence --cov-report=term --cov-report=html $(E2E_TESTS)\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Run standards validation across project\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: validate-setup\nvalidate-setup:  ##\n\tpoetry update\n\tpre-commit install\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Run standards validation across project\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: validate\nvalidate:  ##\n\tpre-commit run --all-files\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Obtain the protoc binary\n# ----------------------------------------------------------------------------------------------------------------------\n$(TOOLS_BIN)/protoc:\n\t@mkdir -p $(TOOLS_BIN)\n\tcurl -Lo $(TOOLS_DIRECTORY)/protoc-3.19.4-osx-x86_64.zip https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-osx-x86_64.zip\n\tcd $(TOOLS_DIRECTORY)\n\tunzip -d $(TOOLS_DIRECTORY) $(TOOLS_DIRECTORY)/protoc-3.19.4-osx-x86_64.zip\n\n#-----------------------------------------------------------------------------------------------------------------------\n# Generate HTML documentation\n# Run this target only in poetry shell\n# The generated html pages are in $(CURRDIR)/docs/_build\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: docs\ndocs:  ## Generate doc\n\tcd $(CURRDIR)/docs;\t\\\n\tpoetry run sphinx-build -b html . _build\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Startup cluster members via docker compose\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-cluster-startup\ntest-cluster-startup: $(BUILD_PROPS) ## Startup any test cluster members using docker-compose\n\tcd tests/utils && ${COMPOSE} -f docker-compose-2-members.yaml up -d\n\t$(eval LOGFILE_NAME=log-clear-tests-$(COHERENCE_VERSION).txt)\nifeq ($(RUN_SECURE), true)\n\t$(eval LOGFILE_NAME=log-ssl-tests-$(COHERENCE_VERSION).txt)\nendif\n\tcd tests/utils && ${COMPOSE} -f docker-compose-2-members.yaml logs -f --no-color > $(LOGFILE_NAME) &\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Shutdown any cluster members via docker compose\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-cluster-shutdown\ntest-cluster-shutdown: ## Shutdown any test cluster members using docker-compose\n\tcd tests/utils && ${COMPOSE} -f docker-compose-2-members.yaml down || true\n\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Startup standalone coherence via java -jar\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-coherence-startup\ntest-coherence-startup: ## Startup standalone cluster\n\tscripts/startup-clusters.sh $(TEST_LOGS_DIR) $(CLUSTER_PORT) $(COHERENCE_GROUP_ID) ${COHERENCE_VERSION}\n\t@echo \"Clusters started up\"\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Shutdown coherence via java -jar\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: test-coherence-shutdown\ntest-coherence-shutdown: ## shutdown standalone cluster\n\t@ps -ef | grep shutMeDownPlease | grep -v grep | awk '{print $$2}' | xargs kill -9 || true\n\t@echo \"Clusters shutdown\"\n\n# ----------------------------------------------------------------------------------------------------------------------\n# wait for 30 seconds\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: just-wait\njust-wait: ## sleep for 30 seconds\n\t@echo \"Sleep for 30 seconds\"\n\tsleep 30\n\n# ----------------------------------------------------------------------------------------------------------------------\n# Remove docker images\n# ----------------------------------------------------------------------------------------------------------------------\n.PHONY: remove-app-images\nremove-app-images: ## Remove docker images\n\t@echo \"Remove docker images\"\n\tdocker image rmi $(TEST_APPLICATION_IMAGE_1) $(TEST_APPLICATION_IMAGE_2) || true\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Makefile b/Makefile
--- a/Makefile	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/Makefile	(date 1728944050754)
@@ -32,14 +32,14 @@
 MVN_VERSION ?= 1.0.0
 
 # Coherence CE version to run base tests against
-COHERENCE_VERSION ?= 22.06.7
-COHERENCE_GROUP_ID ?= com.oracle.coherence.ce
+COHERENCE_VERSION ?= 15.1.1-0-0-SNAPSHOT
+COHERENCE_GROUP_ID ?= com.oracle.coherence
 COHERENCE_WKA1 ?= server1
 COHERENCE_WKA2 ?= server1
 CLUSTER_PORT ?= 7574
 # Profiles to include for building
-PROFILES ?= ",-jakarta,javax"
-COHERENCE_BASE_IMAGE ?= gcr.io/distroless/java17-debian11
+PROFILES ?= ",jakarta,-javax"
+COHERENCE_BASE_IMAGE ?= gcr.io/distroless/java17-debian12
 
 # ----------------------------------------------------------------------------------------------------------------------
 # Set the location of various build tools
Index: tests/java/coherence-python-test/src/main/java/com/oracle/coherence/python/testing/LongRunningProcessor.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/java/coherence-python-test/src/main/java/com/oracle/coherence/python/testing/LongRunningProcessor.java b/tests/java/coherence-python-test/src/main/java/com/oracle/coherence/python/testing/LongRunningProcessor.java
new file mode 100644
--- /dev/null	(date 1728938954352)
+++ b/tests/java/coherence-python-test/src/main/java/com/oracle/coherence/python/testing/LongRunningProcessor.java	(date 1728938954352)
@@ -0,0 +1,24 @@
+package com.oracle.coherence.python.testing;
+
+
+import com.tangosol.util.Base;
+import com.tangosol.util.InvocableMap;
+import java.util.Map;
+import java.util.Set;
+
+
+public class LongRunningProcessor
+        implements InvocableMap.EntryProcessor<Object, Object, Void>
+    {
+    public Void process(InvocableMap.Entry<Object, Object> entry)
+        {
+        Base.sleep(60000);
+        return null;
+        }
+
+    public Map<Object, Void> processAll(Set<? extends InvocableMap.Entry<Object, Object>> setEntries)
+        {
+        Base.sleep(60000);
+        return InvocableMap.EntryProcessor.super.processAll(setEntries);
+        }
+    }
Index: tests/java/pom.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<!--\n\n    Copyright (c) 2022, 2023 Oracle and/or its affiliates.\n    Licensed under the Universal Permissive License v 1.0 as shown at\n    https://oss.oracle.com/licenses/upl.\n\n-->\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.oracle.coherence.python</groupId>\n  <artifactId>coherence-python-parent</artifactId>\n  <packaging>pom</packaging>\n  <version>1.0.0</version>\n\n  <description>Oracle Coherence Python Client Test</description>\n  <name>coherence-python-parent</name>\n\n  <modules>\n    <module>coherence-python-test</module>\n  </modules>\n\n  <properties>\n    <revision>1.0.0</revision>\n    <operator.version>${project.version}</operator.version>\n\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <maven.compiler.source>11</maven.compiler.source>\n    <maven.compiler.target>11</maven.compiler.target>\n\n    <coherence.group.id>com.oracle.coherence.ce</coherence.group.id>\n    <coherence.version>24.03.1</coherence.version>\n\n    <!-- The version of Coherence to use in the test images -->\n    <coherence.test.groupId>com.oracle.coherence.ce</coherence.test.groupId>\n    <coherence.test.version>${coherence.version}</coherence.test.version>\n\n    <coherence.test.base.image>gcr.io/distroless/java:11</coherence.test.base.image>\n\n    <!-- library dependency versions -->\n    <version.lib.asciidoctor.diagram>2.2.1</version.lib.asciidoctor.diagram>\n    <version.lib.commonjava.directory>1.0</version.lib.commonjava.directory>\n    <version.plugin.helidon-build-tools>2.0.0-M3</version.plugin.helidon-build-tools>\n    <version.plugin.jib>3.4.3</version.plugin.jib>\n    <version.plugin.maven.assembly>3.7.1</version.plugin.maven.assembly>\n    <version.plugin.maven.compiler>3.13.0</version.plugin.maven.compiler>\n    <version.plugin.maven.dependency>3.8.0</version.plugin.maven.dependency>\n    <version.plugin.maven.jar>3.4.2</version.plugin.maven.jar>\n    <version.plugin.maven.shade>3.2.4</version.plugin.maven.shade>\n    <version.plugin.maven.resource>3.1.0</version.plugin.maven.resource>\n\n    <!-- coherence cache config to build with -->\n    <coherence.cache.config>test-cache-config.xml</coherence.cache.config>\n    <coherence.cluster1>cluster1</coherence.cluster1>\n    <coherence.cluster2>cluster1</coherence.cluster2>\n    <coherence.wka1>server1</coherence.wka1>\n    <coherence.wka2>server1</coherence.wka2>\n\n    <com.sun.xml.bind.version>2.3.0</com.sun.xml.bind.version>\n    <javax.activation.version>1.1.1</javax.activation.version>\n\n    <!-- grpc security settings -->\n    <coherence.grpc.server.socketprovider></coherence.grpc.server.socketprovider>\n    <coherence.security.key></coherence.security.key>\n    <coherence.security.cert></coherence.security.cert>\n    <coherence.security.ca.cert></coherence.security.ca.cert>\n    <coherence.scope></coherence.scope>\n  </properties>\n\n  <dependencyManagement>\n    <dependencies>\n      <dependency>\n        <groupId>${coherence.group.id}</groupId>\n        <artifactId>coherence</artifactId>\n        <version>${coherence.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.oracle.coherence.ce</groupId>\n        <artifactId>coherence-json</artifactId>\n        <version>${coherence.version}</version>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n  <build>\n    <pluginManagement>\n      <plugins>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-compiler-plugin</artifactId>\n          <version>${version.plugin.maven.compiler}</version>\n        </plugin>\n\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-assembly-plugin</artifactId>\n          <version>${version.plugin.maven.assembly}</version>\n        </plugin>\n\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-jar-plugin</artifactId>\n          <version>${version.plugin.maven.jar}</version>\n        </plugin>\n\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-dependency-plugin</artifactId>\n          <version>${version.plugin.maven.dependency}</version>\n        </plugin>\n\n        <plugin>\n          <groupId>org.commonjava.maven.plugins</groupId>\n          <artifactId>directory-maven-plugin</artifactId>\n          <version>${version.lib.commonjava.directory}</version>\n        </plugin>\n      </plugins>\n    </pluginManagement>\n\n    <plugins>\n      <plugin>\n        <groupId>org.commonjava.maven.plugins</groupId>\n        <artifactId>directory-maven-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>generate-top-parent-basedir</id>\n            <goals>\n              <goal>highest-basedir</goal>\n            </goals>\n            <phase>validate</phase>\n            <configuration>\n              <property>top.parent.basedir</property>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n    </plugins>\n  </build>\n\n  <profiles>\n    <profile>\n      <id>jakarta</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <modules>\n        <module>coherence-python-client-data-jakarta</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>javax</id>\n      <activation>\n        <!-- This is a work-around for the fact that activeByDefault does not do what you'd think it should -->\n        <file>\n          <exists>.</exists>\n        </file>\n      </activation>\n      <modules>\n        <module>coherence-python-client-data-javax</module>\n      </modules>\n    </profile>\n\n    <!-- secure grpc with tls -->\n    <profile>\n      <id>secure</id>\n      <properties>\n        <coherence.grpc.server.socketprovider>tls-files</coherence.grpc.server.socketprovider>\n        <coherence.security.key>/certs/star-lord.pem</coherence.security.key>\n        <coherence.security.cert>/certs/star-lord.crt</coherence.security.cert>\n        <coherence.security.ca.cert>/certs/guardians-ca.crt</coherence.security.ca.cert>\n      </properties>\n    </profile>\n\n    <!-- enable testing with scope -->\n    <profile>\n      <id>scope</id>\n      <properties>\n        <coherence.scope>test</coherence.scope>\n      </properties>\n    </profile>\n\n    <!-- member1 image -->\n    <profile>\n      <id>member1</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>com.google.cloud.tools</groupId>\n            <artifactId>jib-maven-plugin</artifactId>\n            <version>${version.plugin.jib}</version>\n            <configuration>\n              <from>\n                <image>docker://${coherence.test.base.image}</image>\n              </from>\n              <container>\n                <jvmFlags>\n                  <jvmFlag>-Xmx2g</jvmFlag>\n                  <jvmFlag>-Xms2g</jvmFlag>\n                  <jvmFlag>-Dcoherence.scope=${coherence.scope}</jvmFlag>\n                  <jvmFlag>-Dcoherence.wka=server1</jvmFlag>\n                  <jvmFlag>-Dcoherence.cluster=cluster1</jvmFlag>\n                  <jvmFlag>-Dcoherence.member=member1</jvmFlag>\n                  <jvmFlag>-Dcoherence.machine=server1</jvmFlag>\n                  <jvmFlag>-Dcoherence.site=Site1</jvmFlag>\n                  <jvmFlag>-Dcoherence.management=all</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.http=all</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.http.port=30000</jvmFlag>\n                  <jvmFlag>-Dcoherence.metrics.http.enabled=true</jvmFlag>\n                  <jvmFlag>-Dcoherence.metrics.http.port=9612</jvmFlag>\n                  <jvmFlag>-Dcoherence.grpc.server.port=1408</jvmFlag>\n                  <jvmFlag>-Dcoherence.grpc.server.socketprovider=${coherence.grpc.server.socketprovider}</jvmFlag>\n                  <jvmFlag>-Dcoherence.security.key=${coherence.security.key}</jvmFlag>\n                  <jvmFlag>-Dcoherence.security.cert=${coherence.security.cert}</jvmFlag>\n                  <jvmFlag>-Dcoherence.security.ca.cert=${coherence.security.ca.cert}</jvmFlag>\n                  <jvmFlag>-Dcoherence.io.json.debug=true</jvmFlag>\n                  <jvmFlag>-Dcoherence.log.level=9</jvmFlag>\n                  <jvmFlag>-Dcoherence.distributed.localstorage=true</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.refresh.expiry=1s</jvmFlag>\n                  <jvmFlag>-Dcoherence.cacheconfig=${coherence.cache.config}</jvmFlag>\n                </jvmFlags>\n                <mainClass>com.oracle.coherence.python.testing.RestServer</mainClass>\n                <format>OCI</format>\n              </container>\n            </configuration>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n\n    <!-- member2 image -->\n    <profile>\n      <id>member2</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>com.google.cloud.tools</groupId>\n            <artifactId>jib-maven-plugin</artifactId>\n            <version>${version.plugin.jib}</version>\n            <configuration>\n              <from>\n                <image>docker://${coherence.test.base.image}</image>\n              </from>\n              <container>\n                <jvmFlags>\n                  <jvmFlag>-Xmx2g</jvmFlag>\n                  <jvmFlag>-Xms2g</jvmFlag>\n                  <jvmFlag>-Dcoherence.scope=${coherence.scope}</jvmFlag>\n                  <jvmFlag>-Dcoherence.wka=server1</jvmFlag>\n                  <jvmFlag>-Dcoherence.cluster=cluster1</jvmFlag>\n                  <jvmFlag>-Dcoherence.member=member2</jvmFlag>\n                  <jvmFlag>-Dcoherence.machine=server2</jvmFlag>\n                  <jvmFlag>-Dcoherence.site=Site1</jvmFlag>\n                  <jvmFlag>-Dcoherence.log.level=9</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.http=all</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.http.port=30000</jvmFlag>\n                  <jvmFlag>-Dcoherence.management.refresh.expiry=1s</jvmFlag>\n                  <jvmFlag>-Dcoherence.distributed.localstorage=true</jvmFlag>\n                  <jvmFlag>-Dcoherence.metrics.http.enabled=true</jvmFlag>\n                  <jvmFlag>-Dcoherence.metrics.http.port=9613</jvmFlag>\n                  <jvmFlag>-Dcoherence.cacheconfig=${coherence.cache.config}</jvmFlag>\n                </jvmFlags>\n                <mainClass>com.oracle.coherence.python.testing.RestServer</mainClass>\n                <format>OCI</format>\n              </container>\n            </configuration>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n  </profiles>\n\n  <repositories>\n    <repository>\n      <id>ossrh-staging</id>\n      <name>OSS Sonatype Staging</name>\n      <url>https://oss.sonatype.org/content/groups/staging/</url>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n    </repository>\n\n    <repository>\n      <id>snapshots-repo</id>\n      <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n      <releases>\n        <enabled>false</enabled>\n      </releases>\n      <snapshots>\n        <enabled>true</enabled>\n      </snapshots>\n    </repository>\n  </repositories>\n</project>\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/java/pom.xml b/tests/java/pom.xml
--- a/tests/java/pom.xml	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/tests/java/pom.xml	(date 1728943213504)
@@ -33,14 +33,14 @@
     <maven.compiler.source>11</maven.compiler.source>
     <maven.compiler.target>11</maven.compiler.target>
 
-    <coherence.group.id>com.oracle.coherence.ce</coherence.group.id>
-    <coherence.version>24.03.1</coherence.version>
+    <coherence.group.id>com.oracle.coherence</coherence.group.id>
+    <coherence.version>15.1.1-0-0-SNAPSHOT</coherence.version>
 
     <!-- The version of Coherence to use in the test images -->
-    <coherence.test.groupId>com.oracle.coherence.ce</coherence.test.groupId>
+    <coherence.test.groupId>com.oracle.coherence</coherence.test.groupId>
     <coherence.test.version>${coherence.version}</coherence.test.version>
 
-    <coherence.test.base.image>gcr.io/distroless/java:11</coherence.test.base.image>
+    <coherence.test.base.image>gcr.io/distroless/java17-debian12:latest</coherence.test.base.image>
 
     <!-- library dependency versions -->
     <version.lib.asciidoctor.diagram>2.2.1</version.lib.asciidoctor.diagram>
Index: tests/java/coherence-python-test/src/main/resources/META-INF/type-aliases.properties
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#\n# Copyright (c) 2022 Oracle and/or its affiliates.\n# Licensed under the Universal Permissive License v 1.0 as shown at\n# https://oss.oracle.com/licenses/upl.\n#\n\n\ntest.customer=com.oracle.coherence.python.testing.Customer\ntest.address=com.oracle.coherence.python.testing.Address\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/java/coherence-python-test/src/main/resources/META-INF/type-aliases.properties b/tests/java/coherence-python-test/src/main/resources/META-INF/type-aliases.properties
--- a/tests/java/coherence-python-test/src/main/resources/META-INF/type-aliases.properties	(revision 3f7f82d51204b2c8b24772b16a2e0ca3e0308249)
+++ b/tests/java/coherence-python-test/src/main/resources/META-INF/type-aliases.properties	(date 1728938954346)
@@ -7,3 +7,4 @@
 
 test.customer=com.oracle.coherence.python.testing.Customer
 test.address=com.oracle.coherence.python.testing.Address
+test.longrunning=com.oracle.coherence.python.testing.LongRunningProcessor
